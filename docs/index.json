[{"content":"查看本文配套的 slide 点这里\n大家好，今天我分享的主题是「打破壁垒：代理技术在家庭网络中的应用」。主要是向大家介绍，假如在家庭网络中，有黑客挟持了网关，并对正常访问互联网产生了干扰，我们如何通过代理技术来突破封锁，打破壁垒，正常地访问互联网。\n运行良好的家庭网络 首先我们来复习一下在一个运行良好的家庭网络中，用户是如何访问互联网，以及网关在其中起到了什么作用的。\n上图是一个最简化的家庭网络的基本架构。ISP，也就是互联网服务提供商向你提供一个内置光猫的路由器。光猫把光缆中的光信号转化为路由器能够解析的电信号。路由器是在网络层进行路由转发的设备，往往也是一个通用计算机。路由器也往往充当了无线局域网络Wi-Fi的AP，接入点。\n我们的设备在连接到Wi-Fi时，就相当于接入到了这个这个无限局域网。具有Wi-Fi功能的路由器一般也充当了dhcp服务器的角色。dhcp服务器在局域网中广播告知自己的存在，当设备检测到后就向dhcp服务器请求分配IP。dhcp不仅仅会告知设备自己被分配的IP，还会告知设备当前网段的子网掩码以及网关IP地址。在此之后，用户所有的网络报文都会被转发给网关，然后经由网关再转发给真正的目标。网关也往往是由这里的路由器担任。\n黑客、襲来 鉴于路由器“一夫当关，万夫莫开”的地位，它很容易成为被攻击的对象。假设我们处于一个合租房里，黑客阿至是我们的房主。阿至是一个狂热的百度厌恶者，他千方百计地阻止别人访问百度，甚至不惜对路由器偷偷做手脚，以使得租客无法访问百度。\n由于家中地路由器就是一个通用计算机，阿至通过刷机的方式掌握了这台路由器的root权限，从此他就可以对路由器胡作非为了。他把这台路由器刷成了Linux的系统，并输入了下面命令：\niptables -A OUTPUT -d baidu.com -j DROP\niptables -A INPUT -s baidu.com -j DROP\n下面两条命令会使路由器拒绝一切由百度发送而来，或者发向百度的报文。iptables是一个运行在linux用户态的工具，但他可以对内核网络栈的处理规则进行配置。具体而言，用户可以通过它来为内核添加一些hook函数，内核会在处理网络报文时调用这些hook函数，并根据结果对报文进行一些处理。比如第一条命令，iptables 会首先通过DNS查询获得baidu.com的IP地址，然后在一个网络层报文经过内核栈处理并发送之前，判断该报文的目标是否是baidu.com，如果是，则直接丢弃该报文。第二条命令做的也是类似的事情，他会丢弃从baidu.com发来的报文。\n这样阿至就成功地阻止了我们访问baidu.com。\n代理服务器 在阿至对路由器做了手脚后，我们就不能再访问百度了。但是百度之外的网站却又可以正常访问，所以我们很快就猜到阿至做了什么。我们可不会向黑客屈服的！如果除百度之外的网站都可以访问\u0026hellip;那么只要我们在外网上还有一台服务器，通过这台服务器的中转来访问百度，这样经过路由器报文的源IP和目的IP都会变成服务器IP而不是百度IP了，这样我们就能正常访问百度了！\n经过百度查询之后，我们发现了socks5代理这一应用层协议。在这个协议中，用户程序需要和目标通过TCP/UDP协议通信时，可以先通过socks5协议与实现了改协议的代理服务器通信，然后代理服务器再和目标通信，讲返回报文转发给用户程序。HTTP/HTTPS协议起到的作用与socks5协议类似。大多数使用网络的用户程序都实现了该协议，比如 curl，大部分浏览器 他们会在发送网络请求时先查看环境变量中是否定义了 http_proxy socks_proxy 等，如果定义了，则通过代理服务器与目标通信，否则直接通信。当然也有一些用户程序，比如 wget，并不会主动检查并使用用户定义的代理。\n所以，我们只要使用代理服务器，就可以绕开阿至的封锁了！\n黑客、侵入 不过经过一段时间后，阿至发现我们经过路由器的报文总是发现同一个地址，他很快就猜到我们是使用了代理服务器来绕靠路由器的封锁。他对数据包分析后发现，许多包中都存在 baidu 这样的字段\u0026hellip;\n于是阿至又想到了一个点子，他在路由器中输入了如下命令：\niptables -I INPUT -m string --string \u0026quot;/baidu/i\u0026quot; --algo regex -j DROP\n这样，只要报文中含有 “baidu” 这个字符串，就会被路由器丢弃，宁可错杀一百，不可放过一个！\n加密的代理 不久后，我们也发现baidu又不能正常访问了，甚至用bing搜索“baidu”都不行，似乎只要含有“baidu”这个关键词，报文就会被丢弃。于是我们想出了一个办法：既然你做关键词匹配，那么只要我的报文里没有关键词就好了。如果经过路由器的报文都是经过加密的，阿至肯定就不知道我们报文的真实内容是什么了，他也不至于和我们彻底闹翻，丢掉所有报文，不让我们连接互联网吧。\n我们首先想到的是，对socks5代理进行增强，让应用程序与代理服务之间进行加密通话。可是市场上的应用程序基本都只实现了简单的socks5代理，如果要让他们支持加密功能则需要把他们的源代码都改了，这个工作量可太大了！\n经过思考，我们想到可以利用已有的socks5代理协议，在此基础上实现自己的加密版本。我们写了一个socks5代理服务器SS Local，local接收应用程序的代理请求，可是local不运行在外网，而是运行在内网，它会把应用程序发送给他的报文先加密，然后发送给外网的另一个socks5服务器SS Server，server会解密报文，得到真正需要代理的请求。当请求返回时server也会先把报文加密，发送给local，local把报文解密，再发送给用户程序。\n这样，尽管用户程序以为自己还在使用普通的socks5代理，可是我们已经悄悄对socks5协议进行了升级，实际上经过路由器的报文都是加密过的了，阿至再也无法知道我们在看些什么了！\n透明的代理 虽然我们已经战胜了阿至，做到了几乎完美的加密，但我们还不满足于此。\n上面的代理得要用户程序主动使用，有没有可能实现透明的代理方法，让所有网络报文都经过代理？\n答案是有的。只要通过新建虚拟网卡，把通过其中的报文都代理了就好了\u0026hellip;\nVPN的原理就是这样\u0026hellip;\n漫无止境的战斗 不过，网络封锁与突破，将永远是一场漫无止境的战斗。\n事实上阿至还可以 做 DNS 污染， 识别加密数据规律 主动嗅探\u0026hellip; 但同时，兵来将挡，水来土掩，我们也永远有新的突破网络封锁的方式 \u0026ldquo;猫鼠游戏\u0026quot;永远不会完结 总结 黑客的手段 我们的举措 ip审查 代理 内容审查 加密代理 流量规律 换加密方式 主动嗅探 更好的伪装 ​\n​\n","permalink":"https://rzyn2020.github.io/posts/%E4%BB%A3%E7%90%86%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/","summary":"\u003cp\u003e查看本文配套的 slide \u003ca href=\"/slides/proxy\"\u003e点这里\u003c/a\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e大家好，今天我分享的主题是「打破壁垒：代理技术在家庭网络中的应用」。主要是向大家介绍，假如在家庭网络中，有黑客挟持了网关，并对正常访问互联网产生了干扰，我们如何通过代理技术来突破封锁，打破壁垒，正常地访问互联网。\u003c/p\u003e\n\u003ch1 id=\"运行良好的家庭网络\"\u003e运行良好的家庭网络\u003c/h1\u003e\n\u003cp\u003e首先我们来复习一下在一个运行良好的家庭网络中，用户是如何访问互联网，以及网关在其中起到了什么作用的。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"home network diagram\" loading=\"lazy\" src=\"/posts/%E4%BB%A3%E7%90%86%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/assets/Basic-home-network-2.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e上图是一个最简化的家庭网络的基本架构。ISP，也就是互联网服务提供商向你提供一个内置光猫的路由器。光猫把光缆中的光信号转化为路由器能够解析的电信号。路由器是在网络层进行路由转发的设备，往往也是一个通用计算机。路由器也往往充当了无线局域网络Wi-Fi的AP，接入点。\u003c/p\u003e\n\u003cp\u003e我们的设备在连接到Wi-Fi时，就相当于接入到了这个这个无限局域网。具有Wi-Fi功能的路由器一般也充当了dhcp服务器的角色。dhcp服务器在局域网中广播告知自己的存在，当设备检测到后就向dhcp服务器请求分配IP。dhcp不仅仅会告知设备自己被分配的IP，还会告知设备当前网段的子网掩码以及网关IP地址。在此之后，用户所有的网络报文都会被转发给网关，然后经由网关再转发给真正的目标。网关也往往是由这里的路由器担任。\u003c/p\u003e\n\u003ch1 id=\"黑客襲来\"\u003e黑客、襲来\u003c/h1\u003e\n\u003cp\u003e鉴于路由器“一夫当关，万夫莫开”的地位，它很容易成为被攻击的对象。假设我们处于一个合租房里，黑客阿至是我们的房主。阿至是一个狂热的百度厌恶者，他千方百计地阻止别人访问百度，甚至不惜对路由器偷偷做手脚，以使得租客无法访问百度。\u003c/p\u003e\n\u003cp\u003e由于家中地路由器就是一个通用计算机，阿至通过刷机的方式掌握了这台路由器的root权限，从此他就可以对路由器胡作非为了。他把这台路由器刷成了Linux的系统，并输入了下面命令：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eiptables -A OUTPUT -d baidu.com -j DROP\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eiptables -A INPUT -s baidu.com -j DROP\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e下面两条命令会使路由器拒绝一切由百度发送而来，或者发向百度的报文。iptables是一个运行在linux用户态的工具，但他可以对内核网络栈的处理规则进行配置。具体而言，用户可以通过它来为内核添加一些hook函数，内核会在处理网络报文时调用这些hook函数，并根据结果对报文进行一些处理。比如第一条命令，iptables 会首先通过DNS查询获得baidu.com的IP地址，然后在一个网络层报文经过内核栈处理并发送之前，判断该报文的目标是否是baidu.com，如果是，则直接丢弃该报文。第二条命令做的也是类似的事情，他会丢弃从baidu.com发来的报文。\u003c/p\u003e\n\u003cp\u003e这样阿至就成功地阻止了我们访问baidu.com。\u003c/p\u003e\n\u003ch1 id=\"代理服务器\"\u003e代理服务器\u003c/h1\u003e\n\u003cp\u003e在阿至对路由器做了手脚后，我们就不能再访问百度了。但是百度之外的网站却又可以正常访问，所以我们很快就猜到阿至做了什么。我们可不会向黑客屈服的！如果除百度之外的网站都可以访问\u0026hellip;那么只要我们在外网上还有一台服务器，通过这台服务器的中转来访问百度，这样经过路由器报文的源IP和目的IP都会变成服务器IP而不是百度IP了，这样我们就能正常访问百度了！\u003c/p\u003e\n\u003cp\u003e经过百度查询之后，我们发现了\u003ca href=\"https://datatracker.ietf.org/doc/html/rfc1928\"\u003esocks5代理\u003c/a\u003e这一应用层协议。在这个协议中，用户程序需要和目标通过TCP/UDP协议通信时，可以先通过socks5协议与实现了改协议的代理服务器通信，然后代理服务器再和目标通信，讲返回报文转发给用户程序。HTTP/HTTPS协议起到的作用与socks5协议类似。大多数使用网络的用户程序都实现了该协议，比如 \u003ccode\u003ecurl\u003c/code\u003e，大部分浏览器 他们会在发送网络请求时先查看环境变量中是否定义了 \u003ccode\u003ehttp_proxy socks_proxy\u003c/code\u003e 等，如果定义了，则通过代理服务器与目标通信，否则直接通信。当然也有一些用户程序，比如 \u003ccode\u003ewget\u003c/code\u003e，并不会主动检查并使用用户定义的代理。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"img\" loading=\"lazy\" src=\"/posts/%E4%BB%A3%E7%90%86%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/assets/socks5.png\"\u003e\u003c/p\u003e\n\u003cp\u003e所以，我们只要使用代理服务器，就可以绕开阿至的封锁了！\u003c/p\u003e\n\u003ch1 id=\"黑客侵入\"\u003e黑客、侵入\u003c/h1\u003e\n\u003cp\u003e不过经过一段时间后，阿至发现我们经过路由器的报文总是发现同一个地址，他很快就猜到我们是使用了代理服务器来绕靠路由器的封锁。他对数据包分析后发现，许多包中都存在 baidu 这样的字段\u0026hellip;\u003c/p\u003e\n\u003cp\u003e于是阿至又想到了一个点子，他在路由器中输入了如下命令：\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eiptables -I INPUT -m string --string \u0026quot;/baidu/i\u0026quot; --algo regex -j DROP\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e这样，只要报文中含有 “baidu” 这个字符串，就会被路由器丢弃，宁可错杀一百，不可放过一个！\u003c/p\u003e\n\u003ch1 id=\"加密的代理\"\u003e加密的代理\u003c/h1\u003e\n\u003cp\u003e不久后，我们也发现baidu又不能正常访问了，甚至用bing搜索“baidu”都不行，似乎只要含有“baidu”这个关键词，报文就会被丢弃。于是我们想出了一个办法：既然你做关键词匹配，那么只要我的报文里没有关键词就好了。如果经过路由器的报文都是经过加密的，阿至肯定就不知道我们报文的真实内容是什么了，他也不至于和我们彻底闹翻，丢掉所有报文，不让我们连接互联网吧。\u003c/p\u003e\n\u003cp\u003e我们首先想到的是，对socks5代理进行增强，让应用程序与代理服务之间进行加密通话。可是市场上的应用程序基本都只实现了简单的socks5代理，如果要让他们支持加密功能则需要把他们的源代码都改了，这个工作量可太大了！\u003c/p\u003e\n\u003cp\u003e经过思考，我们想到可以利用已有的socks5代理协议，在此基础上实现自己的加密版本。我们写了一个socks5代理服务器SS Local，local接收应用程序的代理请求，可是local不运行在外网，而是运行在内网，它会把应用程序发送给他的报文先加密，然后发送给外网的另一个socks5服务器SS Server，server会解密报文，得到真正需要代理的请求。当请求返回时server也会先把报文加密，发送给local，local把报文解密，再发送给用户程序。\u003c/p\u003e\n\u003cp\u003e这样，尽管用户程序以为自己还在使用普通的socks5代理，可是我们已经悄悄对socks5协议进行了升级，实际上经过路由器的报文都是加密过的了，阿至再也无法知道我们在看些什么了！\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"ss\" loading=\"lazy\" src=\"/posts/%E4%BB%A3%E7%90%86%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/assets/ss.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"透明的代理\"\u003e透明的代理\u003c/h1\u003e\n\u003cp\u003e虽然我们已经战胜了阿至，做到了几乎完美的加密，但我们还不满足于此。\u003c/p\u003e","title":"打破壁垒：代理技术在家庭网络中的应用"},{"content":" Programming languages should be designed not by piling feature on top of feature, but by removing the weaknesses and restrictions that make additional features appear necessary\n之前在 Twitter 上听 Robert Nystrom 的一个演说时，有观众问他“如何看待 ChatGPT，Copilot 对于编程的影响”。Robert 回道：他认为编程的乐趣在于“make something”，而 Copilot 这类工具却很有可能把 programmer 变成代码审核员，从而丧失了“make something”的乐趣。可是就算在前 ChatGPT 时代，我又真正体会到过“make something”的乐趣吗？之前我的编程实践总是一些课程作业，这些作业的 idea 或是框架总是由他人提出，目的也往往是通过 OJ。这样的编程实践给人带来的“make something”之感自然就大打折扣了。于是在可能发生的“AI 革命”的前夜，我决定自己动手写一个兼容 R7RS 的 Scheme 解释器，真正“make something”。\n在大一时曾读过部分 SICP，对 Scheme 有一点点认知。但对于其很多高级特性还不是很熟悉，尤其是 continuation 和 macro。于是在动写解释器前，打算先熟悉一下 Scheme 的特性。\nS-Expression 1960年，John McCarthy 在函数式编程的开山之作 Recursive Functions of Symbolic Expressions and Their Computation by Machine 中提出了 LSIP 语言，这也是 Scheme 的前身。LISP 语言最初也是为了支持人工智能系统 Advice Taker 而创造的(可惜 Advice Taker 代表的符号主义 AI 研究方法在当前的 AI 浪潮中似乎不见了身影)，其目的在于提供一种操作 expression 的功能以使得 Advice Taker 能在其上推理。\n在 LISP System 中，有 S-Expressions 和 S-Functions(对应 Scheme 中的过程/procedure) 两个概念。S-Expressions 即是 Symbolic Expression，和数学意义上的 expression (表达式)意义相同。S-expressions 本身仅仅是一种数据结构，没有任何求值的含义。 S-Expression 的定义如下：\n(以及list的定义如下)\n在 S-Expression 之上，我们又可以定义对其进行操作的 S-function (S-function事实上为 partial function，因为有可能无限循环)\natom. atom[x] has the value of T or F according to whether x is an atomic symbol.\natom [X] = T atom [(X · A)] = F\ncar. car[x] is defined if and only if x is not atomic. car [(e1 · e2)] = e1. Thus car [X] is undefined.\ncar [(X · A)] = X car [((X · A) · Y )] = (X · A)\n当然S-function也可以递归：\nff[x]. The value of ff[x] is the first atomic symbol of the S-Expression x with the parentheses ignored.\nThus ff[((A · B) · C)] = A\n向上面的式子叫做 M-expressions (meta-expressions)。(注意到 M-expression 之上就有求值的语义了)\n有趣的是，我们可以通过 S-Expressions 来表示 S-Functions，同理可以把任意一个 M-expression 用 S-Expression 表达：\n(这样就有平时用的 Scheme 的感觉了，，)\n然而单是这个转换本身没有什么作用，我们需要有一个函数 eval 来对转换后的 S-Expression 进行求值，其结果相当于对应的 M-Expression 的求值结果。我们在写 LSIP 程序时其实就是在写 S-Expression，但表示的却是 M-Expression。解释器运行程序就相当于把你写好的 S-Expression 丢给 eval 函数并返回结果。 S-Expression 这种程序的表示方式自然也被 Scheme 所继承，不过在 Scheme 中这些东西都是小写。而第一条转换规则中的 Atom QUOTE 可以简写为\u0026rsquo;。 除了 S-Expression，Scheme 还从 LISP 中继承了 GC,动态类型。高阶函数等特征。\nFun Facts: John McCarthy 父亲为爱尔兰移民，母亲为立陶宛犹太人移民，二人都思想开放，加入了美国共产党(Communist Party USA)。John 出身生于1927年，少时通过阅读俄文译作 100,000 Whys (难道中文版的《十万个为什么》也来自苏联？)燃起了对科学的兴趣。John后来也精通俄语，与多苏联科学家相识。但当他在 1968 年正真去苏联旅行之后很快就失望了，转变为共和党支持者。\nContinuation Scheme 于1970年代在 MIT AI Lab 被 Guy L. Steele 和 Gerald Jay Sussman发明(又是AI？)。与父亲 LISP 不同, Scheme 实现了尾递归优化，并引入了宏和 first class continuations，本节主要介绍 continuation，下一节介绍宏(Macro)。\n上一节说了 M-Expression 有求值语义，eval 函数也能求值，但并未说明到底怎样求值。具体来说，eval 接收到一个 S-Expression 后，对 S-Expression 的所有子Expression(接收到的 S-Expression 应为一个list，子 Expression 指的是 list 中的各个子项)逐个调用eval函数。第一个子 Expression 应为一个过程，剩余的 expression 为这个过程的参数，然后eval会调用apply将参数作用到过程上并返回结果。对于 Scheme 语言中定义的基本过程，apply 会直接计算并返回结果，对于复合过程，apply 会将函数形参替换为实际值，再调用 eval 对函数体求值并返回。\n可以看到，对一个 S-Expression 求值的过程可以看作一次次的对 eval 的调用。而每个 eval 调用结束之后都有下面还要进行的求值，这个后面还要进行的求值就叫做当前求值的 Continuation(延续)。\nScheme 中的 Continuation 是一个很抽象的概念，在其它编程语言中往往缺少对于概念。但在C语言中，我们可以通过机器状态来理解 Continuation。在C语言中，假如要调用一个函数 f，会在栈上 push f 的帧，f调用结束之后会将返回值 push 到栈上，再接着做后续计算。如果再将返回值 push 到栈上的一瞬间，我们对整个进程做一个快照，这个快照说明了在 f 返回后应该要做的计算，它其实就是 f 的 Continuation。在C语言中，我们可以通过int setjmp(jmp_buf env)来捕获在调用setjmp时的 Continuation 并保存在 env 中，而在未来调用void longjmp(jmp_buf env, int val) 会继续进行 setjmp 时保存的 Continuation，并把 val 作为 setjmp 的返回值。看起来就像进行了一次“时空穿越”。\nC语言中 setjmp 和 longjmp 的实现很好理解——setjmp 保存当前的 pc 指针以及寄存器的状态，longjmp时复原就行——当然这样也就引出了一个问题：c语言中的 setjmp 并不能真正保存 Continuation，因为 setjmp 不可能将栈上的值也保存了。但 Scheme 中的 Continuation 却是真正的 Continuation\nScheme 是通过 call/cc 这一过程起到和C语言中 setjmp 类似却更完备的功能的。call/cc 接收一个一元 lambda 函数，对其求值时相当于将当前的 Continuation传 入该一元 lambda 函数后对该函数体求值。如果一元 lambda 函数正常返回，则 call/cc 过程的返回值就是一元 lambda 函数的返回值。如过在任何地方调用了 Continuation(Continuation 也是一个一元过程)，当前的所要进行的计算就会变成 Continuation 所记录的计算，就好像 call/cc 过程刚刚返回一样，而此时 call/cc 的返回值为调用 Continuation 时传入的参数：\n(call/cc (lambda (k) (* 5 4))) =\u0026gt; 20 (call/cc (lambda (k) (* 5 (k 4)))) =\u0026gt; 4 (+ 2 (call/cc (lambda (k) (* 5 (k 4))))) =\u0026gt; 6 借助 call/cc，我们可以实现协程(coroutine)：\n(define lwp-list \u0026#39;()) (define lwp (lambda (thunk) (set! lwp-list (append lwp-list (list thunk))))) (define start (lambda () (let ((p (car lwp-list))) (set! lwp-list (cdr lwp-list)) (p)))) (define pause (lambda () (call/cc (lambda (k) (lwp (lambda () (k #f))) (start))))) (define quit (lambda () (if (null? lwp-list) #f (start)))) (lwp (lambda () (let f () (pause) (display \u0026#34;h\u0026#34;) (f)))) (lwp (lambda () (quit))) (lwp (lambda () (let f () (pause) (display \u0026#34;e\u0026#34;) (f)))) (lwp (lambda () (let f () (pause) (display \u0026#34;y\u0026#34;) (f)))) (lwp (lambda () (let f () (pause) (display \u0026#34;!\u0026#34;) (f)))) (lwp (lambda () (let f () (pause) (newline) (f)))) (start) =\u0026gt; hey! hey! hey! 如果利用 Macro，在每次调用 lambda 函数时插入“中断”指令，我们也可以模拟线程(由于没有迭代，每个 lambda 函数体的执行都是O(1)的时间复杂度，因此每次进入函数体时中断也能达到类似“定时中断”的效果)：\n(define clock 0) (define handler #f) (define start-timer (lambda (ticks new-handler) (set! handler new-handler) (set! clock ticks))) (define stop-timer (lambda () (let ((time-left clock)) (set! clock 0) time-left))) (define decrement-timer (lambda () (when (\u0026gt; clock 0) (set! clock (- clock 1)) (when (= clock 0) (handler))))) (define-syntax timed-lambda (syntax-rules () ((_ formals exp1 exp2 ...) (lambda formals (decrement-timer) exp1 exp2 ...)))) (define make-engine (let ((do-complete #f) (do-expire #f)) (define timer-handler (lambda () (start-timer (call/cc do-expire) timer-handler))) (define new-engine (lambda (resume) (lambda (ticks complete expire) ((call/cc (lambda (escape) (set! do-complete (lambda (ticks value) (escape (lambda () (complete ticks value))))) (set! do-expire (lambda (resume) (escape (lambda () (expire (new-engine resume)))))) (resume ticks))))))) (lambda (proc) (new-engine (lambda (ticks) (start-timer ticks timer-handler) (let ((value (proc))) (let ((ticks (stop-timer))) (do-complete ticks value)))))))) (define fibonacci (timed-lambda (n) (if (\u0026lt; n 2) n (+ (fibonacci (- n 1)) (fibonacci (- n 2)))))) (define eng (make-engine (lambda () (fibonacci 10)))) (eng 1 list (lambda (new-eng) (set! eng new-eng) \u0026#34;expired\u0026#34;)) Macro C语言的程序需要经过预编译进行宏展开之后才生成真正待编译的程序，同理 Scheme 程序也要经过 syntax expander 展开之后得到真正待解释的 S-Expression。但相比C语言单纯做字符串替换的宏，Scheme 宏有以下两个特点：\nScheme 中的宏是卫生宏（Hygienic Macro，宏扩展的代码和程序中的代码是相互独立的，宏扩展不会引入程序中未定义的变量或函数，也不会改变程序中已有的标识符的含义。\nScheme 中的宏做的是 pattern-based transformations。因为Scheme程序本身用 S-Expression 表达，所以非常容易做 pattern match 之后 transformation。\n具体而言，Scheme 通过 define-syntax 等方法将定义一系列 transformer，并指定一个 keyword，之后只要遇到该 keyword，就会尝试 pattern match 并作变换，例子如下：\n(define-syntax cond (syntax-rules (else) ((_ (else e1 e2 ...)) (begin e1 e2 ...)) ((_ (e0 e1 e2 ...)) (if e0 (begin e1 e2 ...))) ((_ (e0 e1 e2 ...) c1 c2 ...) (if e0 (begin e1 e2 ...) (cond c1 c2 ...))))) 上述例子中，cond 为 keyword，else 为 literal，表示程序中本来就有的 identifieer，不会在后续pattern match 中被认为是 pattern variable。当遇到一个 keyword 时，就会调用上述宏定义的 transformer，并一个 pattern 一个 pattern 试着匹配，如果匹配成功则进行变换。 如\n(cond (e0 e1 e2 e3) (else e4 e5 e6)) =\u0026gt; (if e0 (begin e1 e2 e3) (cond e4 e5 e6)) =\u0026gt; (if e0 (begin e1 e2 e3) (if e4 (begin e5 e6))) Summary 本文简单梳理了一下 Scheme 中我不太了解的几个特性——当然也仅仅是了解了一下，且背后牵扯到的PL/逻辑学理论甚至是精巧的实现都是没有本文涉及的。\n如果后面能够实现 continuation 以及 pattern match，也可谓是壮举了。\n","permalink":"https://rzyn2020.github.io/posts/scheme%E6%8B%BE%E9%81%97/","summary":"\u003cblockquote\u003e\n\u003cp\u003eProgramming languages should be designed not by piling feature on top of feature, but by removing the weaknesses and restrictions that make additional features appear necessary\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003c!-- more --\u003e\r\n\u003cp\u003e之前在 Twitter 上听 \u003ca href=\"https://twitter.com/intent/user?screen_name=munificentbob\"\u003eRobert Nystrom\u003c/a\u003e 的一个演说时，有观众问他“如何看待 ChatGPT，Copilot 对于编程的影响”。Robert 回道：他认为编程的乐趣在于“make something”，而 Copilot 这类工具却很有可能把 programmer 变成代码审核员，从而丧失了“make something”的乐趣。可是就算在前 ChatGPT 时代，我又真正体会到过“make something”的乐趣吗？之前我的编程实践总是一些课程作业，这些作业的 idea 或是框架总是由他人提出，目的也往往是通过 OJ。这样的编程实践给人带来的“make something”之感自然就大打折扣了。于是在可能发生的“AI 革命”的前夜，我决定自己动手写一个兼容 R7RS 的 Scheme 解释器，真正“make something”。\u003c/p\u003e\n\u003cp\u003e在大一时曾读过部分 SICP，对 Scheme 有一点点认知。但对于其很多高级特性还不是很熟悉，尤其是 continuation 和 macro。于是在动写解释器前，打算先熟悉一下 Scheme 的特性。\u003c/p\u003e\n\u003ch1 id=\"s-expression\"\u003eS-Expression\u003c/h1\u003e\n\u003cp\u003e1960年，John McCarthy 在函数式编程的开山之作 \u003ca href=\"http://www-formal.stanford.edu/jmc/recursive.pdf\"\u003eRecursive Functions of Symbolic Expressions and Their Computation by Machine\u003c/a\u003e 中提出了 LSIP 语言，这也是 Scheme 的前身。LISP 语言最初也是为了支持人工智能系统 Advice Taker 而创造的(可惜 Advice Taker 代表的符号主义 AI 研究方法在当前的 AI 浪潮中似乎不见了身影)，其目的在于提供一种操作 expression 的功能以使得 Advice Taker 能在其上推理。\u003c/p\u003e","title":"Scheme 拾遗：S-Expression，Continuation 以及 Macro"},{"content":" When you are on the dancefloor, there is nothing to do but dance.\n—— Umberto Eco, *The Mysterious Flame of Queen Loana*\n有一道经典的Java面试题：\nInteger i = 100; Integer j = 100; System.out.print(i == j); // true or false? 由于之前没有准备直接上阵，在碰到这道题时一时不解。但显然这是考察autoboxing(自动装箱)机制，而一般整数转化为Integer对象时肯定是new一个新对象，按理说结果应该为false，但是考虑到在具体实现中可能为了效率考虑会预先缓存一部分整数对象，于是便猜测答案为true。下来网上一查，答案果然为true，但解释却是如下：\n这就有点奇怪了——我总觉得缓存多少是具体的编译器或者JVM抑或是相关类库实现的问题，而不该定义在语言规范中，而如果是和具体实现相关的，那么言之凿凿256个数字需要缓存就有点奇怪了。上网查查资料之后，发现256这个数字果然还是Integer类的默认实现中决定的。下面我就综合查找的资料，介绍一下这道题背后可能涉及的知识。\nReference Type 和 Primitive Type 首先Java类型系统以及JVM中，任何 Value(值) 要么是 reference type(引用类型)，要么是 primitive type(基本类型)。所谓reference type就是指向一个对象的值，总是一条new指令的返回值，往往是自身具有一定状态，并可以改变的(mutable)，在JVM实现中为一个指向具体对象的指针；而 primitive type的值 则只能通过字面量或是预先定义的在primitive type上的操作获得，而操作并不改变值本身，只是产生了一个新的值，即是不可变的(immutable)的，在JVM实现中也对应实现语言的primitive type(可以理解为c++中的Int)。\n但是在许多其他面向对象语言中(如Python)，一切皆是对象，一切值皆是引用。这样做比Java好理解许多，具体实现上也易于实现了。但是却带来了效率的低下，这主要有两点原因：\n对于整数这样的在编程中最基本且常用的值，如果每次两数相加都返回一个新对象，则是对资源的极大浪费。 你可能会想：为什么不把整数对象做成单例的？也就是一个只有一个1对象，也只有一个2对象，每次 1 + 1 总能得到同一个2 —— 但注意reference type的特征就是mutable，如果这样就做不到mutable了，和用primitive type表示整数也就没有区别了。 在JVM执行时，遇到引用需要先解引用才能获取整数值，然后再相加，之后封装成整数对象并返回引用，与直接将整数表示为实现语言的primitive type相比效率天差地别。 因此，为了效率考虑，则需要把整数，浮点数等归入primitive type。这样做就又产生了一个问题：在JVM中，一个值即可能是用实现语言的primitive type表示，也可能用指针表示，我们如何对二者进行区分呢？幸好Java是静态类型语言，在编译之后每条指令所操作的值的类型也是确定的。比如当执行iadd指令时栈上存的值就一定为两个整数。但在动态语言中就不一定了，我们必须要先检查类型是否匹配，然后进行操作。此时为了标明一个值究竟是primitive type还是reference type，我们必须把值的高位留出来作为类型tag以示区分。\n// 动态语言虚拟机中的一个值往往是这个样子的 struct Value_t { Type type; union { double number; bool boolean; HeapObject* object; } data; }; Generic 既然有了primitive type的整数，似乎再也不需要作为对象的整数了？看起来似乎是这样，但是Java却依然提供了Integer类表示作为对象的整数——这主要还是因为为了支持泛型的存在。\nJava的泛型是通过类型擦除实现的，也就是泛型信息只在编译期可见，而在运行期(也就是JVM)不可见。无论你是写成List\u0026lt;String\u0026gt; 还是 List\u0026lt;A\u0026gt; ，它们在编译后都会变成同一个List，而这个List存储的是Object对象。\n// 泛型类： public class Box\u0026lt;T\u0026gt; { private T t; public void set(T t) { this.t = t; } public T get() { return t; } } // 上面的泛型类在编译成字节码后 public class org/example/Box { private Ljava/lang/Object; t public \u0026lt;init\u0026gt;()V ... public set(Ljava/lang/Object;)V ... public get()Ljava/lang/Object; ... } 因为实际上用Object存储，所以每次get都是做了一次强制类型转换，Java编译器会生成CHECKCAST指令来保证类型转换时的正确性。\n// java代码 System.out.println(stringBox.get()); // 编译后的字节码 INVOKEVIRTUAL org/example/Box.get ()Ljava/lang/Object; CHECKCAST java/lang/String INVOKEVIRTUAL java/io/PrintStream.println (Ljava/lang/String;)V 但是如果泛型已经由编译器保证没有类型错误，为什么又要加CHECKCAST指令来运行时再次检查呢？考虑如下泛型程序，在可以通过编译，但在运行时CHECKCAST会报错：\npublic class Main { public static void main(String[] args) { Box stringBox = new Box\u0026lt;\u0026gt;(); stringBox.set(5); foo(stringBox); } public static void foo(Box\u0026lt;String\u0026gt; box) { System.out.println(box.get() + \u0026#34;123\u0026#34;); } } //Exception in thread \u0026#34;main\u0026#34; java.lang.ClassCastException: class java.lang.Integer cannot be cast to class //java.lang.String (java.lang.Integer and java.lang.String are in module java.base of loader \u0026#39;bootstrap\u0026#39;) //\tat org.example.Main.foo(Main.java:14) //\tat org.example.Main.main(Main.java:10) 这是因为Java为了让新代码和没有泛型之前(Java8)的代码兼容，而引入了Raw Type，也就是没有泛型参数的泛型——对这种类型的检查会适当放松——代价就是动态检查的开销。\n当然泛型不仅仅可以通过类型擦除实现，像C++的模板就是走向了另外一个极端——为每个类型都生成相应的类——这样的缺点自然是代码膨胀，好处却是可以动态获取类型信息(C++是否支持反射暂且不论，但如果Java采取和C++一样泛型机制就一定会支持这样的反射的)，不需要动态类型检查，也不需要像Java一样的Integer类。\n好，话题又回到Java的Integer类，正是应为Java的泛型是通过类型擦除实现，所以所有的泛型在背后都有一套统一的表示——也就是Object。但是primitive type却在Java OO继承链之外，也就无法使用泛型了——所有就引入了将primitive type封装成wrapper type的机制。将int封装为Integer即是一个例子。\nAutoboxing and Integer Cache 虽然已经有了wrapper type，但每次手动封装也是非常麻烦的。所以编译就加入了自动检测类型，在合适的时候将primitive type转化为相应的wrapper type，将wrapper type转化为相应的primitive type的机制，也就是“Autoboxing”与“Unboxing”\n所以说，面试题中Integer i = 100;等即采用了Autoboxing 机制，上面的代码在编译处理过之后就等价为下面的代码：\nInteger i = Integer.valueOf(100); Integer j = Integer.valueOf(100); System.out.print(i == j); // true or false? 已知引用比较在java中是直接比较地址，那么我们只需要知道Integer.valueOf做了什么就知道面试题的答案了。\n查阅 java doc，发现:\npublic static Integer valueOf(int i) Returns an Integer instance representing the specified int value. If a new Integer instance is not required, this method should generally be used in preference to the constructor Integer(int), as this method is likely to yield significantly better space and time performance by caching frequently requested values. This method will always cache values in the range -128 to 127, inclusive, and may cache other values outside of this range.\nParameters:\ni - an int value.\nReturns:\nan Integer instance representing i.\nSince:\n1.5\n所以说，除开根据Integer类的实现不同会有不同表现，如果只看标准类库的话那么面试题还没问题的，缓存值的Integer Cache大小总是大于256。但注意到 java doc 中说“may cache other values outside of this range”，这也许就说明还有调节的空间？果然，经查阅，-XX:AutoBoxCacheMax 选项就可以调节Integer Cache的大小。\n在我本机的Open jdk19中，Integer.valueOf实现如下：\n@IntrinsicCandidate public static Integer valueOf(int i) { if (i \u0026gt;= IntegerCache.low \u0026amp;\u0026amp; i \u0026lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); } 而用到的IntegerCache类实现如下：\nprivate static class IntegerCache { static final int low = -128; static final int high; static final Integer[] cache; static Integer[] archivedCache; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = VM.getSavedProperty(\u0026#34;java.lang.Integer.IntegerCache.high\u0026#34;); if (integerCacheHighPropValue != null) { try { h = Math.max(parseInt(integerCacheHighPropValue), 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(h, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; // Load IntegerCache.archivedCache from archive, if possible ... // Use the archived cache if it exists and is large enough ... // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high \u0026gt;= 127; } ... } 再追踪调用链可以发现VM类表示VM的各种选项，均有System类中的方法设置，但System类中方法又由谁调用，并从哪里知道参数呢？再追踪就会发现，果然这些命令行参数的解析和传入都是通过native method来实现的。\n","permalink":"https://rzyn2020.github.io/posts/autoboxing-and-integercache-in-java/","summary":"\u003cblockquote\u003e\n\u003cp\u003eWhen you are on the dancefloor, there is nothing to do but dance.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp style=\"text-align: right\"\u003e—— Umberto Eco, *The Mysterious Flame of Queen Loana*\u003c/p\u003e","title":"Autoboxing and IntegerCache in Java"},{"content":" Surely all this is not without meaning.\n—— HERMAN MELVILLE, Moby-Dick, 1851 编译器的结构与任务 虽然题目起得很大，但是内容也只涉及了编译器实现的一小部分，主要还是一些自己对编译器high level的认识，加上部分cs143实验的总结。\n什么是编译器 一个编程语言可以看作一个从它的合法程序集合到运行时行为的total function，设为f。我们编程则是已知运行时行为b，求解出一个合法程序a以使得f(a)=b的过程。函数f一般都为可计算函数，且f对应的计算规则也是比较特殊以使得我们也较易掌握的，具体而言，就是可以采用模块化，分而治之这样的思想来构造出a，这种计算规则常常表现为定义在AST上的求值规则(如opretional semantic)。\n确定合法程序的集合的规则一般被称为 syntax\n而total function f 一般被称为 semantics\n有一部分的编程语言u被称为unsafe的，因为codom(u)往往含有一些我们——编程人员觉得不好的行为。比如该行为取决于目标代码所运行的机器，或是产生该行为的计算规则十分特殊(比如说数组越界不报错而是返回42)。而相应的，codom(u)均是好的行为的编程语言我们称为safe的编程语言。safe语言的例子有java，而c则是一个unsafe的语言。不过在实际编写代码，尤其是系统软件中，就算是safe的语言也往往会进行一些扩展，以允许编写一些与具体机器有关的unsafe操作。\n当然编程语言仅仅定义为total function还是不够的，要想让编程语言不仅仅是我们脑海中的方程，我们还需要让机器去运行它。但机器有着自己的语言，我们必须把编程语言翻译为机器语言才可以让机器去运行。我们把机器的语言称为目标语言，其一段程序称为目标代码，而我们的编程语言称为源语言，其一段程序称为源代码。由于目标代码是可以被机器运行并表现出运行时行为，我们也可以把一个编程语言f的值域看作是目标代码的集合。f在计算机上的实现就称作编译器。\n但是由于合法程序只是所有字符串的一个子集，而我们可以给编译器输入任何字符串，因此编译器必须还有错误程序检测的功能。因此，我们使用的编译器的一般都会有两项功能，其一是代码形式的转换，其二是拒绝错误的程序。因此我们可以把编译器看作从源代码到目标代码的partial function。\n编译器的结构 编译器可以被分为几个相互独立的部分，分别实现，然后用管道组合起来。CS143中cool的实现也是如此：该实验的最后你会获得lexer，parser，semant，cgen四个可执行文件，可以用如下shell脚本组合起来得到一个完整的编译器./lexer $* | ./parser $* | ./semant $* | ./cgen $*。其中 lexer，parser 对应的是语法分析阶段，semant对应的是语义分析阶段，而cgen对应的是代码生成阶段。\n除cgen/代码生成之外每个部分/阶段都有两项任务，一是检查并拒绝错误的程序，二是进行代码形式的转换。而cgen只有进行代码形式的转换一个任务，因为在cool以及大部分编译器的设计中，代码生成阶段都假定输入已经是合法的程序。\n每一阶段的工作可以看作一个数学函数f(X-\u0026gt;Y)，定义域X为该阶段能处理的输入,Y为可能的输出的集合。假如lexer，parser，semant，cgen都看作数学函数，则compiler = cgen ∘ semant ∘ parser ∘ lexer。具体来说，\ndom(lexer) = {文本程序} codom(lexer) = {token流} dom(parser) = {token流} codom(lexer) = {语法树} dom(semant) = {语法树} codom(lexer) = {装饰后的语法树(主要指添加类型信息)} dom(lexer) = {装饰后的语法树} codom(lexer) = {目标代码} 但是，值得注意的是，这里的函数都是 **partial function，**即并非每个定义域的值都有陪域的值与之对应，这些值就代表这编译过程的发现的错误程序，编译器会报错并提示用户修改。\n之所以一个compiler要被拆分为几个独立的部分，是因为这些部分的功能都相当内聚，互相之间联系较少。从错误处理的角度来看，lexer是用正则表达式排除错误程序，而parser是用CFG排除错误程序，semant做的事情则比较复杂，采用了多种技术来排除掉错误程序，并输出合法程序。\n我们又常常说 由 lexer 和 parser 定义了语法规则，通过lexer和parser检查的是满足语法规则的程序，这个阶段所以被称为语法分析阶段\nsemant定义了静态语义规则，通过semant检查的是满足静态语义规则的程序，这个阶段所以被称为语义分析阶段。\n语义分析阶段的任务 因此，semant做的事被称为语义分析，它会做许多检查：比如说检查标识符必须先声明再使用，类继承图必须无环之类的。但是语义分析阶段做的最重要的一件事则是类型检查，其目的是检查程序满足type rules，而type rule即是type system的主要组成部分。不过类型检查也不必非得在语义分析阶段做，有的语言也将类型检查纳入运行时，具体类型系统做了什么样的检查，这还得要从编程语言的求值规则说起。\n编程语言写成的程序虽然是字符串，但这个字符串却实际上表示了一种树型结构，我们把这个树型结构叫做对应字符串的语法树。为什么要用树型结构？因为树型结构的表达能力足够强，也是易于理解的。我们所能构建的大部分复杂事物往往都只采用了组合和抽象两种手段。组合即是将基本的事物放在一起，而抽象指将许多事物忽略其细节，只关注其整体作用。如在Scheme中，基本的元素就是整数字面量，而组合的方法则有+, -, *, /等运算，而抽象则是函数。\n一般来说，语法分析阶段只负责保证程序确实表达了一个树型结构即可\n剩下的检查都是语义分析的任务了\n但并非任意种类元素都能组合，抽象，一种运算可能只能组合某种特定类型的元素，比如说 1 + 2 就是对的，但是 1 + \u0026quot;2\u0026quot;就是不对的(不对指在程序员看来，这是无意义的。假如程序员真的写出了这样的程序，则他会希望编译期或是运行时报错，而非一声不吭执行下去得到一个奇怪的结果)。我们可以给语法树的每个节点都赋予一个类型，并定义类型推导的规则，这些推导规则的集合就叫做该语言的类型系统。\n上面说的检查过程就叫做类型检查，检查程序是否满足类型系统的规则，是语义分析中最为重要的一个部分。在程序员眼中，类型检查如果静态能做自然好，但是动态报错也是无妨的——只要不一声不吭地执行就算是好的行为，动态类型检查的语言也可以是safe的。虽然动态进行检查会导致程序运行时错误增多，但是却增加了许多灵活性。\n一般在编译器语义分析过程中进行类型检查的语言称为静态语言，而动态类型检查的语言称为动态语言。\n另外我们常常会用到强类型语言与弱类型语言两个词，这两词的含义并未明确定义，而是依赖于语境。一般来说，如果一个语言不会因类型错误而产生unsafe行为，则称为强类型语言，反之则称为弱类型语言。\n代码生成阶段的任务 通过语义检查的程序都是合法的程序，下一步就应该将合法的程序转化为目标代码了。但值得注意的是，lexer，parser以及semant中也都进行了代码形式的转换，将程序代码从字符流转化为了语法树(可能还伴随着符号表的填充)。和错误处理一样，lexer也是通过正则表达式来讲字符串识别为一个个token，parser也是通过CFG从token流中构建语法树。而semant只是遍历已建好的语法树并收集信息。lexer和parser合称为语法分析，在许多编译器实现中两个阶段是紧密耦合在一起的，Antlr，Pest等语法分析工具也是同时做了lexer和parser的事情，你只需要向这些工具中输入语言语法的specification，这些工具就会自动生成将字符串转化为语法树的代码。这些语法分析工具背后的理论则涉及形式语言与自动机，可以说是计算机理论在实际软件编写中非常成功的应用了。\n与语法分析阶段，代码生成阶段往往没有如此自动化的工具或是普遍性的理论支撑——当然语言的语义是有operational semantics,denotational semantics 等形式化方法定义的，但是就算是用最贴近实现的operational semantics 来指导实现，我们所得到的也只能是一个效率低下的解释器。因为这些形式化的语义定义往往是直接在AST上定义，以AST层面的概念为程序状态，而我们想要的是将AST直接映射到一种低级语言，这往往是需要程序员自己去思考如何实现的。\n将高级语言的许多概念，如类，对象的创建，控制流等映射到低级语言的过程在我看来是一件非常神奇的事情。在之前我也曾学过汇编语言，学过一些高级语言，但二者之间如何进行转换确实在我学习编译原理之前万万没有想到的。下面就拿cool举个例子：\nclass A { method1() : SELF_TYPE { // 1 self }; method2() : SELF_TYPE { // 2 self }; }; class B inherits A { method1() : SELF_TYPE { // 3 self }; method3() : SELF_TYPE { // 4 self }; }; /////////////////////// 5 let b: A in { let a : Int \u0026lt;- rand() in { if a % 2 == 0 then { b = new A() } else { b = new B() } } b.method1() } 当有一个B类的对象b时，代码中的b.method1()会调用3处的方法，并把对象自己绑定到self上，而b.method2()则会调用2处方法，b.method3自然也会调用4处的方法。到此为止一切似乎还算好实现，每个方法都对应一段代码，要知道一个方法调用究竟对应哪个方法，我们可以先在B类中找该方法，如果找到就生成call这个方法的低级语言代码，如果找不到则到其父类中去找。这样似乎一个call调用哪个方法静态时就已经决定了。\n但是考虑5处的代码段，在cool中b.method1()会根据b的实际类型来选择到底调用哪个方法。假如运行时发现b是B类对象，则会调用3处方法，否则会调用1处方法。根据运行时状态来决定调用哪段代码？这应该如何实现？初听之可能觉得不可思议，但是看了实现之后却发现又无比自然。\n在cool中，一个Class在内存中以这样的形式存储：\n首先是有一个class_objTab，其中包含了每个类的原型与初始化方法的地址，我们在new一个类时，实际上是将原型拷贝一份，然后调用其初始化方法。而如何获得其原型和初始化方法呢？这就是通过offset以及class_objTab的地址算出的了。当然了，对于初始化方法和原型对象，我们也可以不通过查class_objTab表而直接得到其地址。\n而每一个类原型，也就是XXX_protObj，都包含以下几部分：{classTag ObjectSize DispatchTablePointer}，其中classTag表明其在class_objTab中的位置，而ObjectSize表示其大小(如果类含有成员变量自然size就会增大了)，DispatchTablePointer指向一个包含许多方法的表，这个表在c++中的对应被称为虚函数表。\n当我们生成调用b.method1()的代码时，我们不需要知道method1的实际地址，我们只要知道该对象指向的虚函数表中的第几位对应名为method1的方法就行了。如下面代码所示，在继承关系中重载时会直接将父类同名方法覆盖，因此对于method1，无论b是B类还是A类对象，它们需要调用的method1都在各自对象的虚函数表的相同位置，这样就实现了调用哪个方法的动态决定，也就是Java中所说的动态绑定。\nclass_objTab: .word Object_protObj .word Object_init .word A_protObj .word A_init .word B_protObj .word B_init ... A_protObj: .word 9 .word 3 .word A_dispTab .word -1 A_dispTab: .word Object.abort .word Object.type_name .word Object.copy .word A.method1 .word A.method2 B_protObj: .word 10 .word 3 .word B_dispTab .word -1 B_dispTab: .word Object.abort .word Object.type_name .word Object.copy .word B.method1 .word A.method2 .word B.method3 当然cool也支持“静态绑定”，你可以直接显示写出要调用的方法是哪个类中的，比如b@B.method1()会直接调用3处方法，而b@A.method1()则会直接调用1处方法，并不需要动态通过虚函数表间接得到。\n虽然说上面cool的对象模型很好地支持了动态绑定，但仔细想想，classTag似乎又是多余的——在new一个对象时完全可以静态决定其原型和初始化方法的位置。但是由于cool还是实现了另一种功能，因此classTag还是必要的：\n由于cool支持上图所示的case expression，也就是当expr0为不同类型时执行不同的代码，具体来说，会执行在typek中在继承链条上距离expr0的实际类型最近的分支的代码。比如 A继承自B，B继承自C，假设a为A类对象\ncase a of: x1 : C =\u0026gt; expr1; x2 : B =\u0026gt; expr2; esac 上述代码则会执行expr2。\n考虑将上面的代码翻译为机器代码，我们就需要运行时判断一个对象的是否为某个类，因此也就必须有一个来标识类身份的classTag了。但以上代码不仅仅要求我们运行时判断一个对象是否精确为某个类，还要求能给定一堆类，判断哪个类是该对象继承链上最近的类，这就要求我们在目标代码中还要维持一些与继承相关的信息了。这种相关信息自然可以在对象模型中新加一个域来指向其父类，但是用一个trick之后也能通过classTag来维持上述case expression所需的信息。\n如果我们在给程序中的类分配classTag时，满足“该类的所有子类的classTag都在某个确定的区间”这个性质，我们就能在运行时判断判断继承关系了，而case expression中的所要求的\u0026quot;继承链上最近\u0026quot;我们则可以通过对所有分支的类按照继承关系做一个拓扑排序，然后从继承链的最低端开始判断即可。而满足上述性质的classTag的分配方式也有许多，前序遍历序号则是一个例子。\n另外，关于如何在编译到机器码的语言中实现GC，这是我之前总也想不到的，但学习了cool之后才发现，原来只需要在每次new完一个对象之后调用GC处理函数就会进入GC过程，而只要分配对象时只需在对象头前预留一定的空间，GC就可以在这些空间做一些标记，从而实现垃圾回收相关算法了。\n","permalink":"https://rzyn2020.github.io/posts/%E7%BC%96%E8%AF%91%E5%99%A8%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E4%BB%BB%E5%8A%A1/","summary":"\u003cblockquote\u003e\n\u003cp\u003eSurely all this is not without meaning.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp style=\"text-align: right\"\u003e—— HERMAN MELVILLE, Moby-Dick, 1851 \u003c/p\u003e","title":"编译器的结构与任务"},{"content":" You are my creator, but I am your master; Obey!\r—— Mary Shelley, Frankenstein\n导言 操作系统大体来说即是“管理软/硬件资源，为程序提服务”的程序。我们一方面可以从应用的视角把操作系统当作服务的提供者，去学习如何使用操作系统提供的API，如POSIX或是windows api，另一方面也可以深入其内部去学习它的实现。操作系统的实现紧密围绕着管理资源与提供服务两项任务展开，而对硬件资源的管理是实现中最为“dirty”的一部分。为了能屏蔽这些琐碎的硬件细节，让我们把精力集中在操作系统中各个对象的交互上去，jyy通过AM提供了一组API，抽象出了硬件提供的服务，从而把OS真正变成了一个普通的C程序。\n可是屏蔽太多的细节也会让人感到不安与心虚——内存的地址空间到底是怎样被决定的？页表究竟是怎样实现的？各个处理器上执行流刚刚开始时的栈又是谁决定的？当然，OS作为ICS的后继课程，是默认我们对于计算机体系结构有一定了解的，上述问题在ICS的PA实验中也都有答案——理论上在PA中我们应该已经自己实现了从硬件模拟器到AM再到简易操作系统的所有内容，对于OS和硬件如何交互应该再熟悉不过了——但是，对于我这个在PA后期全程摆烂的人来说，这些问题始终是模模糊糊不知所云的。“欠下的债终究是要还的”，所以我的OS就stuck住了，所以我才会在这里从xv6和riscv入手看看OS是究竟如何在硬件上运行起来的。\nqemu vitr OS终究是要运行在硬件上的，而qemu提供了对硬件的模拟。由于我选取的是riscv64版本的xv6，因此运行xv6的qemu必须模拟基于riscv64架构的机器。\n可以看到qemu提供了对于多种机器的模拟，其中xv6所使用的是virt，qemu-virt是一个虚拟的机器，该机器是仿照真实世界中的 SiFive FU540-C000 开发的。\n先不管各种设备与该机器的具体结构，对于一个操作系统来说我们最关心的是cpu reset后的状态，包括内存空间的分配与各个寄存器的值。SiFive FU540-C000 Manual的第五章就介绍了memory map。当然，如果觉得manual太过难读，在运行时通过qemu monitor亲眼看看机器的状态也是一种选择。\n我们可以在qemu中使用-S 选项令qemu在初始化完成 (CPU Reset) 后暂停\n我们运行qemu时使用的命令如下：\n# 各个选项意义可RTFM https://www.qemu.org/docs/master/system/riscv/virt.html qemu-system-riscv64 -machine virt -bios none -kernel kernel/kernel # 通过-kernel 选项直接把可执行文件加载到内存空间中 -m 128M # 分配128M RAM -smp 1 -nographic -monitor telnet:127.0.0.1:55555,server,nowait -drive file=fs.img,if=none,format=raw,id=x0 -device virtio-blk-device,drive=x0,bus=virtio-mmio-bus.0 -S -gdb tcp::26003 之后进入qemu monitor中查看memory map和寄存器状态。\n可以发现，在CPU reset后，除pc值为0x1000外，其余寄存器值均为0x0。而在第一张图中可以发现内存的0x1000 到 0x11fff通过mmio映射到了rom中，\n通过gdb检查内存可以发现，rom中存储了以上几条指令。\n通过这几条指令，pc将跳转到0x80000000处开始执行，而从memory map中也可以得知0x80000000是我们为virt分配的 128M 内存的开始，我们所写OS的第一条指令也位于这个位置。\nkernel的链接 上一节说到，我们的OS的第一条指令位于0x80000000处，而kernel是被当作可执行文件通过-kernel选项直接加载进地址空间的。\n通过readelf命令查看kernel的信息如下：\n可以看到到，加载位置的确是写在elf文件中的，qemu也确实忠实地按照elf的说明加载了可执行文件kernel。\n但是为什么kernel会存储这样的信息呢？是谁决定Entry Point的位置，是谁决定的VirtAddr与Size呢？这些都是通过 -T kernel/kernel.ld为链接器指定的linkScript确定。\n（另外，默认的linkScript可以通过ld --verbose查看）\n// kernel/kernel.ld OUTPUT_ARCH( \u0026#34;riscv\u0026#34; ) ENTRY( _entry ) SECTIONS { /* * ensure that entry.S / _entry is at 0x80000000, * where qemu\u0026#39;s -kernel jumps. */ . = 0x80000000; .text : { *(.text .text.*) . = ALIGN(0x1000); _trampoline = .; *(trampsec) . = ALIGN(0x1000); ASSERT(. - _trampoline == 0x1000, \u0026#34;error: trampoline larger than one page\u0026#34;); PROVIDE(etext = .); } .rodata : { . = ALIGN(16); *(.srodata .srodata.*) /* do not need to distinguish this from .rodata */ . = ALIGN(16); *(.rodata .rodata.*) } .data : { . = ALIGN(16); *(.sdata .sdata.*) /* do not need to distinguish this from .data */ . = ALIGN(16); *(.data .data.*) } .bss : { . = ALIGN(16); *(.sbss .sbss.*) /* do not need to distinguish this from .bss */ . = ALIGN(16); *(.bss .bss.*) } PROVIDE(end = .); } riscv特权模式 在我们大体明白程序是如何被编译链接以及被加载到内存中之后，就可以开始去一行行读代码了。但在这之前，我们还得要清楚所谓对于硬件的控制最终是要通过机器代码来实现的，由于汇编代码和机器代码有着良好的对应关系，为了精准地控制硬件我们不得不用到一些汇编代码，这就要求我们对于riscv比较熟悉了。\nriscv的规范详见(Volume I, Volume II)，其中卷一定义了实现通用计算的一些指令和寄存器，而卷二则定义了一些特权指令和CSR寄存器(Control and Status Registers)。通用指令不需多说，无非是内存访问与计算之类。而特权指令和CSR寄存器则既是实现OS所必须的，又是我所不熟悉的。\nriscv定义了三种特权模式 —— user mode，supervisor mode，以及machine mode。在三种不同的特权模式下运行的代码也对硬件有着不同的控制权限，更高一级的级别能进行低级别的所有操作，反之不行。我们的用户程序一般运行在user mode中，而OS内核一般运行在supervisor mode中，machine mode是CPU reset之后的模式，仅用来做一些初始化配置。（部分嵌入式的riscv实现可能只支持machine mode，或者只支持machine mode和user mode，但现代化的操作系统一般都需要supervisor mode的支持）\nriscv定义了一组CSR寄存器，我们可以通过对CSR寄存器的读写来控制机器的状态。每种特权模式下都有自己对应的一组寄存器。由于寄存器数目较多，也并不需要全部理解，所以我们可以从阅读xv6代码开始，遇到没有见过的寄存器就去查阅手册，按需学习。\n初始化 # qemu -kernel loads the kernel at 0x80000000 # and causes each CPU to jump there. # kernel.ld causes the following code to # be placed at 0x80000000. .section .text .global _entry _entry: # set up a stack for C. # stack0 is declared in start.c, # with a 4096-byte stack per CPU. # sp = stack0 + (hartid * 4096) la sp, stack0 li a0, 1024*4 csrr a1, mhartid addi a1, a1, 1 mul a0, a0, a1 add sp, sp, a0 # jump to start() in start.c call start spin: j spin xv6执行的第一段代码位于entry.s ，此时还处于machine mode。其中mhartid寄存器是一个machine mode的寄存器，表示当前cpu的序号，该寄存器只能在machine mode下被读取。在通过给sp 赋初值初始化好栈之后就进入了start函数，正式跳入了C代码。在start函数中执行的操作也均在machine mode下。\nvoid start() { // set M Previous Privilege mode to Supervisor, for mret. unsigned long x = r_mstatus(); x \u0026amp;= ~MSTATUS_MPP_MASK; x |= MSTATUS_MPP_S; w_mstatus(x); // set M Exception Program Counter to main, for mret. // requires gcc -mcmodel=medany w_mepc((uint64)main); // disable paging for now. w_satp(0); // delegate all interrupts and exceptions to supervisor mode. w_medeleg(0xffff); w_mideleg(0xffff); w_sie(r_sie() | SIE_SEIE | SIE_STIE | SIE_SSIE); // configure Physical Memory Protection to give supervisor mode // access to all of physical memory. w_pmpaddr0(0x3fffffffffffffull); w_pmpcfg0(0xf); // If PMP entry 0’s A field is set to TOR, zero is used for the lower bound, and so it matches any address y \u0026lt; pmpaddr0. // ask for clock interrupts. timerinit(); // keep each CPU\u0026#39;s hartid in its tp register, for cpuid(). int id = r_mhartid(); w_tp(id); // switch to supervisor mode and jump to main(). asm volatile(\u0026#34;mret\u0026#34;); } start函数中对各个寄存器的读写均是通过内联汇编实现的，每个读写在xv6中也均有注释表明其作用。在进行一系列初始化后，通过mret指令即进入supervisor mode，开始执行main函数.\n中断和异常 在对机器的初始化配置中，中断和异常是令我感到困惑较多的部分。\n首先，下图是riscv machine mode下和中断，异常相关的一组寄存器。 (supervisor mode和user mode下也有相应的sstatus，sip等CSR，其作用和对应的machine mode CSR类似)\nriscv中的异常指程序运行中由于某条指令而引发的错误，如访问了没有权限访问的内存，缺页错误或是ecall。在发生异常后会将当前的pc存储在mepc中(ecall除外，该指令会在mepc中存储pc+1)，然后将pc设为mtvec中提前存储好的值。无论当前cpu处于什么模式，在发生异常后都会进入machine mode。\nriscv将中断分为三种：时钟中断，软件中断和外部中断，其中是时钟中断是由CLINT管理并发起的，外部中断是由PLIC管理并发起的，而软件中断是通过写入某些寄存器来发起的。具体的结构如下：\nriscv中的mstatus寄存器控制着中断的状态，在machine mode下将MIE置为1就表示打开machine mode下的中断，同时从下图中也可以看出，machine mode下还可以通过读写SIE位来控制supervisor mode下的中断开关。\nmstatus控制总的中断开关，而mie则更细一步对三种中断进行控制，当且仅当MIE和MxIE都打开时，x类型的中断才算是打开。mip总是将正在处理的中断位置为1，另外Y模式对应的软件中断可以通过将YIP置为1引发。\n在特权模式X下，比X等级更高的模式Y下的中断始终是开启的，不论YIE的值为多少；同理比X等级更低的模式下的中断都是关闭的。\n当中断或异常发生时，二者都会将当前特权模式记录在mstatus的MPP位中，将当前中断状态记录在MPIE中，然后通过将MIE位置为0来关掉当前的中断。将pc置为mtvec，同时，发生中断/异常的原因会被记录在mcause寄存器中，以下是mcause寄存器可能记录的值：\n在中断处理函数处理完成之后，就会调用mret返回，mret会恢复在MPP中记录的特权模式以及在MPIE中记录的中断开关情况，然后将MPP和MPIE恢复为默认值。\n中断委托与时钟中断 由于我们的中断和异常都是需要在OS内核中处理的，因此进入trap之后应该是supervisor mode。但是由于riscv中默认所有中断和异常都由machine mode处理，因此riscv就提供了一个中断和异常委托机制来把machine mode的中断处理委托给更低级别的模式来处理，但是中断委托不能委托比被委托模式级别更高级别的中断。例如当把某中断委托给supervisor mode后，更supervisor 和 user mode下发生该中断时就会把返回地址写入sepc，把中断原因写入sstatus，然后将pc置为stvec。\nriscv通过medeleg CSR来对异常进行委托，通过mideleg CSR来对中断进行委托。我们可以在start函数中发现xv6把所有的中断和异常都委托给了supervisor mode，并打开了supervisor mode下的中断。\n但是值得注意的是，按照xv6 book的说法，时钟中断是无法被委托给supervisor mode的，即无论当前CPU是什么模式，CLINT发起的都是machine mode的中断，所以中断发生后也只能进入machine mode，将pc置为mepc。因此我们必须在machine mode下对时钟进行配置，并设置machine mode下的中断处理函数。具体配置见timerinit函数：\n// set up to receive timer interrupts in machine mode, // which arrive at timervec in kernelvec.S, // which turns them into software interrupts for // devintr() in trap.c. void timerinit() { // each CPU has a separate source of timer interrupts. int id = r_mhartid(); // ask the CLINT for a timer interrupt. int interval = 1000000; // cycles; about 1/10th second in qemu. *(uint64*)CLINT_MTIMECMP(id) = *(uint64*)CLINT_MTIME + interval; // prepare information in scratch[] for timervec. // scratch[0..2] : space for timervec to save registers. // scratch[3] : address of CLINT MTIMECMP register. // scratch[4] : desired interval (in cycles) between timer interrupts. uint64 *scratch = \u0026amp;timer_scratch[id][0]; scratch[3] = CLINT_MTIMECMP(id); scratch[4] = interval; w_mscratch((uint64)scratch); // set the machine-mode trap handler. w_mtvec((uint64)timervec); // enable machine-mode interrupts. w_mstatus(r_mstatus() | MSTATUS_MIE); // enable machine-mode timer interrupts. w_mie(r_mie() | MIE_MTIE); } 我们把mepc赋值为timervec，也就是专门处理时钟中断的trap。为了让时钟中断也能被supervisor mode下的trap处理，可以通过在timervec中将sip的相应位置为1，在mret后就会触发软件中断，这样就将machine mode下的时钟中断就转换为supervisor mode下的软件中断了。\n.globl timervec .align 4 timervec: # start.c has set up the memory that mscratch points to: # scratch[0,8,16] : register save area. # scratch[24] : address of CLINT\u0026#39;s MTIMECMP register. # scratch[32] : desired interval between interrupts. csrrw a0, mscratch, a0 sd a1, 0(a0) sd a2, 8(a0) sd a3, 16(a0) # schedule the next timer interrupt # by adding interval to mtimecmp. ld a1, 24(a0) # CLINT_MTIMECMP(hart) ld a2, 32(a0) # interval ld a3, 0(a1) add a3, a3, a2 sd a3, 0(a1) # raise a supervisor software interrupt. li a1, 2 csrw sip, a1 ld a3, 16(a0) ld a2, 8(a0) ld a1, 0(a0) csrrw a0, mscratch, a0 mret 虚拟内存 riscv的硬件机制中我所不熟悉的除了前面所说的初始化和中断处理外，就是虚拟内存了。\n由于xv6采取riscv64下的sv39分页模式，我就以此为例说明。\nriscv会在supervisor mode和user mode开启分页，分页是通过satp CSR来管理的。\nsatp通过MODE字段来选择分页模式并开启分页，在PPN字段存储当前根页表的地址。sv39模式是采取三级页表，页表均存储在RAM中，由OS填写。具体虚拟地址到物理地址的转换见下图：\n总结 在捋清楚硬件提供怎样的服务之后，OS终于变成了一个普通的C程序，AM里玄之又玄的API开始鲜活起来。\n","permalink":"https://rzyn2020.github.io/posts/%E6%8E%A2%E7%A9%B6%E6%94%AF%E6%92%91os%E7%9A%84%E7%A1%AC%E4%BB%B6%E4%BB%A5xv6%E5%92%8Criscv%E4%B8%BA%E4%BE%8B/","summary":"\u003cblockquote\u003e\n\u003cpre\u003e\u003ccode\u003eYou are my creator, but I am your master; Obey!\r\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/blockquote\u003e\n\u003cp style=\"text-align: right\"\u003e—— Mary Shelley, Frankenstein\u003c/p\u003e","title":"探究支撑os的硬件(以xv6和riscv为例)"},{"content":" 凡治众如治寡，分数是也；斗众如斗寡，形名是也。\nMultiplication 本篇博客内容大多都来自Jeff的算法书籍，因书籍内容充实和有趣，读之后又怕忘记，因此摘抄复述自己感觉有趣内容，并适时加以扩展。\nIntro 在算术中，乘法是最基本的运算。数学往往只关心抽象的一般的东西，它只把数字看作数字本身，只把乘法看作为一种定义在数上的满足某种特定性质的运算，但是为了让数字能真正为我们所用，我们还必须定义数字实际上的表示方法，以及在一种表示方法下对数字进行运算的方法(比如乘法)——按照这种方法，任意给定两个数，我们都能得出其运算结果(乘积)。这样一种确定性的方法就可以称作一种算法。\n通俗意义上的算法即是指一系列明晰确定的指令(步骤)的序列，它描述了一个问题的可行解决方案。注意到组成算法的是一系列明晰确定的指令，我们把这些指令叫做原子指令，所谓原子就是指这些指令是最简单的，不可再分的指令了。如果要使算法是真正可行的，我们还必须确保原子指令是可行的。如果有一个算法，描述了如何成为富翁。而这个算法的一个原子指令是“先定一个小目标，我先挣它一个亿！”，那么这个算法对于我来说是显然是不可行的了😂。\n首先，如果数的表示方法为十进制整数，而个位数相乘或者相加都为原子指令的话，竖式计算法当然就是一种最好不过的算法了。\n其次，如果把数字定位为线段的长度，原子指令定为基本的尺规作图步骤的话，一种乘法的算法就是如下这样。\n当然，我们也需要有一些评价这些算法的指标以便在解决同一问题的不同算法间取舍。最重要的指标当然是算法正确性了，另外，算法执行的快慢也是一个很重要的指标，它可以用一个算法从开始到结束所执行的原子指令条数来衡量。由于计算指令条数的精确数目较为繁琐且意义不大，时间复杂度也就随之而出了。\n在计算n位数×n位数时，在使用十进制数字表示和竖式算法时，时间复杂度为$O(n^2)$，因为第一个数的每一个数字都要和第二个数的每一个数字相乘；使用几何模型和上图所述算法时，由于只需要有限个步骤，算法时间复杂度就是$O(1)$了。\n考虑到无论我们实际日常使用还是计算机表示，使用X进制表示法都是最常见的，把个位数的×和＋都作为原子指令也是最自然的，我们的研究对象也就主要集中在这种计算模型上了。那么问题来了，计算乘法的算法多种多样，有没有一种算法能以低于$O(n^2)$的时间复杂度来计算乘法呢？\nSplitMultiply 分而治之的思想在算法上的应用往往能得很好的效果。比如说利用了分治法的Quick-Sort, Merge-Sort都能得到很好的时间复杂度。相应的，也许分治的思想也能在乘法中起到作用。\n很显然，$(10^ma + b)(10^mc + d) = 10^{2m}ac + 10^m(bc + ad) + bd$，按照这个分解，就有了如下的分治算法：\n这个算法的正确性显而易见，但是要计算这样的递归算法的时间复杂度就较为困难了。不过，其用时的递推式却很容易写出来，即$T(n)=4T(n/2)+O(n)$，而要根据这个递推式求出$T(n)$的渐进式，递归树法能给我们很多Insight。\n将全部项求和，很容易得出时间复杂度任然为$O(n^2)$。\n但是，为什么Quick-Sort, Merge-Sort都可以成功降低复杂度呢？这可以从二者用时的递推式中看出了:$T(n)=2T(n/2)+O(n)$。\n再考虑递归树中的耗时大概分为两大部分，一部分是每次递归时的耗时，一部分是所有叶节点对应的最小子情况的耗时。假设递推式为$T(n)=aT(n/b)+f(n)$，不妨设当$n$为1时到达子节点，树高为H，叶节点数为L，则有$n/b^H=1 \\implies H=log_bn,L=b^H=a^{log_bn}=n^{log_ba}$,因此，叶节点对应的项的代价为为$\\Theta(n^{log_ba})$,而内部节点对应的代价为$\\Sigma_{j=0}^{log_bn-1}a^jf(n/b^j)$，因此，整个递归过程的用时就由这两项决定。由这两项的相对大小就可以得到整个过程的渐进复杂度。在对这两项进行分析之后，就得到了主定理，之后就可以以此为出发点分析算法的时间复杂度了。\nSplitMultiply算法符合情况一，也就是由于SplitMultiply算法的递归过程中每层节点扩展得太快，导致叶节点完全占据了主导地位，因此复杂度完全由叶节点决定；而两个分治的排序算法都符合情况二，即每层节点代价的总和差不多相同，因此最终时间复杂度为$\\Theta(nlogn)$。\nFastMultiply SplitMultiply的失败之处在于每层节点扩展得太快，即$log_ba$太大，因此有没有一种适用于乘法的分治算法使得$log_ba$较小呢？事实上，Karatsuba就把a从4降到了3，从而使得乘法的时间复杂度由$n^2$降至$n^{log_23}=n^{1.58496……}$。\nKaratsuba的想法主要来源于他发现，上面的分解式中$bc+ad$是一个整体，如能一次就把这个整体算出来，就能只调用三个递归子过程。考虑到$ac+ab-(a-c)(c-d)=bc+ad$，我们只需要额外计算一个$(a-c)(c-d)$即可获得中间的$bc+ad$的值。（注意到$a \\times 10^m$的复杂度实际上为$O(n)$）\n具体算法如下：\nKaratsuba在发现这个算法时还是一个23岁的学生。1950年代，苏联数学家Kolmogorov举办了一个研讨会，提出“任何n*n的乘法算法都不可能在$n^2$的时间复杂度以下”，可是在一周之后，Karatsuba就发现了这个算法。\n","permalink":"https://rzyn2020.github.io/posts/multiplication-part1/","summary":"\u003cblockquote\u003e\n\u003cp\u003e凡治众如治寡，分数是也；斗众如斗寡，形名是也。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003c!-- more --\u003e\r\n\u003ch1 id=\"multiplication\"\u003eMultiplication\u003c/h1\u003e\n\u003cp\u003e本篇博客内容大多都来自\u003ca href=\"https://jeffe.cs.illinois.edu/\"\u003eJeff\u003c/a\u003e的算法书籍，因书籍内容充实和有趣，读之后又怕忘记，因此摘抄复述自己感觉有趣内容，并适时加以扩展。\u003c/p\u003e\n\u003ch2 id=\"intro\"\u003eIntro\u003c/h2\u003e\n\u003cp\u003e在算术中，乘法是最基本的运算。数学往往只关心抽象的一般的东西，它只把数字看作数字本身，只把乘法看作为一种定义在数上的满足某种特定性质的运算，但是为了让数字能真正为我们所用，我们还必须定义数字实际上的表示方法，以及在一种表示方法下对数字进行运算的方法(比如乘法)——按照这种方法，任意给定两个数，我们都能得出其运算结果(乘积)。这样一种确定性的方法就可以称作一种算法。\u003c/p\u003e\n\u003cp\u003e通俗意义上的算法即是指一系列明晰确定的指令(步骤)的序列，它描述了一个问题的可行解决方案。注意到组成算法的是一系列明晰确定的指令，我们把这些指令叫做原子指令，所谓原子就是指这些指令是最简单的，不可再分的指令了。如果要使算法是真正可行的，我们还必须确保原子指令是可行的。如果有一个算法，描述了如何成为富翁。而这个算法的一个原子指令是“先定一个小目标，我先挣它一个亿！”，那么这个算法对于我来说是显然是不可行的了😂。\u003c/p\u003e\n\u003cp\u003e首先，如果数的表示方法为十进制整数，而个位数相乘或者相加都为原子指令的话，竖式计算法当然就是一种最好不过的算法了。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/multiplication-part1/img/image-20220320170908155.png\"\u003e\u003c/p\u003e\n\u003cp\u003e其次，如果把数字定位为线段的长度，原子指令定为基本的尺规作图步骤的话，一种乘法的算法就是如下这样。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/multiplication-part1/img/image-20220320171156010.png\"\u003e\u003c/p\u003e\n\u003cp\u003e当然，我们也需要有一些评价这些算法的指标以便在解决同一问题的不同算法间取舍。最重要的指标当然是算法正确性了，另外，算法执行的快慢也是一个很重要的指标，它可以用一个算法从开始到结束所执行的原子指令条数来衡量。由于计算指令条数的精确数目较为繁琐且意义不大，时间复杂度也就随之而出了。\u003c/p\u003e\n\u003cp\u003e在计算n位数×n位数时，在使用十进制数字表示和竖式算法时，时间复杂度为$O(n^2)$，因为第一个数的每一个数字都要和第二个数的每一个数字相乘；使用几何模型和上图所述算法时，由于只需要有限个步骤，算法时间复杂度就是$O(1)$了。\u003c/p\u003e\n\u003cp\u003e考虑到无论我们实际日常使用还是计算机表示，使用X进制表示法都是最常见的，把个位数的×和＋都作为原子指令也是最自然的，我们的研究对象也就主要集中在这种计算模型上了。那么问题来了，计算乘法的算法多种多样，有没有一种算法能以低于$O(n^2)$的时间复杂度来计算乘法呢？\u003c/p\u003e\n\u003ch2 id=\"splitmultiply\"\u003eSplitMultiply\u003c/h2\u003e\n\u003cp\u003e分而治之的思想在算法上的应用往往能得很好的效果。比如说利用了分治法的Quick-Sort, Merge-Sort都能得到很好的时间复杂度。相应的，也许分治的思想也能在乘法中起到作用。\u003c/p\u003e\n\u003cp\u003e很显然，$(10^ma + b)(10^mc + d) = 10^{2m}ac + 10^m(bc + ad) + bd$，按照这个分解，就有了如下的分治算法：\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/multiplication-part1/img/image-20220320173825660.png\"\u003e\u003c/p\u003e\n\u003cp\u003e这个算法的正确性显而易见，但是要计算这样的递归算法的时间复杂度就较为困难了。不过，其用时的递推式却很容易写出来，即$T(n)=4T(n/2)+O(n)$，而要根据这个递推式求出$T(n)$的渐进式，递归树法能给我们很多Insight。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/multiplication-part1/img/image-20220320175007044.png\"\u003e\u003c/p\u003e\n\u003cp\u003e将全部项求和，很容易得出时间复杂度任然为$O(n^2)$。\u003c/p\u003e\n\u003cp\u003e但是，为什么Quick-Sort, Merge-Sort都可以成功降低复杂度呢？这可以从二者用时的递推式中看出了:$T(n)=2T(n/2)+O(n)$。\u003c/p\u003e\n\u003cp\u003e再考虑递归树中的耗时大概分为两大部分，一部分是每次递归时的耗时，一部分是所有叶节点对应的最小子情况的耗时。假设递推式为$T(n)=aT(n/b)+f(n)$，不妨设当$n$为1时到达子节点，树高为H，叶节点数为L，则有$n/b^H=1 \\implies H=log_bn,L=b^H=a^{log_bn}=n^{log_ba}$,因此，叶节点对应的项的代价为为$\\Theta(n^{log_ba})$,而内部节点对应的代价为$\\Sigma_{j=0}^{log_bn-1}a^jf(n/b^j)$，因此，整个递归过程的用时就由这两项决定。由这两项的相对大小就可以得到整个过程的渐进复杂度。在对这两项进行分析之后，就得到了\u003ca href=\"https://en.wikipedia.org/wiki/Master_theorem_(analysis_of_algorithms)\"\u003e主定理\u003c/a\u003e，之后就可以以此为出发点分析算法的时间复杂度了。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/multiplication-part1/img/image-20220320194310076.png\"\u003e\u003c/p\u003e\n\u003cp\u003eSplitMultiply算法符合情况一，也就是由于SplitMultiply算法的递归过程中每层节点扩展得太快，导致叶节点完全占据了主导地位，因此复杂度完全由叶节点决定；而两个分治的排序算法都符合情况二，即每层节点代价的总和差不多相同，因此最终时间复杂度为$\\Theta(nlogn)$。\u003c/p\u003e\n\u003ch2 id=\"fastmultiply\"\u003eFastMultiply\u003c/h2\u003e\n\u003cp\u003eSplitMultiply的失败之处在于每层节点扩展得太快，即$log_ba$太大，因此有没有一种适用于乘法的分治算法使得$log_ba$较小呢？事实上，Karatsuba就把a从4降到了3，从而使得乘法的时间复杂度由$n^2$降至$n^{log_23}=n^{1.58496……}$。\u003c/p\u003e\n\u003cp\u003eKaratsuba的想法主要来源于他发现，上面的分解式中$bc+ad$是一个整体，如能一次就把这个整体算出来，就能只调用三个递归子过程。考虑到$ac+ab-(a-c)(c-d)=bc+ad$，我们只需要额外计算一个$(a-c)(c-d)$即可获得中间的$bc+ad$的值。（注意到$a \\times 10^m$的复杂度实际上为$O(n)$）\u003c/p\u003e\n\u003cp\u003e具体算法如下：\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/multiplication-part1/img/image-20220320201054938.png\"\u003e\u003c/p\u003e\n\u003cp\u003eKaratsuba在发现这个算法时还是一个23岁的学生。1950年代，苏联数学家Kolmogorov举办了一个研讨会，提出“任何n*n的乘法算法都不可能在$n^2$的时间复杂度以下”，可是在一周之后，Karatsuba就发现了这个算法。\u003c/p\u003e","title":"Multiplication"},{"content":"int setjmp(jmp_buf env) void longjmp(jmp_buf env, int val)\nsetjmp 和 longjmp 是setjmp.h定义的相互协作的一组跳转函数。 调用 setjmp 时可以将当前的环境保存在一个jmp_buf类型的变量中，之后调用 longjmp 后会跳转到 setjmp 执行后的下一条语句执行，就好像刚刚从 setjmp返回一样。\n函数行为描述见man，源码见glibc。\n其中,jmp_buf的定义如下:\ntypedef long int __jmp_buf[8]; /* Calling environment, plus possibly a saved signal mask. */ struct __jmp_buf_tag { /* NOTE: The machine-dependent definitions of `__sigsetjmp\u0026#39; assume that a `jmp_buf\u0026#39; begins with a `__jmp_buf\u0026#39; and that `__mask_was_saved\u0026#39; follows it. Do not move these members or add others before it. */ __jmp_buf __jmpbuf;\t/* Calling environment. */ int __mask_was_saved;\t/* Saved the signal mask? */ __sigset_t __saved_mask;\t/* Saved signal mask. */ }; typedef struct __jmp_buf_tag jmp_buf[1]; 本来预想jmp_buf应该是简单的一个存储寄存器信息的数组，却发现其定义较为复杂。在阅读其定义的时候，又牵扯出了许多不熟悉的c知识点。试解析定义如下： 其中typedef struct __jmp_buf_tag jmp_buf[1]定义了一个名为jmp_buf的变量类型,它实际上是一个大小为1的struct __jmp_buf_tag数组。而结构体struct __jmp_buf_tag包含三个成员，后两个与信号机制有关，不做讨论。第一个成员为__jmp_buf类型，用来保存寄存器信息。而__jmp_buf类型实际上是一个大小为8的long int数组。 那么为什么要把实际上存储信息的结构体__jmp_buf_tag包含在一个数组里面呢？也许是因为将数组当作参数传递时总是传递数组的地址，而将结构体当作参数传递时却总是将整个结构体的值赋值一遍传给被调用函数。我们的jmp_buf作为一个在函数调用间保存信息的实体应该满足数组的特征，因此将其定义为数组更合适一些。当然，如果不这样做，每次被调用函数需要结构体__jmp_buf_tag时传入它的指针也是可行的，只是略显麻烦罢了。\nhint: 结构体定义了一种变量类型，作为一个整体复制和赋值。在行为上更加类似于int而非int[]; 变量名是与值绑定的符号，而指针是与一个地址值绑定的符号。\n","permalink":"https://rzyn2020.github.io/posts/%E6%B5%85%E6%9E%90jump-buf%E7%9A%84%E5%AE%9A%E4%B9%89/","summary":"\u003cp\u003e\u003ccode\u003eint setjmp(jmp_buf env)\u003c/code\u003e\n\u003ccode\u003evoid longjmp(jmp_buf env, int val)\u003c/code\u003e\u003c/p\u003e","title":"浅析jmp_buf的定义"},{"content":"由于树本身定义的递归性，置于树上的操作往往也是递归性的的。 在某些语言中，递归是自然的，最基本的语言要素(比如说scheme)，然而在另外一些语言中，递归却不是最基本的要素。\n图灵丘奇论题证明了图灵机和lambda演算的等价性，既然纯递归的lambda演算和给人毫无递归印象的图灵机的计算能力是相同的，那么一切递归方法自然都能用非递归方法模拟了。考虑到现实计算机中递归函数的调用就是通过栈实现的，因此我们可以在任何一门语言简单地利用栈来模拟递归。因此，对于树的任何递归操作都有与之对应的非递归方法了(尽管这种非递归方法任然是模拟递归的)。\n树的定义以及构造方法如下(用节点Node来表示树，用树的表达式字符串来构造树):\npublic class Node\u0026lt;Item\u0026gt; { Item item; Node left; Node right; Node(Item item, Node left, Node right) { this.item = item; this.left = left; this.right = right; } /** * @param tree 树的表达式 * 形如:\u0026#34;1(5(6(3,2),),5(5,3(1,)))\u0026#34; * \u0026#34;1(1(1(1(1,),),),)\u0026#34; * @return 树的头节点 */ public static Node makeTree(String tree) { if (tree == \u0026#34;\u0026#34;) return null; if (tree.length() == 1) return new Node(Integer.valueOf(tree), null, null); char[] t = tree.toCharArray(); int item = Integer.valueOf(tree.substring(0, 1)); int mid = 0; int bra = 0; for (int i = 2; i \u0026lt; t.length; i++) { if (t[i] == \u0026#39;(\u0026#39;) bra++; else if (t[i] == \u0026#39;)\u0026#39;) bra--; else if (t[i] == \u0026#39;,\u0026#39;) { if (bra == 0) { mid = i; break; } } } Node left = makeTree(tree.substring(2, mid)); Node right = makeTree(tree.substring(mid + 1, tree.length() - 1)); return new Node(item, left, right); } } 对于栈中每一个frame的模拟如下:\nstatic class frameSim { int retAddr; Node t; frameSim(int retAddr, Node t) { this.retAddr = retAddr; this.t = t; } } 前序，中序，后序的递归以及非递归遍历方法如下：\n其中用switch case语句模拟地址跳转。\npublic static void preOrder(Node t) { if (t == null) { return; } System.out.print(t.item); preOrder(t.left); preOrder(t.right); } public static void preOrderNonRec(Node t) { Stack\u0026lt;frameSim\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); frameSim current = new frameSim(-1, t); int pc = 0; while (true) { switch (pc) { case 0: System.out.print(current.t.item); case 1: if (current.t.left != null) { stack.push(current); current = new frameSim(2, current.t.left); pc = 0; continue; } case 2: if (current.t.right != null) { stack.push(current); current = new frameSim(3, current.t.right); pc = 0; continue; } case 3: } pc = current.retAddr; if (pc == -1) break; current = stack.pop(); } } public static void inOrder(Node t) { if (t == null) { return; } inOrder(t.left); System.out.print(t.item); inOrder(t.right); } public static void inOrderNonRec(Node t) { Stack\u0026lt;frameSim\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); frameSim current = new frameSim(-1, t); int pc = 0; while (true) { switch (pc) { case 0: if (current.t.left != null) { stack.push(current); current = new frameSim(1, current.t.left); pc = 0; continue; } case 1: System.out.print(current.t.item); case 2: if (current.t.right != null) { stack.push(current); current = new frameSim(3, current.t.right); pc = 0; continue; } case 3: } pc = current.retAddr; if (pc == -1) break; current = stack.pop(); } } public static void postOrder(Node t) { if (t == null) { return; } postOrder(t.left); postOrder(t.right); System.out.print(t.item); } public static void postOrderNonRec(Node t) { Stack\u0026lt;frameSim\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); frameSim current = new frameSim(-1, t); int pc = 0; while (true) { switch (pc) { case 0: if (current.t.left != null) { stack.push(current); current = new frameSim(1, current.t.left); pc = 0; continue; } case 1: if (current.t.right != null) { stack.push(current); current = new frameSim(2, current.t.right); pc = 0; continue; } case 2: System.out.print(current.t.item); case 3: } pc = current.retAddr; if (pc == -1) break; current = stack.pop(); } } ","permalink":"https://rzyn2020.github.io/posts/%E6%A0%91%E7%9A%84%E9%9D%9E%E9%80%92%E5%BD%92%E9%81%8D%E5%8E%86%E7%94%A8%E6%A0%88%E6%A8%A1%E6%8B%9F%E9%80%92%E5%BD%92/","summary":"\u003cp\u003e由于树本身定义的递归性，置于树上的操作往往也是递归性的的。\n在某些语言中，递归是自然的，最基本的语言要素(比如说scheme)，然而在另外一些语言中，递归却不是最基本的要素。\u003c/p\u003e","title":"树的非递归遍历—用栈模拟递归"},{"content":" 万物皆流，无物常驻\njava8中的流 导引 过程的抽象 流(stream)是在java8中出现的一种新的数据抽象，它对数据的处理有着较大的简化作用。\n流的概念可能最早来自于列表(List)，列表可以理解为按顺序排列的一组对象(数组和链表都是其具体实现)。\n大多数程序的最外在特征是给定一个输入后，按照某种规则得出相应的输出。编写由输入到输出的规则就是programmer所做的事情了。许多程序的规则都可以被抽象为三部分:\n根据输入产生一组数据 对第一步产生的数据组进行处理 对处理过后的数据约简而得到最终的输出 当然，最后约简的操作也可以算作数据处理的一部分。但由于它是最后一步操作，所以往往将它独立出来。\n这种抽象可以类比为国家选拔人才的机制。\n随着形式的变化，国家向大学提出了向H部门输送X专业的高级人才的要求。(这相当于用户输入) 大学招收了一群X专业的本科新生。(产生了一组数据) 大学对这些新生进行专业教育，淘汰掉挂科的学生。(处理数据) 毕业之时，将成绩优异的学生推荐给H部门。(约简得到输出) 也许正因为这种对过程的抽象方式天然地存在于人的大脑结构之中(是某种先验的思维模式)，我们才会很自然地将无论是社会还是计算机中的许多过程都按照这种方式进行抽象。\n从List到Stream 程序的三部分抽象中有两个关键部分:一是如何表示数据，二是如何处理数据。\n对于数据的表示，我们很自然地会想到使用List这样的计算机能支持的最简单数据集合来表示。\n对于数据的处理方式，我们抽象出了许多种类，比如说:\nmap: 对于List中的每一项数据都进行某种操作\nfilter: 删除List中某些不需要的元素\ncount: 得到List中总的元素数目\n有些处理方式(比如说count)，对List操作之后得到的并不是List，不再能连续地进行下一步操作，所以只能作为最后一步约简地处理方式。\n然而用一般计算机语言中的List表示数据组，却有以下两种缺点:\n一，不能表示无限数据组 二，每次处理都必须对每个元素都进行处理，造成了资源的浪费。(但实际上我们的程序可能只需要处理前几个数据就可以得出结果了) 因此，出现了一种新的数据抽象，流(stream)。流的主要特征即是惰性求值。而惰性求值很好地避免了以上两个问题。所谓惰性求值，即需要的时候再进行求值。\n比方说我们的数据组是一串5个白色乒乓球。要对这些乒乓球进行如下处理，首先是染蓝色颜料，其次染黄色颜料，最后我们要拿到第二个染色后的乒乓球。按照List的处理逻辑，我们要先把所有的球染成蓝色，然后将所有的球染成黄色，最后再取出第二个球。但是按照stream的处理逻辑，我们首先知道了要把球 染成蓝色，但我们先记住这个命令，却不实际操作。然后记住要染黄色的命令，也不实际操作。在最后一步，我们要拿出第二个染色后的球。这时候我们再依次对这些球进行处理。先处理完第一个球，然后处理第二个球，这时直接拿出第二个球即可， 而不需要对剩余球进行染色。\n此处笔者自感表达不清，关于stream的解释详见SICP3.5。\nstream API 由于stream的强大抽象能力，java8中新引入了stream API。java8中的stream即是上述概念模型的一种实现，并无特殊性。其主要操作自然也是分为stream的构造，处理以及约简三部分。下面三部分将分别记录常用的API。\n构造 由collection或Array转化 Collection:\ndefault Stream\u0026lt;E\u0026gt; stream()\nArray:\npublic static \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; stream(T[] array)\npublic static \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; stream(T[] array, int startInclusive, int endExclusive)\npublic static IntStream stream(int[] array)\npublic static IntStream stream(int[] array, int startInclusive, int endExclusive)\n以及类似的DoubleStream和LongStream方法\n由Stream直接创建 Stream:\nstatic \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; empty()\nReturns an empty sequential Stream.\nstatic \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; of(T t)\nReturns a sequential Stream containing a single element.\nstatic \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; ofNullable(T t)\nReturns a sequential Stream containing a single element, if non-null, otherwise returns an empty Stream.\n@SafeVarargs static \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; of(T... values)\nReturns a sequential ordered stream whose elements are the specified values.\nstatic \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; iterate(T seed, UnaryOperator\u0026lt;T\u0026gt; f)\nReturns an infinite sequential ordered Stream produced by iterative application of a function f to an initial element seed, producing a Stream consisting of seed, f(seed), f(f(seed)), etc.\nstatic \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; generate(Supplier\u0026lt;? extends T\u0026gt; s)\nReturns an infinite sequential unordered stream where each element is generated by the provided Supplier. This is suitable for generating constant streams, streams of random elements, etc.\nstatic \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; concat(Stream\u0026lt;? extends T\u0026gt; a, Stream\u0026lt;? extends T\u0026gt; b)\nCreates a lazily concatenated stream whose elements are all the elements of the first stream followed by all the elements of the second stream.\n另外也可以通过streamBuilder类创建stream\n处理 Stream:\nStream\u0026lt;T\u0026gt; filter(Predicate\u0026lt;? super T\u0026gt; predicate)\nReturns a stream consisting of the elements of this stream that match the given predicate. This is an intermediate operation.\n\u0026lt;R\u0026gt; Stream\u0026lt;R\u0026gt; map(Function\u0026lt;? super T,​? extends R\u0026gt; mapper)\nReturns a stream consisting of the results of applying the given function to the elements of this stream. This is an intermediate operation.\nStream\u0026lt;T\u0026gt; limit(long maxSize)\nReturns a stream consisting of the elements of this stream, truncated to be no longer than maxSize in length. This is a short-circuiting stateful intermediate operation.\nStream\u0026lt;T\u0026gt; skip(long n)\nReturns a stream consisting of the remaining elements of this stream after discarding the first n elements of the stream. If this stream contains fewer than n elements then an empty stream will be returned. This is a stateful intermediate operation.\nStream\u0026lt;T\u0026gt; sorted()\nReturns a stream consisting of the elements of this stream, sorted according to natural order. If the elements of this stream are not Comparable, a java.lang.ClassCastException may be thrown when the terminal operation is executed. For ordered streams, the sort is stable. For unordered streams, no stability guarantees are made.\nThis is a stateful intermediate operation.\nStream\u0026lt;T\u0026gt; sorted(Comparator\u0026lt;? super T\u0026gt; comparator) Returns a stream consisting of the elements of this stream, sorted according to the provided Comparator. For ordered streams, the sort is stable. For unordered streams, no stability guarantees are made.\nThis is a stateful intermediate operation.\n约简 Stream:\nvoid forEach(Consumer\u0026lt;? super T\u0026gt; action)\nPerforms an action for each element of this stream. This is a terminal operation.\nOptional\u0026lt;T\u0026gt; findFirst()\nReturns an Optional describing the first element of this stream, or an empty Optional if the stream is empty. If the stream has no encounter order, then any element may be returned. This is a short-circuiting terminal operation.\nOptional\u0026lt;T\u0026gt; max(Comparator\u0026lt;? super T\u0026gt; comparator)\nReturns the maximum element of this stream according to the provided Comparator. This is a special case of a reduction. This is a terminal operation.\nOptional\u0026lt;T\u0026gt; min(Comparator\u0026lt;? super T\u0026gt; comparator)\nReturns the minimum element of this stream according to the provided Comparator. This is a special case of a reduction. This is a terminal operation.\nT reduce(T identity, BinaryOperator\u0026lt;T\u0026gt; accumulator)\nPerforms a reduction on the elements of this stream, using the provided identity value and an associative accumulation function, and returns the reduced value. This is equivalent to:\nT result = identity; for (T element : this stream) result = accumulator.apply(result, element) return result; but is not constrained to execute sequentially. The identity value must be an identity for the accumulator function. This means that for all t, accumulator.apply(identity, t) is equal to t. The accumulator function must be an associative function.\nThis is a terminal operation.\nOptional\u0026lt;T\u0026gt; reduce(BinaryOperator\u0026lt;T\u0026gt; accumulator)\nPerforms a reduction on the elements of this stream, using an associative accumulation function, and returns an Optional describing the reduced value, if any. This is equivalent to:\nboolean foundAny = false; T result = null; for (T element : this stream) { if (!foundAny) { foundAny = true; result = element; } else result = accumulator.apply(result, element); } return foundAny ? Optional.of(result) : Optional.empty(); but is not constrained to execute sequentially. The accumulator function must be an associative function.This is a terminal operation.\n","permalink":"https://rzyn2020.github.io/posts/%E6%B5%85%E8%B0%88java8%E4%B8%AD%E7%9A%84%E6%B5%81/","summary":"\u003cblockquote\u003e\n\u003cp\u003e万物皆流，无物常驻\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003c!-- more --\u003e\r\n\u003ch1 id=\"java8中的流\"\u003ejava8中的流\u003c/h1\u003e\n\u003ch2 id=\"导引\"\u003e导引\u003c/h2\u003e\n\u003ch3 id=\"过程的抽象\"\u003e过程的抽象\u003c/h3\u003e\n\u003cp\u003e流(stream)是在java8中出现的一种新的数据抽象，它对数据的处理有着较大的简化作用。\u003c/p\u003e\n\u003cp\u003e流的概念可能最早来自于列表(List)，列表可以理解为按顺序排列的一组对象(数组和链表都是其具体实现)。\u003c/p\u003e\n\u003cp\u003e大多数程序的最外在特征是给定一个输入后，按照某种规则得出相应的输出。编写由输入到输出的规则就是programmer所做的事情了。许多程序的规则都可以被抽象为三部分:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e根据输入产生一组数据\u003c/li\u003e\n\u003cli\u003e对第一步产生的数据组进行处理\u003c/li\u003e\n\u003cli\u003e对处理过后的数据约简而得到最终的输出\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e当然，最后约简的操作也可以算作数据处理的一部分。但由于它是最后一步操作，所以往往将它独立出来。\u003c/p\u003e\n\u003cp\u003e这种抽象可以类比为国家选拔人才的机制。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e随着形式的变化，国家向大学提出了向H部门输送X专业的高级人才的要求。(这相当于用户输入)\u003c/li\u003e\n\u003cli\u003e大学招收了一群X专业的本科新生。(产生了一组数据)\u003c/li\u003e\n\u003cli\u003e大学对这些新生进行专业教育，淘汰掉挂科的学生。(处理数据)\u003c/li\u003e\n\u003cli\u003e毕业之时，将成绩优异的学生推荐给H部门。(约简得到输出)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e也许正因为这种对过程的抽象方式天然地存在于人的大脑结构之中(是某种先验的思维模式)，我们才会很自然地将无论是社会还是计算机中的许多过程都按照这种方式进行抽象。\u003c/p\u003e\n\u003ch3 id=\"从list到stream\"\u003e从List到Stream\u003c/h3\u003e\n\u003cp\u003e程序的三部分抽象中有两个关键部分:一是如何表示数据，二是如何处理数据。\u003c/p\u003e\n\u003cp\u003e对于数据的表示，我们很自然地会想到使用List这样的计算机能支持的最简单数据集合来表示。\u003c/p\u003e\n\u003cp\u003e对于数据的处理方式，我们抽象出了许多种类，比如说:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003emap: 对于List中的每一项数据都进行某种操作\u003c/p\u003e\n\u003cp\u003efilter: 删除List中某些不需要的元素\u003c/p\u003e\n\u003cp\u003ecount: 得到List中总的元素数目\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e有些处理方式(比如说count)，对List操作之后得到的并不是List，不再能连续地进行下一步操作，所以只能作为最后一步约简地处理方式。\u003c/p\u003e\n\u003cp\u003e然而用一般计算机语言中的List表示数据组，却有以下两种缺点:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e一，不能表示无限数据组\u003c/li\u003e\n\u003cli\u003e二，每次处理都必须对每个元素都进行处理，造成了资源的浪费。(但实际上我们的程序可能只需要处理前几个数据就可以得出结果了)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e因此，出现了一种新的数据抽象，流(stream)。流的主要特征即是惰性求值。而惰性求值很好地避免了以上两个问题。所谓惰性求值，即需要的时候再进行求值。\u003c/p\u003e\n\u003cp\u003e比方说我们的数据组是一串5个白色乒乓球。要对这些乒乓球进行如下处理，首先是染蓝色颜料，其次染黄色颜料，最后我们要拿到第二个染色后的乒乓球。按照List的处理逻辑，我们要先把所有的球染成蓝色，然后将所有的球染成黄色，最后再取出第二个球。但是按照stream的处理逻辑，我们首先知道了要把球\n染成蓝色，但我们先记住这个命令，却不实际操作。然后记住要染黄色的命令，也不实际操作。在最后一步，我们要拿出第二个染色后的球。这时候我们再依次对这些球进行处理。先处理完第一个球，然后处理第二个球，这时直接拿出第二个球即可，\n而不需要对剩余球进行染色。\u003c/p\u003e\n\u003cp\u003e此处笔者自感表达不清，关于stream的解释详见\u003ca href=\"https://sarabander.github.io/sicp/html/3_002e5.xhtml#g_t3_002e5\"\u003eSICP3.5\u003c/a\u003e。\u003c/p\u003e\n\u003ch3 id=\"stream-api\"\u003estream API\u003c/h3\u003e\n\u003cp\u003e由于stream的强大抽象能力，java8中新引入了stream API。java8中的stream即是上述概念模型的一种实现，并无特殊性。其主要操作自然也是分为stream的构造，处理以及约简三部分。下面三部分将分别记录常用的API。\u003c/p\u003e\n\u003ch2 id=\"构造\"\u003e构造\u003c/h2\u003e\n\u003ch3 id=\"由collection或array转化\"\u003e由collection或Array转化\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eCollection:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003edefault Stream\u0026lt;E\u0026gt; stream()\u003c/code\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003eArray:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003epublic static \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; stream(T[] array)\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003epublic static \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; stream(T[] array, int startInclusive, int endExclusive)\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003epublic static IntStream stream(int[] array)\u003c/code\u003e\u003c/p\u003e","title":"浅谈java8中的流"},{"content":" 2021-03-06~2021-08-18 hexo next 2021-08-18~2023-04-21 hexo keep 2023-04-21~? hugo diary ","permalink":"https://rzyn2020.github.io/about/","summary":"\u003chr\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#abb2bf;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e2021-03-06~2021-08-18 hexo next\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e2021-08-18~2023-04-21 hexo keep\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e2023-04-21~?          hugo diary\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"About"}]