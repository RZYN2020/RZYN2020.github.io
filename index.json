[{"content":"在后端实习面试中，有 数据库，Java，网络，OS 四大考点，其中又以数据库考察最为频繁。数据库问题中，除了少部分范式相关理论，基本为 MySQL 问题。因此，在这里摘录相关知识点，做一个总结，既是为秋招做准备，也是总结找实习过程中的所学知识。\nb 站视频解析\n架构 MySQL 整体可分为 Server 层 和 存储引擎 层。Server 层处理客户连接，接收 SQL 语句，生成执行计划，并调用存储引擎 API 来获取 / 写入具体数据。每一个客户端连接都由一个线程来负责处理。每个 table 都可以设置不同的存储引擎。具体流程\n存储引擎自定义实现数据的物理，逻辑组织以及索引，事务等特性。（因此面试考察的问题几乎都属于存储引擎层）抽象存储引擎层 api 是通过抽象类 handler 来实现。a minimal sorage engine in c++\nThe current limitations of the storage API are not intrinsic aspects of MySQL/MariaDB or Postgres\u0026rsquo;s design. For both project there used to be no pluggable storage at all. We can imagine a future patch to either project that allows support for batched row reads and writes that together could make column-wise storage and vectorized execution more feasible.\nMySQL 采用插件式存储引擎，我们可以根据使用场景 选择合适的。最常用的也是默认的存储引擎为 InnoDB，它是唯一满足 ACID 特性事务的存储引擎。\nMaybe you want an in-memory storage layer so that you can quickly run integration tests. Maybe you want to switch between B-Trees (read-optimized) and LSM Trees (write-optimized) and unordered heaps (write-optimized) depending on your workload. Or maybe you just want to try a third-party storage library (e.g. RocksDB or Sled or TiKV).\n索引 B-tree 资源\n**在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表 **。又 InnoDB 使用了 **B+ 树索引模型 **，所以数据都是存储在 B+ 树中的。每一个索引在 InnoDB 里面对应一棵 B+ 树。\n聚簇索引是主键所在的索引，数据也存在其中。\n二级索引是初次之外的索引，查询后得到主键，其他信息需要到主索引中 “回表查询”。\n除此之外，也可以对多个键进行联合索引。联合索引的建立应该遵循最左前缀原则。\n而如果我们要查询的数据已经在索引中，避免了回表查询。这个索引就叫做覆盖索引。\n事务 事务的执行流程：\n事务指满足 ACID 特性的一组操作。\n一致性：数据库处于正确的状态\n原子性：或者成功，或者失败，没有中间状态\n隔离性：并发事务相互不影响\n持久性：断电内存数据丢失后可恢复\n实现原子性 -\u0026gt; undo log 每一条 SQL 通过执行器后，会在 undo log segment 中申请一个 undo log 页。然后根据 SQL 信息构造 undo log 内容，并写入磁盘，保证真正操作之前 undo log 完整。\nMySQL 采用 SEGMENT -\u0026gt; PAGE -\u0026gt; 具体记录 来管理内存\n每当 InnoDB 中需要修改某个 Record 时，都会将其历史版本写入一个 Undo Log 中，对应的 Undo Record 是 Update 类型。当插入新的 Record 时，还没有一个历史版本，但为了方便事务回滚时做逆向（Delete）操作，还是会写入一个 Insert 类型的 Undo Record。\nInsert Undo Record 仅仅是为了可能的事务回滚准备的，并不在 MVCC 功能中承担作用。因此只需要记录对应 Record 的 Key，供回滚时查找 Record 位置即可。\n其中 Undo Number 是 Undo 的一个递增编号，Table ID 用来表示是哪张表的修改。下面一组 Key Fields 的长度不定，因为对应表的主键可能由多个 field 组成，这里需要记录 Record 完整的主键信息，回滚的时候可以通过这个信息在索引中定位到对应的 Record。除此之外，在 Undo Record 的头尾还各留了两个字节用户记录其前序和后继 Undo Record 的位置。\n由于 MVCC 需要保留 Record 的多个历史版本，当某个 Record 的历史版本还在被使用时，这个 Record 是不能被真正的删除的。因此，当需要删除时，其实只是修改对应 Record 的 Delete Mark 标记。对应的，如果这时这个 Record 又重新插入，其实也只是修改一下 Delete Mark 标记，也就是将这两种情况的 delete 和 insert 转变成了 update 操作。再加上常规的 Record 修改，因此这里的 Update Undo Record 会对应三种 Type：TRX_UNDO_UPD_EXIST_REC、TRX_UNDO_DEL_MARK_REC 和 TRX_UNDO_UPD_DEL_REC。他们的存储内容也类似：\n除了跟 Insert Undo Record 相同的头尾信息，以及主键 Key Fileds 之外，Update Undo Record 增加了：\nTransaction Id 记录了产生这个历史版本事务 Id，用作后续 MVCC 中的版本可见性判断 Rollptr 指向的是该记录的上一个版本的位置，包括 space number，page number 和 page 内的 offset。沿着 Rollptr 可以找到一个 Record 的所有历史版本。 Update Fields 中记录的就是当前这个 Record 版本相对于其之后的一次修改的 Delta 信息，包括所有被修改的 Field 的编号，长度和历史值。 每个事务其实会修改一组的 Record，对应的也就会产生一组 Undo Record，这些 Undo Record 收尾相连就组成了这个事务的 Undo Log。除了一个个的 Undo Record 之外，还在开头增加了一个 Undo Log Header 来记录一些必要的控制信息，因此，一个 Undo Log 的结构如下所示：\n索引中的同一个 Record 被不同事务修改，会产生不同的历史版本，这些历史版本又通过 Rollptr 穿成一个链表，供 MVCC 使用。如下图所示：\ninsert undo log 在事务结束后即可回收，但 update undo log 需要支持 MVCC，不能直接删除。当某个历史版本已经确认不会被任何现有的和未来的事务看到的时候，就应该被清理掉。\n实现隔离性 -\u0026gt; MVCC 和锁 如果并发事务间不隔离就会产生以下问题：\n脏读：A 事务读取 B 事务未提交的数据 不可重复读：A 事务两次读取到不同的数据（B 事务修改且提交） 幻读：A 事务两次读取到数量不同的行数据（B 事务删除 / 增加行） InnoDB 中实现了四大隔离级别：\n隔离级别 脏读 不可重复读 幻读 READ-UNCOMMITTED √ √ √ READ-COMMITTED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × Innodb 通过锁机制和 MVCC 来实现各种隔离级别，其中锁又分为：\nLOCK_S 共享锁 LOCK_X 独占锁 LOCK_IS 共享意向锁（意向锁：在表上做一个标记） LOCK_IX 独占意向锁 LOCK_AUTO_INC 自增锁 按照粒度又分为 LOCK_TABLE 表锁，和 LOCK_REC 行锁。\n行锁又分为：\nLOCK_REC_NOT_GAP 精准行锁，锁住某一行 LOCK_GAP 锁住某两行间隙，防止插入 LOCK_ORDINARY next-key 锁 = LOCK_GAP + LOCK_REC_NOT_GAP LOCK_INSERT_INTENTION 插入意向锁，共享的 gap 锁 如果要加多个锁，会强制使用 两段锁协议 以保证可串行化。\n通过强制锁的申请和释放顺序，两段锁协议确保事务间的冲突操作（如读写、写写）遵循固定顺序，从而避免因操作交叉导致的数据不一致。例如，若事务 T1 和 T2 均遵守两段锁协议，它们的操作顺序会被锁定为 “T1 全加锁→T1 释放锁→T2 加锁”，等效于串行执行。\nMVCC 具体通过 undo log 和 read view 实现。undo log 存储了所有变更。一个事务的 read view 记录了当前活跃事务集合，最小事务 id，下一个事务 id，当前事务 id。读取时，沿着版本链，找到合适的版本。\n对于读未提交级别：\n读取时不做任何加锁处理，直接访问内存中的最新数据页版本。 更新时加 独占行锁，事务结束时释放。（其他事务不可以修改，但可读取） 对于读已体提交：\n每次查询构造一个新的 readview，解决脏读 更新时加 独占行锁，事务结束时释放。 对于可重复读：\n使用第一次查询时生成的 readview，解决脏读和不可重复读 更新数据时加 next-key 锁，解决了部分幻读问题 对于串行读：\n读取时使用共享表锁 更新时使用独占表锁 实现持久性 -\u0026gt; redo log，binlog redo log 是一种 WAL（Write-Ahead Logging）。当有一条记录需要更新时，InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面。（注意 undo 页可能一直在 buffer pool 中，从不实际写入磁盘）\n有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。\n那么我们需要什么样的 REDO 呢？首先，REDO 的维护增加了一份写盘数据，同时为了保证数据正确，事务只有在他的 REDO 全部落盘才能返回用户成功，REDO 的写盘时间会直接影响系统吞吐，显而易见，**REDO 的数据量要尽量少 **。其次，系统崩溃总是发生在始料未及的时候，当重启重放 REDO 时，系统并不知道哪些 REDO 对应的 Page 已经落盘，因此 REDO 的重放必须可重入，即 **REDO 操作要保证幂等 。最后，为了便于通过并发重放的方式加快重启恢复速度，REDO 应该是 ** 基于 Page 的，即一个 REDO 只涉及一个 Page 的修改。\n数据量小是 Logical Logging 的优点，而幂等以及基于 Page 正是 Physical Logging 的优点，因此 InnoDB 采取了一种称为 Physiological Logging 的方式，来兼得二者的优势。所谓 Physiological Logging，就是以 Page 为单位，但在 Page 内以逻辑的方式记录。\n举个例子，MLOG_REC_UPDATE_IN_PLACE 类型的 REDO 中记录了对 Page 中一个 Record 的修改，方法如下：\n（Page ID，Record Offset，(Filed 1, Value 1) … (Filed i, Value i) … )\n其中，PageID 指定要操作的 Page 页，Record Offset 记录了 Record 在 Page 内的偏移位置，后面的 Field 数组，记录了需要修改的 Field 以及修改后的 Value。\nMySQL 的 InnoDB 页大小为 16KB，而操作系统（如 Linux）的页大小为 4KB。InnoDB 将一个 16KB 的页写入磁盘时，需要拆分为 4 个操作系统页（4KB×4）。若在写入过程中发生崩溃（如断电），可能出现仅部分操作系统页成功写入的情况，导致 InnoDB 页数据损坏。这种损坏无法通过 Redo Log 恢复，因为 **Redo Log 记录的是操作而非完整页数据 **。\nInnoDB 中采用了 Double Write Buffer 的方式来通过写两次的方式保证恢复的时候找到一个正确的 Page 状态。它的作用是，在把页写到数据文件之前，InnoDB 先把它们写到一个叫 Double Write Buffer（双写缓冲区）的共享表空间内，在写 Double Write Buffer 完成后，InnoDB 才会把页写到数据文件的适当的位置。如果在写页的过程中发生意外崩溃，InnoDB 在稍后的恢复过程中在 Double Write Buffer 中找到完好的 page 副本用于恢复。\nDouble Write Buffer 能够保证找到一个正确的 Page 状态，我们还需要知道这个状态对应 REDO 上的哪个记录，来避免对 Page 的重复修改。为此，InnoDB 给每个 REDO 记录一个全局唯一递增的标号 LSN (Log Sequence Number)。Page 在修改时，会将对应的 REDO 记录的 LSN 记录在 Page 上（FIL_PAGE_LSN 字段），这样恢复重放 REDO 时，就可以来判断跳过已经应用的 REDO，从而实现重放的幂等。\nMySQL 中使用 binlog 做 主从库间的备份。\n最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统 —— 也就是 redo log 来实现 crash-safe 能力。\n这两种日志有以下三点不同。\nredo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是 “在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如 “给 ID=2 这一行的 c 字段加 1”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写” 是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 MySQL 采用两阶段提交(2PC) 机制，是为了解决 redo log（重做日志） 和 binlog（归档日志） 之间的逻辑一致性问题，确保事务的原子性和持久性。\n","permalink":"https://rzyn2020.github.io/posts/mysql%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/","summary":"\u003cp\u003e在后端实习面试中，有 数据库，Java，网络，OS 四大考点，其中又以数据库考察最为频繁。数据库问题中，除了少部分范式相关理论，基本为 \u003ca href=\"https://db-engines.com/en/ranking\"\u003eMySQL\u003c/a\u003e 问题。因此，在这里摘录相关知识点，做一个总结，既是为秋招做准备，也是总结找实习过程中的所学知识。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.bilibili.com/video/BV1mg411s7Ej/?spm_id_from=333.337.search-card.all.click\u0026amp;vd_source=226da368954a7c68d6b7e4bbdc91b2cd\"\u003eb 站视频解析\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"架构\"\u003e架构\u003c/h1\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250312144230196\" loading=\"lazy\" src=\"/posts/mysql%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/img/image-20250312144230196.png\"\u003e\u003c/p\u003e\n\u003cp\u003eMySQL 整体可分为 Server 层 和 存储引擎 层。Server 层处理客户连接，接收 SQL 语句，生成执行计划，并调用存储引擎 API 来获取 / 写入具体数据。每一个客户端连接都由一个线程来负责处理。每个 table 都可以设置不同的存储引擎。\u003ca href=\"https://tangocc.github.io/2018/10/11/mysql-sourcecode/\"\u003e具体流程\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"img\" loading=\"lazy\" src=\"/posts/mysql%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/img/post-mysql-client-server.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e存储引擎自定义实现数据的物理，逻辑组织以及索引，事务等特性。（因此面试考察的问题几乎都属于存储引擎层）抽象存储引擎层 api 是通过抽象类 \u003ca href=\"https://github.com/MariaDB/server/blob/11.4/sql/handler.h#L3200\"\u003ehandler\u003c/a\u003e 来实现。\u003ca href=\"https://notes.eatonphil.com/2024-01-09-minimal-in-memory-storage-engine-for-mysql.html\"\u003ea minimal sorage engine in c++\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe current limitations of the storage API are not intrinsic aspects of MySQL/MariaDB or Postgres\u0026rsquo;s design. For both project there used to be no pluggable storage at all. We can imagine a future patch to either project that allows support for batched row reads and writes that together could make column-wise storage and vectorized execution more feasible.\u003c/p\u003e","title":"MySQL 知识点总结 "},{"content":" cheat sheet Machine Learning Glossary 基本概念 什么是机器学习？\n机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。\n经验通常以\u0026quot;数据\u0026ldquo;形式存在，因此机器学习研究的主要内容，是关于在计算机上从数据中产生\u0026rdquo;模型\u0026quot;(model) 的算法，即\u0026quot;学习算法\u0026quot; (learning algorithm).\n记录的集合称为一个\u0026quot;数据集\u0026quot; (data set) ，其中每条记录是关于一个事件或对象的描述，称为一个\u0026quot;示例\u0026quot;(instance) 或\u0026quot;样本\u0026quot;(sample). 反映事件或对象在某方面的表现或性质的事项称为\u0026quot;属性\u0026quot;(attribute) 或\u0026quot;特征\u0026quot;(feature); 属性上的取值称为\u0026quot;属性值\u0026quot; (attribute value). 属性张成的空间称为\u0026quot;属性空间\u0026quot; (attribute space) 、\u0026quot;样本空间\u0026quot; (sample space)或\u0026quot;输入空间\u0026quot;。我们也把一个示例称为一个\u0026quot;特征向量\u0026quot; (feature vector).属性的数目被称为样本的\u0026quot;维数\u0026quot; (dimensionality).\n从数据中学得模型的过程称为\u0026quot;学习\u0026quot;(learning)或\u0026quot;训练\u0026quot; (training),这个过程通过执行某个学习算法来完成.训练过程中使用的数据称为\u0026quot;训练数据\u0026quot; (training data) ，其中每个样本称为一个\u0026quot;训练样本\u0026quot; (training sample),训练样本组成的集合称为\u0026quot;训练集\u0026quot; (training set). 学得模型对应了关于数据的某种潜在的规律，因此亦称\u0026quot;假设\u0026quot; (hypothesis); 这种潜在规律自身，则称为\u0026quot;真相\u0026ldquo;或\u0026rdquo;真实\u0026quot;(ground-truth) ，学习过程就是为了找出或逼近真相.\n学得模型后，使用其母行预测的过程称为\u0026quot;测试\u0026quot;(testing) ，被预测的样本 称为\u0026quot;测试样本\u0026quot; (testing sample).\n都有哪些机器学习算法？\n一份算法列表\n除如图所示的监督和非监督学习外，强化学习也是一类基本学习算法。\n什么是深度学习\n深度学习（Deep Learning）是机器学习的一个分支，是一种基于人工神经网络的算法模型。它模仿人类大脑处理信息的方式，采用多层神经网络从大量数据中提取特征并进行决策。深度学习在监督，非监督，强化学习中均有应用。\n对学习的理解 我们可以把学习过程看作一个在所有假设 (hypothesis)组成的空间中进行搜索的过程，搜索目标是找到与训练集\u0026quot;匹配\u0026quot;(fit) 的假设，即能够将训练集中的瓜判断正确的假设.假设的表示一旦确定，假设空间及其规模大小就确定了.\n可能有多个假设与训练集一致，即存在着一个与训练集一致的\u0026quot;假设集合\u0026quot;，我们称之为\u0026quot;版本空间\u0026quot; (version space).\n机器学习算法在学习过程中对某种类型假设的偏好，称为\u0026quot;归纳偏好\u0026quot; (inductive bias) ,或简称为\u0026quot;偏好\u0026quot;.任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看似在训练集上\u0026quot;等效\u0026quot;的假设所迷惑，而无法产生确定的学习结果.\n归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或\u0026quot;价值观\u0026quot;。\u0026ldquo;奥卡姆剃刀\u0026rdquo; (Occam\u0026rsquo;s razor)是一种常用的、自然科学研究中最基本的原则，即\u0026quot;若有多个假设与观察一致，则选最简单的那个。\n事实上，归纳偏好对应了学习算法本身所做出的关于\u0026quot;什么样的模型更好\u0026quot;的假设.在具体的现实问题中，这个假设是否成立，即算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能.\n不同的神经网络架构既体现了不同的假设空间，也体现了不同的归纳偏好\n假设空间：由架构定义，是模型可以表示的所有可能函数。\n理论上来说，一层全连接神经网络（具有足够的神经元和非线性激活函数）就能逼近任意连续函数。\n归纳偏好：由架构及其优化过程（例如损失函数、正则化策略）定义，是模型在有限数据下更倾向选择的函数。\n而同时，根据NFL 定理，没有任何一种学习算法在所有问题上都优于其他算法。\n直观来说：\n如果我们对问题分布一无所知，那么所有算法在这些问题上成功的概率是等价的。 要在特定任务中取得好性能，算法必须对任务的特定性质做出假设（即引入归纳偏好）。 模型评估和选择 经验误差与过拟合 在机器学习中，我们通常用以下指标来衡量模型的性能：\n错误率（Error Rate）：分类错误的样本数占样本总数的比例。例如，如果在 $m$ 个样本中有 $\\alpha$ 个样本被分类错误，则： $\\text{错误率} = \\frac{\\alpha}{m}$ 精度（Accuracy）：分类正确的样本数占样本总数的比例，与错误率互补： $\\text{精度} = 1 - \\text{错误率}$ 更广义地，我们把学习器的实际预测输出与样本的真实输出之间的差异称为“误差（Error）”：\n训练误差（Training Error）：学习器在训练集上的误差，又称为“经验误差（Empirical Error）”。 泛化误差（Generalization Error）：学习器在新样本上的误差。 我们的目标是构建一个泛化误差尽可能小的学习器。然而，由于事先无法得知新样本的分布，我们通常通过最小化经验误差来间接优化泛化误差。\n在实践中，我们希望学习器能对新样本做出准确预测，这要求它从训练数据中学到能适用于所有潜在样本的“普遍规律”。但模型的学习能力可能出现两种极端情况：\n过拟合（Overfitting）： 学习器对训练样本学得过于“精准”，甚至将训练样本中特有的噪声或不普遍的特性当成一般规律。这会导致模型对新样本的泛化性能下降。 欠拟合（Underfitting）： 学习器没有充分捕捉训练样本的一般规律，导致模型在训练集和测试集上的表现都不理想。 常见原因：\n过拟合：学习能力过强，模型复杂度过高。 欠拟合：学习能力不足，模型复杂度过低。 过拟合是机器学习中的一个普遍现象，无法彻底避免，但可以通过以下方法缓解或减小其影响：\n增加训练数据。 使用正则化（如 $L_1$ 或 $L_2$ 正则化）。 采用早停（Early Stopping）策略。 使用更简单的模型（降低复杂度）。 引入交叉验证（Cross-Validation）评估模型性能。 本质限制：过拟合无法完全避免，因为机器学习问题通常是 NP 难或更复杂的，而有效的学习算法必然是多项式时间内运行完成。要彻底避免过拟合，经验误差最小化就能找到最优解，而这在理论上等同于 $P=NP$（构造性地证明），目前尚未被证明。\n许多学习问题（如神经网络权重优化、支持向量机中的核参数选择等）涉及非凸优化问题，或需要在一个离散的组合空间中搜索最佳解。这类问题通常被证明为 NP难。\n在实际任务中，我们面临许多选择，包括：\n不同的学习算法（如决策树、支持向量机、深度学习）。 同一算法的不同参数配置（如正则化强度、学习率、网络结构）。 这引出了模型选择（Model Selection）问题： 如何选择一个泛化性能最好的模型？\n理想目标：直接评估候选模型的泛化误差，选择泛化误差最小的模型。 现实困境：泛化误差无法直接获得，训练误差又可能因过拟合而无法准确反映模型性能。\n评估方法 在机器学习中，模型的性能评估是关键的一环。为了衡量模型的泛化能力（即在新样本上的表现），我们通常通过实验测试来评估泛化误差。以下将介绍几种常用的数据集划分与评估方法，并探讨参数调节的技巧。\n在评估模型时，需将原始数据集 $D$（包含 $m$ 个样本）划分为训练集 $S$ 和测试集 $T$，即 $D = S \\cup T$ 且 $S \\cap T = \\emptyset$。训练集用于训练模型，测试集用于评估模型在未见样本上的表现。测试误差（Testing Error）被视为泛化误差的近似，假设测试样本与训练样本是从相同分布中独立同分布抽取的。\n1. 留出法（Hold-out Method） 留出法是最简单的评估方法，将数据集 $D$ 随机划分为训练集和测试集。例如，常用 2/3 至 4/5 的样本作为训练集，其余作为测试集。\n注意事项：\n数据划分需尽量保持分布一致性（如分类任务中保持类别比例），可通过分层采样（Stratified Sampling）实现。 单次划分的评估结果可能不稳定，因此需多次随机划分，取平均值作为最终评估结果。 权衡：\n训练集比例过大：模型更接近使用全数据训练的情况，但测试集过小可能导致结果不稳定。 测试集比例过大：测试结果更稳定，但训练集与全数据差距较大，可能影响评估结果的保真性（Fidelity）。 2. 交叉验证法（Cross-validation） 交叉验证将数据集 $D$ 分为 $k$ 个大小相等的互斥子集： $D = D_1 \\cup D_2 \\cup \u0026hellip; \\cup D_k$​，且 $D_i \\cap D_j = \\emptyset , (i \\neq j)$\n每次用 $k−1$ 个子集作为训练集，剩余一个子集作为测试集，重复 $k$ 次后取测试结果的均值作为最终评估结果。常见的 $k$ 值为 10，称为10 折交叉验证（10-fold Cross-validation）。\n优点：\n比留出法更稳定可靠。 可随机重复多次交叉验证（如 10 次 10 折交叉验证），进一步减少划分差异的影响。 特例：留一法（Leave-One-Out Cross-validation, LOO）\n令 $k=m$，即每次仅用一个样本作为测试集，其余样本作为训练集。 LOO 不受随机划分影响，训练集与全数据集非常接近，但计算复杂度较高，尤其在样本量较大时。 在理论上，多次留出法的随机划分结果有可能与交叉验证法某次划分完全一致\n3. 自助法（Bootstrapping） 自助法通过自助采样（Bootstrap Sampling）生成新的训练集。每次从原始数据集 $D$ 中随机抽取一个样本放入训练集，并将其放回，再次采样，重复 $m$ 次。采样后：\n$D′$ 为训练集，包含 $m$ 个样本，其中部分样本重复出现。 $D \\setminus D\u0026rsquo;$ 作为测试集，包含约 36.8% 的未被采样样本（概率计算如下）： $P(\\text{样本未被采样}) = (1 - \\frac{1}{m})^m \\approx e^{-1} \\approx 36.8%$ 特点：\n适用于数据量较小或难以划分的场景。 可生成多个训练集，用于集成学习等方法。 局限：\n改变了数据分布，可能引入估计偏差。 参数调节与最终模型选择 机器学习模型通常有多个参数需设定，不同参数配置会显著影响模型性能。调参（Parameter Tuning）是优化模型性能的重要步骤。\n常见调参方法：\n网格搜索（Grid Search）： 为每个参数设定取值范围和步长，逐一评估所有参数组合，选择性能最佳者。 计算复杂度较高，但可行性依赖于参数数量和候选值范围。 示例：3 个参数，每个参数有 5 个候选值，需训练 $5^3 = 125$ 个模型。 随机搜索（Random Search）： 随机采样参数组合，降低计算成本。 验证集（Validation Set）： 在训练数据中留出一部分作为验证集，用于模型评估和参数调节。 实际测试数据则保留用于最终测试。 常用的比例是训练集占 70%~80%，测试集占 20%~30%。再从训练集划分出验证集，常见比例是：训练集占原始数据的 60%~70%，验证集占 10%~20%。 验证集允许模型在开发过程中尝试不同的算法或参数设置，为模型选择和调参提供依据，而测试集不参与这个过程，以防止评估偏差。 神经网络 神经元模型 神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。神经网络中最基本的成分是神经元 (neuron)模型。\n（M-P 神经元）\n感知机和多层网络 感知机 (Perceptron) 由两层 神经元 组成，感知机能容易地实现逻辑与、或、非运算。\n史一般的，常见的神经网络是形如图所示的层级结构，每层神经元与下 层神经元全互连。神经元之间不存在同层连接，也不存在跨层连接。这样 的 神经网络结构通常称为\u0026quot; 多层前馈神经网络 \u0026quot; (multi-layer feedforward neural networks)\n反向传播算法 最常用的神经网络训练方法，详见： https://ml-cheatsheet.readthedocs.io/en/latest/backpropagation.html\n深度学习训练技巧 深度学习训练中的变量：\n数据集 模型结构（model bias） 超参数 epoch数目，batch大小等 loss function 优化算法 解决问题都得从这几个方面入手\n应对欠拟合问题 优化过程中，神经网络的目标是最小化损失函数。然而，优化过程可能会遇到多种挑战，尤其是在高维空间中。\nAdam算法结合了RMSProp和动量方法，是目前最常用的优化算法之一，能够有效提高训练速度，并避免梯度消失问题。最为常用。\n1. 局部最优与鞍点 局部最优解：损失函数在某个局部区域内达到最小值，这可能导致优化算法在该点停滞，从而影响模型的训练。 鞍点：在高维空间中，鞍点比局部最优解更多。鞍点的梯度为零，但它既不是最小值也不是最大值，优化算法容易被卡在这种点上。 解决鞍点：可以通过计算Hessian矩阵来判断一个点是否为鞍点。训练过程中使用动量和自适应学习率等技术可以帮助避免被卡住。 2. 小批量与噪声 小批量的优势：小批量训练时，由于每个批次的样本较少，噪声较大，这种噪声有助于模型跳出局部最小值，避免陷入“峡谷”中。实验证明，小批量训练有助于提高模型的泛化能力，并且在测试集上的表现通常更好。 劣势：小批量训练需要更多的时间来完成一个epoch，因为每个batch的训练时间较长。 大批量的劣势：大批量训练时，由于噪声较小，模型更容易停留在局部最小值，从而导致训练效果不佳。 3. 自适应学习率 学习率是控制梯度下降步伐的重要超参数。过大的学习率可能导致优化过程不稳定，过小的学习率则可能导致收敛缓慢。\n自适应学习率：使用Adagrad、RMSProp、Adam等自适应学习率算法，可以根据每个参数的梯度大小调整步伐，从而提高训练效率和收敛速度。 学习率调度：逐渐降低学习率（如通过学习率衰减或warm-up策略），能够避免震荡，帮助网络找到更精确的解。 4. 动量（Momentum） 动量方法通过结合当前的梯度和前一时刻的梯度信息，帮助网络在遇到局部最小值时继续向前推进，避免停滞在局部最小值。动量方法模仿物理中小球滚动的现象，在训练过程中具有较强的稳定性。\n5. 批归一化（Batch Normalization） 批归一化通过对每层输入进行标准化，消除不同维度间的差异，使得网络训练更加稳定。\n平坦化误差表面：批归一化能有效平滑损失函数，减少训练过程中出现不均匀的误差。 训练与测试的区别：在训练时，批归一化使用当前批次的数据进行标准化，而在测试时使用训练期间计算的均值和方差。 6. 激活函数的选择 激活函数对优化过程有着重要影响。不同的激活函数会决定网络的非线性能力，从而影响优化效果。\nReLU（Rectified Linear Unit）：ReLU是目前最常用的激活函数，能够有效避免梯度消失问题，并且计算效率高。 Sigmoid和Tanh：这些激活函数适用于浅层网络，但在深层网络中容易出现梯度消失问题，影响训练效果。 应对过拟合问题 过拟合是深度学习训练过程中常见的问题，特别是当模型在训练集上表现很好，但在测试集上性能较差时。为了减少过拟合，可以采用以下方法：\n1. 增加数据量 数据增强：通过对现有数据进行旋转、平移、缩放等变换，生成更多的样本，以减少模型对训练数据的依赖，从而提高泛化能力。 正则化技术：如L2正则化和dropout等，能够有效抑制模型的过拟合。 2. 正则化方法 L2正则化：通过在损失函数中增加惩罚项，迫使模型参数保持较小的值，从而避免模型过于复杂。 Dropout：在训练过程中随机丢弃一定比例的神经元，这样可以避免网络过度依赖某些特定神经元，从而提高泛化能力。 3. 提前停止（Early Stopping） 在训练过程中，通过监控验证集的损失，若验证集损失不再下降或开始上升，则提前停止训练。这样可以避免模型在训练集上过拟合。\n4. 更简单的模型结构 减小网络规模：使用较小的网络结构（例如减少网络层数或神经元数量），可以减少模型的复杂度，从而降低过拟合的风险。 分类任务中的优化策略 在分类任务中，优化策略需要根据任务的特点进行调整：\n1. 分类问题转化为回归问题 有时将分类问题转化为回归问题进行解决，网络输出一个连续值。这种方法可能会引入伪关系，因此更常见的是使用One-hot向量作为输出，并结合Softmax函数进行标准化。\n2. 损失函数的选择 交叉熵损失 (Cross-Entropy Loss)：对于分类任务，尤其是多分类任务，交叉熵损失是更合适的选择，特别是与Softmax结合使用时，能够更好地指导优化过程。 Pytorch——手写数字识别的例子 pytorch internals\nimport torch import torch.nn as nn import torch.optim as optim import torch.nn.functional as F from torch.utils.data import DataLoader from torchvision import datasets, transforms from torch.utils.data import random_split # 超参数 batch_size = 64 learning_rate = 0.001 epochs = 10 dropout_rate = 0.5 # 1. 数据加载和预处理 transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)) ]) # 加载MNIST数据集 train_dataset = datasets.MNIST(root=\u0026#39;./data\u0026#39;, train=True, download=True, transform=transform) test_dataset = datasets.MNIST(root=\u0026#39;./data\u0026#39;, train=False, download=True, transform=transform) # 数据分批次处理 train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) # 2. 定义卷积神经网络 (CNN) class SimpleCNN(nn.Module): def __init__(self): super(SimpleCNN, self).__init__() # 第一卷积层，输入1个通道，输出32个通道 self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1) self.bn1 = nn.BatchNorm2d(32) # 批归一化 # 第二卷积层，输入32个通道，输出64个通道 self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1) self.bn2 = nn.BatchNorm2d(64) # 批归一化 # 第三卷积层，输入64个通道，输出128个通道 self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1) self.bn3 = nn.BatchNorm2d(128) # 批归一化 # 线性层（全连接层） self.fc1 = nn.Linear(128 * 7 * 7, 512) self.fc2 = nn.Linear(512, 10) # 输出10个类别（MNIST是0-9的数字） # Dropout层，防止过拟合 self.dropout = nn.Dropout(p=dropout_rate) def forward(self, x): # 卷积层 + 激活函数 + 批归一化 + 池化 x = F.relu(self.bn1(self.conv1(x))) x = F.max_pool2d(x, 2) x = F.relu(self.bn2(self.conv2(x))) x = F.max_pool2d(x, 2) x = F.relu(self.bn3(self.conv3(x))) x = F.max_pool2d(x, 2) # 将特征图展平（Flatten） x = x.view(-1, 128 * 7 * 7) # 全连接层 x = F.relu(self.fc1(x)) x = self.dropout(x) # 在全连接层后应用Dropout x = self.fc2(x) return x # 3. 模型、损失函数和优化器 model = SimpleCNN() # Adam优化器，并使用L2正则化（weight decay） optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001) # 使用交叉熵损失函数（适用于分类任务） criterion = nn.CrossEntropyLoss() # 4. 训练过程 def train(model, train_loader, optimizer, criterion, epoch): model.train() running_loss = 0.0 correct = 0 total = 0 for batch_idx, (data, target) in enumerate(train_loader): # 将数据移到GPU（如果可用） data, target = data.cuda(), target.cuda() # 清除梯度 optimizer.zero_grad() # 向前传播 output = model(data) # 计算损失 loss = criterion(output, target) running_loss += loss.item() # 向后传播 loss.backward() # 更新参数 optimizer.step() # 计算准确度 _, predicted = torch.max(output, 1) total += target.size(0) correct += (predicted == target).sum().item() # 打印每个epoch的损失和准确率 print(f\u0026#39;Epoch {epoch}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100. * correct/total:.2f}%\u0026#39;) # 5. 测试过程 def test(model, test_loader, criterion): model.eval() # 切换为评估模式 test_loss = 0.0 correct = 0 total = 0 with torch.no_grad(): # 测试时不需要计算梯度 for data, target in test_loader: # 将数据移到GPU（如果可用） data, target = data.cuda(), target.cuda() # 向前传播 output = model(data) # 计算损失 loss = criterion(output, target) test_loss += loss.item() # 计算准确度 _, predicted = torch.max(output, 1) total += target.size(0) correct += (predicted == target).sum().item() # 打印测试集上的损失和准确率 print(f\u0026#39;Test Loss: {test_loss/len(test_loader):.4f}, Test Accuracy: {100. * correct/total:.2f}%\u0026#39;) # 6. 训练和测试模型 # 如果有GPU，使用GPU训练 device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) model.to(device) for epoch in range(1, epochs + 1): train(model, train_loader, optimizer, criterion, epoch) test(model, test_loader, criterion) ","permalink":"https://rzyn2020.github.io/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/","summary":"","title":"深度学习基础知识总结"},{"content":" 人们自己创造自己的历史，但是他们并不是随心所欲地创造，并不是在他们自己选定的条件下创造，而是在直接碰到的、既定的、从过去继承下来的条件下创造。\n写在前面的感想 吉登斯的这本「社会学」虽然只有薄薄百余页，却都是精华。做笔记时差点把整本书都复制一遍\u0026hellip;（所以与其看笔记倒不如去看书_(┐「ε:)_\n读完印象最深刻的观点有：\n社会学不同于自然科学，是批判的学科 社会学理论的两大主流：资本主义理论和工业社会理论 吉登斯简要介绍了这两种理论，并对比了这两种理论对现代社会的不同看法 吉登斯同时批判了两种理论，认为真相应该是某种折中 此外，我也感受到，这些社会学理论的背后都有一些基本的价值，我所总结出的是：机会平等 和 结果平等。这两者不可得兼，但也要一定程度上兼顾。前者激励人们奋发图强，后者能保证社会和谐。「礼记」中的「選賢與能，講信修睦」似乎就是这个意思。\n当然，我们肯定也有别的价值：比如自由，比如家庭\u0026hellip; 但是这两种平等似乎才是现代资本主义社会面临的核心问题。\n资本主义和工业社会理论的分歧点在于：\n对于社会现状的判断不同：如果有更好的调查方法和更详实的数据，应该就能弥合这个分歧 对于未来的预测不同：这主要源于他们所构建的理论不同。一个好的理论应该能经得起实践的检验 基本价值的偏差：如密里本德相对于拉伦多夫，似乎更重视结果平等。前两者的分歧都可以用自然科学的方法来弥补，但是价值观的偏差就不能了。 不过，价值观也并不是什么先天就刻在DNA里的东西，而是受到我们的社会实践和社会认识的影响。所以社会学就像社会自身的哲学一样，会在实践中不断重新定义自身。\n就像我们需要哲学一样，我们也需要社会学。这是由人本身理解世界的冲动决定的。即使这种理解只是特定条件下的谎言，或者部分的真理，它也是不可或缺的。\n此外，在了解了社会学的大体框架后，我也产生了下面一些问题，等待后续有机会再去研究。\n资本主义的问题：马克思认为资本主义产权以及自由的概念本身就蕴藏了不平等——究竟哪里不平等了？难道有一种在具有相同自由的程度下还更平等的社会形态吗？ 第三条道路：吉登斯以及许多人主张资本主义和社会主义之外的“第三条道路”（虽然没有明确提出），似乎在上个世纪也有不少政党践行这一理论。第三条道路究竟是怎么样的？它成功了吗？ 参与式民主：吉登斯提出，现有的代议制民主存在许多问题，其本身的前提就是官僚制，而且民主只保留在了政治领域。但是，在人口众多的前提下，难道真的能实现参与式民主吗？ 自由市场的问题：许多社会学家对自由市场提出了批判，认为其逐利的本性反而限制了人自发生产的积极性。甚至对垄断资本提出了赞扬——垄断资本至少没有那么逐利。但是显然竞争不充分也降低了市场效率。那么，不充分的竞争究竟在什么程度上，以什么方式影响了效率与平等呢？ 技术发展的问题：技术发展对社会形态也产生了巨大影响，比如上个世纪白领阶层的出现。如今信息产业的发展似乎大有取代大部分工作之势，或许真将制造一个庞大的失业者群体。所以，技术发展到底会给社会带来什么？如果技术发展反而破坏了社会（就如同19世纪许多工人的生活水平甚至不如农民），我们有办法改变吗？ 什么是社会学 社会学产生的背景：\n1789 年法国大革命，人类历史上首次出现由纯粹人间理想所指引的运动——自由和平等 18,19 世纪发源于英国的工业革命，带来了城市化，工业化，人口大增长，深刻地改变了社会 在欧洲，这两场大革命带来一些列社会变迁，当人们试图理解这些变迁的条件及其可能的结果时，社会学诞生了。但同时，社会学形成的思想背景也促进了两次大革命。 什么是社会学：\n社会学研究的是人类社会 一个社会就是一套制度化(institutionalised)行为模式的集结(cluster)或体系 社会学和其他社会科学，如人类学，经济学都把社会作为共同的研究对象，但社会学的显著特征在于它集中关注“两次大革命”以来所出现的各种社会形式。 最终定义：社会学是一门社会科学，它重点研究的是过去两三个世纪工业转型所形成的社会制度 注意：社会学和其他社会科学间不存在明确分野，而且这种分野也没有存在的必要 社会学与自然科学的不同：\n在一开始，许多社会学家认为，研究社会就应该像研究自然科学一样\n奥古斯特·孔德(Auguste Comte)： 预测就是为了控制(Prévoir pour pouvoir) 涂尔干主张，社会现象应当作为事物(things)来处理：我们应当把我们自身看作是自然世界中的客体。他从而重申了社会学与自然科学之间的相似性。 但是吉登斯认为社会学的研究方法仍然和自然科学有区别\n我们无法像了解自然世界中的客体或事物那样来了解社会或“社会事实”，因为社会仅仅存在于人类自身的创造和再创造行为中。 我们创造社会的同时，社会也创造了我们 社会学的实践意涵也不能直接等同于科学的技术用途。 作为人类，我们不仅仅生活在历史之中，我们对历史的理解本身构成了历史及其未来面貌的内在组成部分。 社会学的想象力：\n社会学的实践需要唤起C.赖特·米尔斯所谓的“社会学的想象力” 历史的想象力：能够意识到传统社会和现代社会的区别 人类学的想象力：能够意识到原始社会和工业社会的区别 批判的想象力：能够想象未来的各种可能性 资本主义和工业社会 为了解释“两次大革命”对世界工业化地区的发展所造成的影响，历史上有两天主线：工业社会和资本主义。这两个术语并不是单纯的标签，而是代表了社会思想家在理解现代世界变迁的本质时形成的两种对立途径。\n“工业社会”术语是19世纪初期由圣西门(Comte Henri de Saint-Simon)在其作品中提出的，他同时还提出了一些后来被其他研究者所采用的普遍性理论准则。这条主线内部差异也巨大。\n资本主义社会的观点首先是与卡尔·马克思联系在一起的，尽管马克思的主要观点也出自此前社会理论、哲学和经济学各种思想流派。\n下面以典型的工业社会和资本主义理论为例，比较两者不同：\n工业社会理论 主要观点 当代世界最重大的变迁在于从主要以农业为基础的“传统社会”向以机械化生产和商品交换为基础的“工业社会”过渡。 从传统社会向工业社会过渡代表了历史上的进步运动。 对于19世纪和20世纪早期发生在西欧的阶级冲突，工业社会理论认为，这是从传统农业秩序向工业社会转变过程中形成的张力的结果。 但是，随着彼此能够接受的工业谈判模式得到建立，以及“政治公民身份权利”——投票和组建政党的权利——扩展到大多数人口，这些紧张关系很大程度上被化解了 从传统向现代过渡的一个基本环节就是自由民主国家的兴起。自由民主制度是一种常见于西欧和美国的政治制度，盛行议会制政府，由两个或两个以上政党通过选举的方式获取议席。 工业社会理论的支持者假定或认为，工业秩序一旦出现，就存在其基本的一致性。这种观点有时得到了最为直率的表达，其中最著名的要数克尔(Kerr)和他的同事。当然，它也遭到了如本迪克斯(Bendix)这一类人的强烈批判，他们强调，在当代社会，传统与现代的融合存在着各种不同的方式。 现代化理论的核心论点在于，“不发达社会”深陷于传统制度之中，如果它们想要获得西方社会的经济繁荣的话，它们就必须从传统制度中解放出来。从世界上未实现工业化的社会而言，工业社会的观念通常与所谓的“现代化理论”密切相关。 一个代表人物 达伦多夫 的论述（如何看待后马克思时代） 资本主义已经过时，现在是工业化时代 达伦多夫所使用的“工业化”概念表示的是工厂或企业中商品生产机械化的涵义，而工业社会则表示在该社会中，工业主义已成为经济组织的主要形式。 达伦多夫毫不迟疑地告诉我们，工业化是影响当代社会发展的主要现象。他说道，资本主义仅仅是工业社会的一种组织形式——一种仅仅局限于19世纪和20世纪早期的西欧社会的过渡形式 因为所有权和管理权，所以已经没有资本家 但是，这种所有权与管理权重叠在一起的现象仅仅是一种短暂的现象。自马克思时代以来，随着工业规模的不断扩大，资本所有权不再赋予对企业权威体系的控制权了。 资本主义社会不过是工业社会的一种次要形式，不过是工业社会发展的一个阶段。 社会流动性的增长可以带来机会平等的扩大。 个体在教育体系的成功或失败将成为影响其社会地位的主要因素。教育使社会流动更趋自由，而这一趋势又成为工业社会稳定成长的关键。 人们的地位将更多取决于涂尔干的“内在不平等”，而非“外在不平等” 个人将找到与其智慧相当的社会地位，而这又依赖于一个善意国家的引导。 善意国家能调节不同阶级冲突 自由民主国家的出现，各种工业仲裁形式的建立，包括法律上对罢工权利的正式承认，使工业领域的冲突得到了调节和控制。前者使政治领域中代表各种不同阶级利益的政党的正式组建成为可能，后者则使工业领域中的不同利益得到了类似的承认。 资本主义理论 主要观点 经济活动形式的资本主义 资本主义的两个基本结构：资本 和 雇佣劳动力 假定作为经济活动形式的资本主义在工业革命以前就已经出现，并且为工业化的启动提供了刺激因素。 工业化的过程——加速了农村劳动力向以城市为基础的工业劳动阶级的转换。 资本主义是一种永不休止、不断扩张的体系，资本主义生产越来越处于支配地位，并推动了与工业革命联系在一起的技术革新。 政治制度的资本主义 马克思把资本主义看作是一种经济活动形式，同时，由于他相信，其他制度与这种经济活动形式是紧密联系在一起的，因此，他也把资本主义看作是一种社会类型。 在马克思理论中，阶级关系直接把资本主义经济组织与资本主义社会的其他制度连接在一起。 1789年法国大革命，标志着资产阶级政治权力的兴起。 资本主义社会本质上是一种阶级社会，形成这种社会的各种阶级关系本质上是一种冲突或斗争的关系 资本家和工人之间的依赖是一种不平衡关系：工人很少能够控制他们所从事的工作，而雇主却能够依照自己的目的获取利润。 阶级冲突并不会仅仅局限在资本主义发展的早期阶段，它将随着时间的延续而变得越来越尖锐。 国家是阶级权力的表现形式 马克思的时代，大部分人都没有投票权力（因为财产限制） 劳动者政党的组建受到法律限制或禁止 国家更注重于维护资本主义劳动契约 一个代表人物 拉尔夫·密里本德(Ralph Miliband) 的论述（如何看待后马克思时代） 资本主义仍然存在 在密里本德看来，尽管存在着大型企业不断成长和国家不断染指经济领域的现象，资本的私人所有权仍然是当代西方社会的首要特征。 （资本主义社会）有两个重要的特征：一是它们都是高度工业化的社会，二是其经济活动的大部分工具都为私人所占有和支配。 所有权和管理权分离并没有导致资本主义解体 首先，这种分离将不会产生通常所说的进步意义，少数股票持有者依然能够控制一个大企业，只要它的其他股份是高度分散的。 更为重要的是，资本所有者和经理在维持资本主义的生产框架方面有着相同的经济利益，他们都来自相同的特权背景，从而形成了一个相对统一的支配阶级。 社会流动性实际上并没有那么大 密里本德认为，大部分流动都是“小幅度的”(short-range)，也就是说，是阶级体系中毗邻地位之间的流动，很少存在“大幅度”的流动，使来自工人阶级背景的人能够上升到精英群体。 即使把一种较具‘精英’(meritocratic)方式的升迁路径嫁接到现存的经济体系中去，也只能保证许多工人阶级出身的人能够上升到现存阶级体系的上层。这种结果或许是怡人心意的，但它不会把现存的阶级体系变成另一种不同的体系。” 阶级斗争依然是核心 普遍公民权和工业仲裁程序，但在密里本德看来，它们只有在阶级斗争中，而且也只有通过阶级斗争才能实现，并且它们仍然是阶级斗争的核心。（并非善意国家赐予的） 苏联模式：它至多是一种残缺的或扭曲的社会主义面貌。 资本主义国家的社会主义政党巩固，而不是瓦解了现存秩序 为了赢得选举的广泛胜利，它们通常必须淡化其社会变革的方案。一旦上台执政，它们的实际政策也不会像选举运动时所标榜的那么激进，因为既得利益阶层出于其既有的地位和特权所受到的威胁，将会提出强烈的抗议。 “议会制社会主义”(parliamentary socialism)本身不可能奏效，只有借助于议会之外的额外运动，彻底的社会变革才有可能实现。 他认为，由于受流行意识形态的影响，西方社会主义政党出现了广泛的改良主义倾向。 控制了生产工具和政治机器的阶级同时也就控制了这个社会的信仰和象征。在资本主义社会，存在着密里本德所谓的“同意工程学”(engineering of consent)，它可以在人口中培育起对现状的顺从态度。 在达伦多夫看来，教育是通往平等的主要车轮，它促进了流动性和“精英式”社会秩序的形成，但在密里本德眼里，教育主要是一种阻碍社会变革的现象，因为教育体系在每一代人那里都会被反复用来创造有利于统治阶级利益的总体意识形态。 可以总结出他们的几个关注点：机会平等和社会和谐，以及阶级冲突的地位\n机会平等在于每个人都得到与其智慧相当的社会地位（選賢與能） 社会和谐在于社会的整体结构不存在过分的不平等和压迫（講信修睦） 当前两者不能满足时，就会有阶级冲突 资本主义理论解释了这两种不平等的来源 拉伦多夫，密里本德对马克思19世纪资本主义工业的描述都赞同，但区别在于近一百年西方社会的变迁 现状的判断不同 -\u0026gt; 需要详实的数据支持 趋势的判断不同 -\u0026gt; 需要完善的理论支持 大道之行也，天下為公。選賢與能，講信修睦，故人不獨親其親，不獨子其子，使老有所終，壯有所用，幼有所長，矜寡孤獨廢疾者，皆有所養。男有分，女有歸。貨惡其棄於地也，不必藏於己；力惡其不出於身也，不必為己。是故謀閉而不興，盜竊亂賊而不作，故外戶而不閉，是謂大同。禮記 禮運\n吉登斯的最后评价：\n在逻辑上，工业社会理论和资本主义理论都未必说得通，在经验上，两者也未必可行。我们面对的是一个具有无限可能性的世界，我们有关这个世界的知识形成了这些可能性。 但是，评估上面所勾画的这两种观点依然是重要的，我们要看看何者更为准确。因为这将强烈影响我们对这个世界最有可能出现的发展趋势的认识，同时还强烈影响我们有关社会变迁方向的最现实选择的认识。 若干的现象进一步讨论 阶级分析问题 股份制大公司 现象：\n这里更重要的是要关注不断提高的经济集中(concentration of the economy)：大型公司对经济生活的支配。 20世纪初以来，美国200个最大的公司以每年递增0.5%的速度扩大了其在总资产中的份额。今天，这200个最大的公司已经控制了整个工业生产的3/5左右。与此类似，200个最大的金融组织现在也控制了美国全部金融交易的一半以上。 在这些大公司中，大部分都是所谓的公开招股公司(public corporate)：也就是说，公司由股票所有者所“拥有”，它们发行既可以买进也可以卖出的股票。 这说明了什么：\n“经理主义拥护者的立场”(managerialist position) 与全盛时期的企业家资本主义相比较，巨型公司已经“更不那么资本主义”了 19世纪时期的资本主义具有强烈的竞争性，因此，每一个公司都致力于实现利润最大化的目标。但是现在，巨型公司已经处于某一经济领域的主导地位，它们能够支配市场，而不被市场所支配。 另外，这种观点还进一步认为，它们已变得更关注于稳定和长期增长了，而不是一时的最大利润。 这种公司越来越变成了“满足者”(satisficers)。它们所追求的是总体利润率的维持，而不是把利润最大化的目标置于一切之上。 巨型公司的形式拥有者——即股票持有者——现在不再对公司事务形成强大的控制了，权力已经过渡到了经理手中。 既然经理不是“资本家”——他们不拥有他们所控制的公司——他们也就更关心公司内部行政管理的稳定，而不是它所追求的利润。一些持经理主义拥护者立场的作家极为强调这一点。他们宣称，巨型公司已成为一种具有社会责任感的机构，一种具有“高尚情感的公司”(soulful corporation)，它远离了19世纪那种野心勃勃的、自私自利的公司形式。 公司越是趋于集中化，以前的阶级团结(solidarity)形式也就越趋于瓦解。 资本“所有者”现在已成为一个四分五裂的概念，因为现在股票持有者已变得高度分散了。 反驳 实际上，早期实业家通常非常注重从长远的角度经营自己的企业，而不仅仅是获取尽可能多的利润。 或许更重要的是，今天的巨型公司仍然是在竞争资本主义的框架内运作的 从严格的意义上说，很少有哪个巨型公司能够真正处于一种“垄断”的地位：这指的是这样一种情况，在某一特定经济领域中，这个公司是唯一的商品生产者。 这种竞争的压力，这种为了获得尽可能高的边际利润的驱动力，实际上可能是非常大的。 应当注意到，经理主义的主张主要盛行于20世纪五六十年代，当西方工业处于稳定扩张和相对没什么问题的阶段。在随后的几年里，经济危机的再现，以及部分工业化国家依靠低廉的劳动成本使本国的生产商日益居于优势地位，它们给巨型公司在某些经济领域中的获利能力制造了巨大的麻烦。 经理也是资本家 一是与其他资本所有者一样，他们在股市繁荣方面有着共同的利益；二是他们在巨型公司中的活动受资本主义企业这一活动框架的引导。 支配阶级依然存在 西方资本主义社会在财富分配方面仍然存在的明显不平等现象。如果我们从股票和股权的角度考察，而不是一般财富的角度来看，少数人占有的情况还要更加突出。 社会流动的问题——从精英群体的构成角度来看，甚至根本就不存在什么社会流动。 工会：阶级冲突的制度化 现象：\n一个世纪以来，墓仍然没有挖好，而且，资本主义未来的继承人尽管不再像其先祖那样充满活力，但也没有那种死期将至的严重威胁。\n这说明了什么：\n“阶级冲突制度化”是工业社会理论家所热衷的观点之一，而且它也明白地涵盖了他们所着重强调的重点。因为根据这些作者的观点，公开或者破坏性的阶级斗争仅仅局限于工业资本主义发展的早期阶段。工业仲裁模式的建立和规范化使阶级冲突的棱角趋于钝化，并转化成为“工业冲突”。 政治权力的获得也促进了其工业谈判权利的发展。 T. H.马歇尔(T. H. Marshall) 19世纪的阶级冲突被此后发展起来的三种连续性“公民身份权利”(citizenship rights)所软化。这三种公民权利是：公民身份权利、公民政治权利和公民社会权利。 第一种公民身份权利，主要涉及法律面前人人平等和参与法律体系的权利。 第二种公民政治权利，主要指普遍公民权的获得，以及组建政党的权利。 第三种权利主要指工业谈判的权利和获得福利的权利——包括失业救济、医疗保险，等等。 马歇尔说道，在过去100多年的时间里，“公民身份与资本主义的阶级体系一直处于尖锐对立的状态”。但是，胜利的是前者，尽管这种胜利可能并不全面，但阶级斗争的威胁已经不再足于瓦解资本主义秩序了。 对马歇尔的修正 马歇尔没有充分强调“资产阶级法律关系”与雇佣工人的地位之间存在的不平衡特征。 早期资本家侧重于建立一个能够按自己意志加以雇佣或解雇的“自由”劳动力后备队伍。 资本主义的劳动契约预先假定了形式上“自由”的个体，他们之间不存在各种封建效忠关系的约束，这是一种通过自由契约所形成的纯粹经济关系。 但是，这种“自由”实际上有助于雇主支配工人的权力。 政治权利尽管使每一个人成为了公民，但它并没有延伸到工业领域，可是，这一领域却占据了大多数人日常生活的大部分时间。 马歇尔所描述的公民身份权利的扩张实际上并非国家仁慈的结果，而是必须积极争取的东西。 马歇尔所说的“福利国家”依然是资本主义 在私有资本的支配下，生产利润仍然是经济系统的主要动力； 私有财产，尤其是私有资本的分布仍然是高度不均衡的； 阶级冲突在经济和政权(polity)层面仍然具有重要的意义。因此，可以说，资本主义仍然是阶级社会。 白领阶层 现象：\n20世纪西方社会的阶级体系发生的一个引人注目和最受到讨论的变化就是，与体力或者“蓝领”劳动比较，“非体力”或者“白领”工作的相对增长。\n这些统计数据似乎与马克思所设想的资本主义社会的发展轨迹完全背道而驰。因为马克思相信，大部分人口将注定要成为体力劳动者，从事一些例行单调的工作，小资本家很大程度上将消失，最终形成一个少数大资本家与广大无产阶级对抗的格局。\n这说明了什么：\n马克思所设想的是一个两个对立阶级日益分裂的社会。但的确，新中间阶级的扩张已成为一种促进稳定的力量，它腐蚀了工人阶级，使之越来越纳入到中间阶级的队伍中，而不是反过来使中间阶级受到改造。 但同时许多白领职业依旧具有单调、甚至是机械性的特征 大部分人认为，尽管新中间阶级并不像统计数据所天真地表明的那么大，但它或多或少已成为资本主义阶级关系的一个复杂因素。 信息技术以及失业者 现象1：\n我们正在进入一个由“信息技术”所支配的时代，这个时代不再像过去那样由制造工业所主宰。\n这说明了什么：\n科学在现代生产中所发挥的作用、电脑技术的广泛采用，尤其是最近微芯片技术的广泛普及，将对先前的社会秩序产生深远的影响。 反驳 后工业社会概念延续了隐藏在工业社会理论后面的技术决定论。 在圣西门所构想的“工业社会”中，就是科学家和技术专家的联合统治。但是，它并没有成为现实，而且尽管当代信息技术突飞猛进，它仍然不太可能实现。 只有在一种世界性的背景下，我们才能充分理解与新技术发展联系在一起的社会和经济变迁 现象2：\n信息技术的广泛使用可能逐渐改变大部分人所从事的工作的性质，并提高失业率的水平。事实上，大部分世界经济都深陷于长期性经济衰退之中，近年来，许多国家的失业率水平也急剧提升。针对这些现象，许多人认为，工业国家将永远不可能再回到20世纪60年代那种“充分就业”的经济景象中去了。\n这说明了什么：\n法国作家高兹(Gorz)——工人阶级在消失 当前的情况是，与其说无产阶级推翻资本主义体系，反不如说资本主义的成熟越来越缩小了工人阶级的作用。 在他看来，信息技术将消除大部分现存的体力劳动，同时也将消除许多单调乏味的白领工作。 现代工业所隐含的生产能力，能够创造远高于满足人类基本需要所必须的财富。 工作本身将成为目的，由它能够提供给生产者的自我满足水平所决定。 然而，高兹说道，资本主义的后续发展却彻底背离了这样一种预期。管理制度所采取的严格的劳动控制，已经有效地压制了工人形成任何创造性劳动潜力的意识。 “当前的重点在于反对劳动的性质、内容、必然性和各种模式，以便使自己从劳动中解放出来。” 上面所勾画的发展趋势表明，工人阶级已经被高兹所说的“非劳动者的非阶级”(non-class of non-workers)或“新无产阶级”(neoproletariat)所取代。 这个阶级或者由大量永久失业的人员所组成，或者即使他们在工作，也没有得到很好组织，缺乏阶级认同，职业的保障程度也较低。从长期来看，作为信息技术不断扩张的结果，失业的队伍将会日益增大。 他们越来越倾向于寻求满足感的源泉，但这种满足感与工作和工作场所毫无关系 高兹宣称，我们正在走向一种“二元社会”：一方面，生产和政治管理将会很好地组织起来，以使其效率最大化；另一方面，将会出现一个个人具有多元追求的领域，在这一领域中，享受和自我满足将成为追求的目标。 生产主义的工作伦理将让位于一种关注度过“自由时间”的全新观念，这种自由时间将不再仅仅被当作是一天活动之外的余暇。 希默尔斯特兰德——工人阶级在扩大 在瑞典，工人阶级并没有萎缩 他希望看到的并不是任何国有工业的扩展，或生产计划集中化的扩展。相反，他希望看到的是工人在某种程度上实际控制他们所从事的生产过程——在高兹看来，现代工业是不可能实现这个目标的。 相反，他所谈论的是他所谓的“扩展的无产阶级”(extended working class)——指大部分劳动力——他们对社会主义改革具有普遍的兴趣。 希默尔斯特兰德试图表明的是，根据各种阶级意识指标，这种以扩展的无产阶级面目出现的无产阶级不但依然存在，而且还充满活力。 希默尔斯特兰德所关注的是在工业领域建立起一种工资收入者基金(wage-earner\u0026rsquo;s funds)制度 但它们基本都主张实行利润共享制。这种共享制表现在，公司的利润每一年都将按比例转移到员工身上，同时还将特定比例的利润转化成国家和地区发展基金。 国家性质问题 国家在社会生活中的作用已日益扩张的问题。 从经济角度看，资本主义国家在指导生产活动方面发挥着越来越直接的作用。在绝大多数这类国家，国家直接雇佣的劳动人口占全国从事经济活动的劳动人口的40%以上 另外，在其他社会生活领域，同样少不了国家介入的影子，如参与组建监狱、收容所、医院等，参与供给“福利”名目下的各种服务等。 令人奇怪的是，直到最近，社会学却很大程度上忽视了国家的存在，不论是马克思主义的社会学家还是其他流派的社会学家，都概莫能外。 然而，在过去10年左右，国家却成为讨论的热门话题，在马克思主义者中尤其如此。 国家与阶级 观点1：\n阶级统治的直接工具，直接由资产阶级所支配。 国家的阶级特征在于国家官僚所维护的是整个资本主义生产的延续性。 在一个依然是阶级社会的社会，统治圈子中存在着相当多的派系和摩擦。 观点2：\n但在普朗查兹看来，资产阶级是一个内在分裂的阶级，国家具有一种独立于资产阶级的“相对自主性”。 在普朗查兹看来，上层阶级内部也存在着分裂，但这并不说明资产阶级的支配由此就遭到了破坏，分裂是一种正常的现象，关键在于，资本主义生产的制度性架构能够维持下去。 国家与官僚 韦伯 资本主义特征：例行化 只有在非个人化的准则(norm)的基础上，这种例行化的形式才能建立起来，因为这种准则能够对各种程序进行详细的说明，并使精确的经济计算成为可能。 韦伯比马克思更加强调，资本主义扩张的条件在于官僚制国家的早期发展。在他看来，在国家的管理之下，建立起一套完备的法律体系和金融体系是资本主义生产大规模扩张的必要基础。 从本质上看，官僚制使权力集中在少数人手里，即集中在处于组织顶峰的那些人手里。 工人被剥夺生产资料的情况并不仅仅限于资本主义社会，因此，超越资本主义并不见得这一现象就将消失。 使大部分人仅仅成为“机器上的一个小齿轮”，所有这些都是官僚制的一般特征 民主的理念起源于小型社会，在这种社会中，那些能被称作“公民”的人仅仅占人口中的极小部分，这部分人可以亲自参与各种集会以行使政治权力。 现代是“政党机器的政治”(party machine politics)的时代，在这种时代里，普通公民的参与程度对政策制定的影响可谓微乎其微。 \u0026ldquo;民主的精英主义”(democratic elitism)或许是一种有限的政治参与模式，但在多党制的背景下，它还是好过什么都没有 参与式民主的可能性 寡头统治的铁律既不是一种铁律，甚至根本就是一种未加限制的不确切表达。 实际上，在高度整合的工作条件下，工人在某些方面获得了比以前还要大的权力。因为高度整合的生产线是极度脆弱的，很容易为少部分工人步调一致的行为所破坏。 所有行动者都是具有认知能力的行动者，而不是只受其行动环境影响的被动接受者，认识到这一点具有重要的社会学意义。 如果处于下层地位的人能够通过这种消极的方式获得某种程度的权力的话（指的是罢工），那我们就有充分的理由假定，公民身份权利的扩张将进一步把这种权力延展至工业领域。换句话说就是，在当代社会，存在着某些建立“参与式民主”的可能性，不应当像韦伯那样完全排斥这种可能性。正如马克思的分析所表明的那样，这种民主在工业领域将具有特别强大的力量。 国家与革命 在蒂利看来，革命运动是他所谓“多元主权”(multiple sovereignty)——即指由于这种或那种原因，国家无法在其统治范围内充分行使控制权——情况下集体行动的次级类型。 蒂利倾向于认为，对利益有意识和有目的的追求是革命运动的先导，而“成功”的革命运动则发生在人们设法实现其利益的情况下。 在斯考切波看来，革命运动的目标典型的是模棱两可和摇摆不定的，大规模革命性变动很大程度上是一种无意识的结果，是某些群体和运动所要实现的一些较为片面的目标的意外后果。 当斯考切波强调，重大的社会革命并不是那种有目的地组织起来以推翻现存社会秩序为目的的运动时，她无疑是正确的。但是，在有目的地形成的社会变动与“结构性”失调所导致的社会变动之间，她或许过于强调了两者间的对立。 世界体系 现象：\n在我们的时代，没有什么会比发生在特定时空背景中的日常生活行为与跨越广泛时空范围的事件联系在一起更富有特色。\n现代世界体系理论：\n现代化理论 第一，第三世界中的传统社会不仅是低度发展(underdeveloped)的社会，而且是不发达(undeveloped)的社会，它们有待工业转型力量的冲击。 第二，这些国家因此必须重蹈工业化国家所走过的老路，再生产出“工业社会”所取得的成就。 批判 现代化理论建立在一种错误的前提之上，在某种程度上，它为西方资本主义国家支配世界其他地方提供了意识形态辩护。 国家之间的不平等 民族国家 民族国家可以被定义为：它是政治治理的各种制度，在这些制度下，社会统治者成功地实现了对暴力工具（军队和警察）的垄断，控制成为他们在特定领土边界范围内进行行政管理的主要保障措施。 现代民族国家的形成与民族主义情感的兴起息息相关。民族主义可以被定义为：对于某些符号的共同归属感，这些符号可以使特定人群的成员认同他们归属于相同的共同体。 如果说资本主义世界经济是现代世界体系的一个突出特征的话，那么，民族国家体系同样是现代世界体系的突出特征之一。 国家间的无政府主义 ","permalink":"https://rzyn2020.github.io/posts/%E5%90%89%E7%99%BB%E6%96%AF%E7%A4%BE%E4%BC%9A%E5%AD%A6%E7%AC%94%E8%AE%B0/","summary":"\u003cblockquote\u003e\n\u003cp\u003e人们自己创造自己的历史，但是他们并不是随心所欲地创造，并不是在他们自己选定的条件下创造，而是在直接碰到的、既定的、从过去继承下来的条件下创造。\u003c/p\u003e\u003c/blockquote\u003e","title":"吉登斯「社会学」笔记"},{"content":"“I call architecture frozen music\u0026hellip;” - Goethe\nBitTorrent 是一个 p2p 下载协议，官网网站见这里。官方网站内不仅含有标准规范，而且仿照PEP（Python Enhancement Protocol），有着自己的 BEP，用来对协议进行增强。\n不过官方标准规范较为难懂，这里有一份协议的非官方版本，更易于理解： Unofficial Specification\n这里也有一份简介： https://web.cs.ucla.edu/classes/cs217/05BitTorrent.pdf\np2p 网络 最严格的 p2p 网络定义为：\nA communications model in which each party has the same capabilities and either party can initiate a communication session\n也就是网络中每个节点都起相同功能，且不会出现单点故障。与之相反，server-client 式的架构就被称为 集中式 网络。\nARPNET 就是 p2p 式的；DNS system 可以算 p2p 和 集中式 的一个折中。\n假如 DNS 是集中式的，一个主机负责全世界的 IP 查询，则很容易碰上 单点故障 和 性能限制。因此，DNS 采取了分布式的架构——树形递归查询加上多级缓存。有许多起相同功能的本地 DNS 服务器，挂掉一个也不影响整个系统运作，未尝不可称之为某种程度上的 p2p。\n因此，一个宽松一点的 p2p 定义：\n“A distributed network architecture may be called a Peer-to-Peer (P-to-P, P2P,\u0026hellip;) network, if the participants share a part of their own (hardware) resources (processing power, storage capacity, network link capacity, printers,\u0026hellip;). These shared resources are necessary to provide the Service and content offered by the network (e.g. file sharing or shared workspaces for collaboration). They are accessible by other peers directly, without passing intermediary entities. The participants of such a network are thus resource (Service and content) providers as well as resource (Service and content) requestors (Servant-concept).”\n这样的定义下，虽然不能完全避免单点故障，但的确体现出来 p2p 的本质：\n每个参与者即是 服务提供者 又是 服务享受者 因此，p2p 就有着以下特点：\n相对可扩展性：增加服务享受者的同时也增加了服务提供者 相对稳定性：许多服务提供者，挂掉一个也无妨 BitTorrent 下面再来介绍典型的 p2p 协议 —— BitTorrent。\nBitTorrent 主要被用来分发/下载文件，因为其 p2p 的特性而不需要耗费上传者太多带宽 —— p2p 网络中的每个用户在下载文件的同时也把自己已下载好的文件传给别人。\nBitTorrent 协议与在它之前的 p2p 协议相比，有一个特点：它会把每个文件都切分为许多小块（piece），一个用户可以同时向许多同伴（peer）请求同一个文件的不同部分。\n而它之前的 p2p 协议往往是一对一协议，一个下载好的人负责给一个没有下载好的人传送文件。但是因为一般网卡的上传带宽都远远小于下载带宽，因此这种模型下，文件传送的最大速率最大也只能等于peer的上传带宽。\n但是在 BitTorrent 下，对于一个非常火爆的已经有很多人下载好的文件，我们就可以同时向他们所有人请求文件块，充分利用自己的下载带宽了。这也是为什么 BitTorrent 一经推出就统治了 p2p 下载界。\n比如上面的文件，有 169 人上传，只有 18 人下载，可想而知下载速度是非常快的\nBitTorrent 的架构中含有如下实体：\n一个元信息文件： torrent file 一个集中式 tracker 第一个参与者：seed 其他参与者：leecher tracker 会记录哪些 peer 正在下载文件，并帮助他们互相认识。peer 通过 http 协议和 tracker 进行通信，以获取相关信息。\n世界上有许多公开的 tracker 服务器，比如这个列表里收录的：trackerlist\n在一开始，一个用户决定分发某个文件时，会先做种（seed）：他会使用本地的bt软件，把文件分为通常是 512 KB 或 256Kb 许多小块（piece），并计算每个小块的 SHA-1 哈希值 ，然后把所有的哈希值和相关元信息封装在一个 torrent 文件里，传给别人。同时他也在 tracker 处登记自己持有这个文件。（通常 torrent 文件里也包含推荐的 tracker）\n当某个用户要下载时，他会向 tracker 请求 peer 列表，然后向 peer 们请求不同的文件块，并用 torrent 文件里的哈希值验证数据是否出错。\n在这个流程中，有两个算法决定着 bt 网络的正常高效运转：\n决定先向 peer 请求那个块（The Piece Selection Algorithm） —— 以达到最大下载速度 决定是否给某个 peer 发送数据（Resource Allocation） —— 以避免懒汉（free rider） The Piece Selection Algorithm 快选择算法的核心目标有两个：\n尽快在不同 peer 上复制不同的块（确保任何时刻网络中总能拼凑出一份完整的文件） 尽快下载完成文件 sub pieces BitTorrent peer 之间通过 TCP 协议进行连接，因此需要避免 TCP 慢启动机制 对传输速率的影响。块常常被划分为 16kb 大小的子块进行传输，BitTorrent 协议保证和一个 peer 之间无论何时总是有一些 子块 等待被传输，以此来维持高速连接。一个块的不同子块可以从不同的 peer 处下载。\npolicys strict policy：每开始下载一个块时，就优先下载该块的所有子块。 random first piece：刚开始下载时，为了尽快得到能给其他 peer 上传的块，就随机选择一个块进行下载。 rarest first：优先下载网络中最稀有的块。 endgame mode：当到最后一块时，向所有 peer 都请求该块的子块，以快速下载完文件。 Resource Allocation Resource Alllocation 算法用来决定和哪个 peer 进行合作。我们采用“tit-for-tat” （以牙还牙）策略，以达到利益最大化。一般来说，你上传的越多，下载的也就越快。\nEnhancements 自从 BitTorrent 被发明以来，许多 BEP 提出了一些改进，下面介绍一些有趣的改进功能。\nDecentralized tracker youtube视频简介\nBitTorrent 中，由于 tracker 服务器的存在，所以不能达到 \u0026ldquo;真p2p\u0026rdquo;，因此就有了 去中心化tracker 拓展。它基于 DHT （Distributed hash table）在 peer 间存储 peerlist，以取代中心化 tracker。\nDHT 的基本思想为：将所有 node 连接成一个环，环上每个 node 都负责存储某一范围内的 key，且知道相邻 node 的地址。查询时沿着环就可以找到目标key了。当添加或删除新 node 时，都调整数据分布以使得环结构仍然成立。\nUpnp 问题的起因是这样的：我们的 bt客户端 大都运行在内网，可以通过路由器的 NAT机制 访问外网，可是外网设备就访问不到我们的 bt客户端 了，这就让其他 peer 没办法主动和我们建立连接。为了解决这个问题，我们可以在路由器上手动设置端口转发（当然前提是你的路由器就拥有公网 IP），或者使用 VPN。\nUpnp （Universal Plug and Play）是一个应用层协议，可以在路由器上开启，接受到客户端的请求后，进行自动端口转发。其原本目标是为了让设备之间无需手动配置就能相互连接，不过许多 bt客户端 也实现了 Upnp协议，可以和路由器协商进行自动端口转发。但目前 Upnp协议 存在安全漏洞，很容易成为黑客攻击的目标。\nDDNS DDNS 即 动态（dynamic）DNS服务。如果机器每次启动都是不同的 IP，那么就可以使用 DDNS 服务，在机器每次启动时都向 DDNS 服务器告知新 IP。这适用于当你的路由器被运营商分配动态公网 IP 时，也能对外界提供一个稳定的地址。\n内网穿透 但当路由器本身就被运营商分配了局域网 IP 时，就只能通过内网穿透才能使我们的 bt客户端 暴露在公网中，接受其他 peer 的请求了。内网穿透即是通过外网中持有公网 IP 的服务器提供的中介服务，来暴露我们的客户端（相当于简化版 VPN）。\n","permalink":"https://rzyn2020.github.io/posts/bittorrent%E5%8D%8F%E8%AE%AE%E5%8F%8A%E5%85%B6%E6%89%A9%E5%B1%95/","summary":"\u003cp\u003e“I call architecture frozen music\u0026hellip;” - Goethe\u003c/p\u003e","title":"BitTorrent协议及其扩展"},{"content":" 纵横计不就，慷慨志犹存\n今年5月到8月间参加了 CSCC 举办的编译系统设计赛，但实际上集中开发也就是7月。尽管达成了最初的目标——“学习编译器后端知识”与“找回写代码的感觉”，但最后的名次却不尽人意。虽然比赛8月早已结束，近日写总结也不算为晚（总还未完全忘记）。\n我们的编译器实现 前端 使用antlr4生成lexer和parser，构建抽象语法树（AST）。 采用访问者模式遍历AST，构建中间代码（IR）。 中端 IR设计 IR结构设计参考了LLVM IR的设计，基本组件包括：\nModule: Module是IR的顶级容器，用于表示一个完整的程序或翻译单元。它包含函数、全局变量和相关的元数据。 Function: Function表示程序中的一个函数，由一系列基本块（BasicBlock）组成。每个函数在Module中唯一标识。 BasicBlock: BasicBlock是IR中的基本执行单元，由一系列指令组成。每个基本块以终结指令（如br或ret）结束，并且在执行过程中不包含控制流跳转。 Instruction: Instruction是IR中的操作指令，类似于机器指令。每个指令可以产生一个值，并作为其他指令的操作数。常见指令包括算术运算（如add、sub）、内存访问（如load、store）和控制流指令（如br、ret）。 Value: Value是IR中的数据表示，包括变量、常量和指令的结果。所有的Instruction和Constant都是Value的子类。 IR优化 中端实现了各类优化，提升了代码性能。实现的优化包括：\nMemToReg: 实现寄存器提升（Promote Memory to Register），减少内存访问。 CommonSubexpElimination: 消除公共子表达式，减少重复计算。 MergeBlock: 合并基本块以简化控制流图。 Inlining: 函数内联，减少函数调用开销。 LoopSimplify: 简化循环结构。 LoopInvariantCodeMotion: 循环不变代码外提。 GlobalCodeMotion: 全局代码移动。 GlobalValueNumbering: 全局值编号，优化冗余计算。 LoopUnroll: 循环展开，提高性能。 TailRecursionElimination: 消除尾递归。 DeadCodeElimination: 死代码消除。 ConstantFolding: 常量折叠，计算常量表达式。 GlobalVariableLocalize: 全局变量本地化，减少全局变量使用。 StrengthReduction: 强度削减，用更低代价运算代替高代价运算。 LoadElimination: 加载消除，减少不必要的内存加载。 Reassociate: 重结合运算。 GEPSimplify: 简化GEP指令。 CFGSimplify: 控制流图简化。 StoreElimination.cc: 存储消除，减少不必要的内存存储。 LruCache.cc: 缓存递归纯函数的结果，避免冗余函数调用。 InductionVariableSimplify.cc: 简化归纳变量。 后端 Instruction Seletction: 将中间代码转换为面向目标机器的低层IR。 Register Allocation: 采用SSA分配算法，先溢出以减小寄存器压力，再对寄存器进行着色。 Peephole Optimization: 实施一系列小规模的代码优化，如指令合并和消除冗余指令。 Instruction Scheduling: 采用 Local List Scheduling 算法，进行简单的指令重排，并针对 SIFive u74 的双发射特性进行了优化。 Branch Simplification: 实施和控制流相关的一些优化，如消除冗余跳转指令，基本块排序。 开发的流程与思路 理想 vs 现实 最一开始确定的开发原则有两条：\n渐进式开发 测试驱动开发 渐进式开发 主要指先实现 Sysy 的一个可工作子集，然后再不断扩充功能，直到实现完整的 Sysy 语言。在此之后慢慢增加各种优化。\n这样做的好处有：\n在大部分时间都有一个可以正常运作的编译器，可以增强开发者信心\n每次实现一小部分功能，方便实现和测试\n此外就是测试驱动开发，意思是每当实现一个功能时，先写好测试用例，然后进行开发。\n这样做的好处有：\n开发时有一个明确的目标，增强动力 每一部分代码都有测试，保证代码的正确性 同时编译器又可以分为前端，中端和后端三个部分。\n最初的计划是小组四名成员，一人负责前端实现，两人负责中端框架实现，一人负责后端框架以及无优化下的翻译实现。在基本框架实现完成后进行调试，得到一个最简单的无优化编译器。之后再做进一步计划，渐进式不断增加新的优化pass。\n然而这个计划却没有成功——我们前后中三端各自实现了一个月，才分别实现好，最后一起debug十余天后就到ddl了\u0026hellip;\n究其原因，是前端成为了我们的开发瓶颈。在后端和中端开发完成后，前端依然不能正常运行，以至于中后端bug无法及时暴露和修复。如果没有前端，中后端测试时只能通过直接调用API构造IR测试用例，但这又过于繁琐（当然也可以再实现一个 IR parser，这就更麻烦了，更何况有许多现成的 Sysy 语言测例可以利用）。所以我们还是选择等待前端完成后再debug，在这段时间抓紧时间实现一些优化 pass。但等到前端实现完成时，中后端也已经积累了非常多的bug，最后大把时间都花在了debug上\u0026hellip;\n陷入debug困境的原因 造成这样灾难性后果的原因主要有两点：\n第一，开发规划不明确。\n在一开始我认为前端较为简单，能在短时间内实现完整的 Sysy parser，而中端只是仿照 LLVM 实现，并不复杂（而且中前端的许多知识在本院课程中都已经学过）。所以实现一个可以 work 的无优化编译器应该并不困难。 可是当前端明显暴露出短板时，我才意识到直接实现一个完整前端的工作量较大，也许先实现一个 Sysy 的子集是更合理的。于是我告诉前端开发同学，“只要先实现 Sysy 的一个子集”，“能先跑起来就好”。可是当时的我却并没有 明确规定 Sysy 的哪个子集？如果我不去明确规定划分，前端可能也不知道如何选取一个易于实现的子集——如果前端有选取易于实现子集的能力，那么显然他也能在短时间内实现完整个前端。所以，前端开发同学最后还是花了一个月时间，实现了一个充满 bug 的完整前端。\n第二，测试的基础设施不完善。\n其次是测试驱动开发中遇到的问题：在前端遇到瓶颈时，中端和后端仍然不管不顾蒙头开发。可是现在回想一下，尽管没有前端不能进行系统测试，但是对部分函数进行单元测试总是可以的。实际上我在编写代码时也对部分函数感到不放心，但还是决定先把问题放着，等到集成测试时再 debug ——最后的集成测试时就成了一场灾难。实际上，c++虽然没有 rust 那么方便做单元测试，但是也有 Google test 等框架来帮忙。在前端迟迟没有完成的情况下，单元测试就更为必要了。\n第三，出现问题时没有及时调整分工。\n在前端遇到瓶颈时，当时更优的解决方法其实应该是让后端和中端的同学去协助前端，而不是让他们仍然开发各自模块。但是因为前端同学总是承诺马上就要做完了（实际上却一拖再拖），一直到20余天后中端开发同学才去帮忙实现。承诺往往是不可靠的，进行计划调整时其实应该更重视过往经验，而非开发人员的口头承诺。\n亮点不充分的原因 这里的亮点指我们在比赛中与其他队伍相比，较为亮眼的部分。当然，最后就成绩来看，也并没有什么非常亮眼之处了。\n大部分组的亮点基本可以分为以下三类：\n出色，完备的代码 实现了好的算法 优秀的基础设施 因为赶工，基本就不求 基础设施 和 代码质量 \u0026hellip; 可能唯一值得一提的是算法。\n中端参考了往年代码，实现了大部分的常见优化。后端在寄存器分配时使用了基于弦图的SSA分配算法，并且针对硬件做了简单的 Instruction Scheduling。不过SSA分配算法带来的性能提升并不大（实现上也略有粗制滥造之处），指令重排也是后期临时添加，提升效果非常有限。尽管如此，因为中后端优化实现的都比较完全,在初赛时也有一个不错的成绩。\n但8月因为种种事情，在决赛以及之前并没有做多少新的优化，而其他组这期间大都在中端做了许多激进的优化：如函数记忆化，数组访问优化，以及一些针对特殊用例的优化。\n最后也得知，许多队伍都参照了往年代码（这也就是比赛为什么一年比一年卷的原因），因此他们的目标很明确：\n实现往年第一名实现过的所有优化 在此基础上再寻找新的优化可能 而我们组就偏向于蒙头写代码，想到什么写什么了。\n这里的教训时：如果对于名次还是比较在意，比赛开始时就应该早早搜集信息，明确目标。\n团队管理的总结 开发出现问题的一个重要原因就是团队管理没有做好。虽然是四个人的小组，但大部分工作却由两个人完成。可以预想，如果只有两个人，开发效率反而会更高。或许，在开始时应该多了解一些团队管理的技巧的\u0026hellip;\n最一开始人们结成团队，肯定是拥有共同的目标。我们经过利益权衡后选择加入团队，以使得自己的利益最大化。可是加入团队后，却往往丢失了主动性，开始变得依赖管理者，并因为各种琐事而推脱团队事物。经常，只有管理者才一直把团队的利益放在心理（这是我在几次合作中的体会）。也许这也和不同文化有关，如「文化与组织」这本书里说的，华人在团队合作中往往习惯于集权，管理者往往具有更大权力，但相应的，成员也会更缺乏“主人翁意识”。在这种情况下，管理者正确运用自己的“权力”，做出更好地决策就更为重要了，在适当时候，不妨果断一些\u0026hellip;\n我在团队合作中感受到的问题有：\n信息交流不足 几个陌生人组队，很容易陷入尴尬状态，不能充分讨论，博采众长。 此时就需要管理者破冰，主动召开会议，客观分析现状，让每个都发言，都能有参与感 这样经过充分讨论做出的决策，每个人也更认同 动机不足 偷懒是人的天性\u0026hellip; 尤其是成员，如果管理者没有分配任务，明确目标，就很容易偷懒 所以就需要管理者主动给每个人分配有明确验收标准的任务，并确定DDL 难以决策 可能因为华人文化的特点，大家都习惯于听从管理者的命令，不愿意主动提出自己想法 此时决策就需要管理者更自信一点，去一锤定音了 虽然大家没有明确提出自己意见，但是他们认同决策与否可以通过执行决策是否积极来判断 但发现大家的动力不足时，应该主动了解原因，调整决策 后端知识学习经验 我主要负责后端的实现。因为之前对于编译器后端了解较少，实现时也在短时间内学习了大量新知识。\n在学习新知识时，往往会遇到许多困难。比如在学习某个寄存器分配算法时，我会先去看看一些经典的大部头教科书，提出算法的 paper，以及相关课程的slide，或者 youtube 上的讲解视频，最后是一些程序员的博客，中文所写的综述。不过在学习时我也并没有明确规划，而是这个看一点那个看一点，最后还是感到一头雾水。\n经典教科书的问题有：\n英语所写，较难抓住重点和关键的思想；工作记忆有限，梳理不清条理 都是讲最经典的实现，用简单的例子慢慢引入，学习时较为耗费时间，且很难知道研究现状和该问题各种算法的综合比较 paper的问题有：\n因为阅读经验不足，也难抓住重点 context较多，就会变得难以理解；而且不知道该论文在领域内处于一个什么样的位置 slide的问题有：\n虽然能抓住核心，但太简略难懂，许多图像意义需要脑补，不好理解 youtube视频以及博客的问题有：\n虽然许多资料深入浅出，但许多深入内容的较少，也有许多价值不高的内容 \u0026hellip;.\n经过一些挫折后，我尝试着给出一个较为系统化的新知识学习方案，也许能以后作为参考。\nSTFW 搜集各种信息，并分类整理搜集到的信息 了解相关背景知识和发展历程，心里有一个大概的框架 深入学习其中一个经典案例，搞清楚核心的思想，基本的抽象；这一步可以做一些笔记，或者在草稿纸上模拟，以加深理解 再去搜集一些综述，了解该领域发展现状，能有一个更细致的框架 此时根据自己的目标 以及 刚刚学习到的框架，为目标选择一个适合的目标算法，然后去学习 当选定目标算法并实现时，可以参考开源项目代码以及开发人员的实现相关博客 总结 项目 明确规定目标：可以文档化规范化需求 完善基础设施：既有集成测试，也有单元测试 及时识别瓶颈并处理 留够时间做killer feature 管理 交流：充分协商，打开思路，让每个人获得参与感 动机：设置ddl 决策：果断决策，不断迭代（对于集中式团队） 比如：通过ddl完成情况来了解每个人的动力值，及时给动力值不足的人重新分配任务 学习 系统化 ","permalink":"https://rzyn2020.github.io/posts/%E7%BC%96%E8%AF%91%E5%99%A8%E5%BC%80%E5%8F%91%E5%8F%8D%E6%80%9D/","summary":"\u003cblockquote\u003e\n\u003cp\u003e纵横计不就，慷慨志犹存\u003c/p\u003e\u003c/blockquote\u003e","title":"编译器开发反思"},{"content":"查看本文配套的 slide 点这里\n大家好，今天我分享的主题是「打破壁垒：代理技术在家庭网络中的应用」。主要是向大家介绍，假如在家庭网络中，有黑客挟持了网关，并对正常访问互联网产生了干扰，我们如何通过代理技术来突破封锁，打破壁垒，正常地访问互联网。\n运行良好的家庭网络 首先我们来复习一下在一个运行良好的家庭网络中，用户是如何访问互联网，以及网关在其中起到了什么作用的。\n上图是一个最简化的家庭网络的基本架构。ISP，也就是互联网服务提供商向你提供一个内置光猫的路由器。光猫把光缆中的光信号转化为路由器能够解析的电信号。路由器是在网络层进行路由转发的设备，往往也是一个通用计算机。路由器也往往充当了无线局域网络Wi-Fi的AP，接入点。\n我们的设备在连接到Wi-Fi时，就相当于接入到了这个这个无限局域网。具有Wi-Fi功能的路由器一般也充当了dhcp服务器的角色。dhcp服务器在局域网中广播告知自己的存在，当设备检测到后就向dhcp服务器请求分配IP。dhcp不仅仅会告知设备自己被分配的IP，还会告知设备当前网段的子网掩码以及网关IP地址。在此之后，用户所有的网络报文都会被转发给网关，然后经由网关再转发给真正的目标。网关也往往是由这里的路由器担任。\n黑客、襲来 鉴于路由器“一夫当关，万夫莫开”的地位，它很容易成为被攻击的对象。假设我们处于一个合租房里，黑客阿至是我们的房主。阿至是一个狂热的百度厌恶者，他千方百计地阻止别人访问百度，甚至不惜对路由器偷偷做手脚，以使得租客无法访问百度。\n由于家中地路由器就是一个通用计算机，阿至通过刷机的方式掌握了这台路由器的root权限，从此他就可以对路由器胡作非为了。他把这台路由器刷成了Linux的系统，并输入了下面命令：\niptables -A OUTPUT -d baidu.com -j DROP\niptables -A INPUT -s baidu.com -j DROP\n下面两条命令会使路由器拒绝一切由百度发送而来，或者发向百度的报文。iptables是一个运行在linux用户态的工具，但他可以对内核网络栈的处理规则进行配置。具体而言，用户可以通过它来为内核添加一些hook函数，内核会在处理网络报文时调用这些hook函数，并根据结果对报文进行一些处理。比如第一条命令，iptables 会首先通过DNS查询获得baidu.com的IP地址，然后在一个网络层报文经过内核栈处理并发送之前，判断该报文的目标是否是baidu.com，如果是，则直接丢弃该报文。第二条命令做的也是类似的事情，他会丢弃从baidu.com发来的报文。\n这样阿至就成功地阻止了我们访问baidu.com。\n代理服务器 在阿至对路由器做了手脚后，我们就不能再访问百度了。但是百度之外的网站却又可以正常访问，所以我们很快就猜到阿至做了什么。我们可不会向黑客屈服的！如果除百度之外的网站都可以访问\u0026hellip;那么只要我们在外网上还有一台服务器，通过这台服务器的中转来访问百度，这样经过路由器报文的源IP和目的IP都会变成服务器IP而不是百度IP了，这样我们就能正常访问百度了！\n经过百度查询之后，我们发现了socks5代理这一应用层协议。在这个协议中，用户程序需要和目标通过TCP/UDP协议通信时，可以先通过socks5协议与实现了该协议的代理服务器通信，然后代理服务器再和目标通信，将返回报文转发给用户程序。HTTP/HTTPS协议起到的作用与socks5协议类似。大多数使用网络的用户程序都实现了该协议，比如 curl，大部分浏览器 他们会在发送网络请求时先查看环境变量中是否定义了 http_proxy socks_proxy 等，如果定义了，则通过代理服务器与目标通信，否则直接通信。但也有一些用户程序，比如 wget，并不会主动检查并使用用户定义的代理。\n所以，我们只要使用代理服务器，就可以绕开阿至的封锁了！\n黑客、侵入 不过经过一段时间后，阿至发现我们经过路由器的报文总是发向同一个地址，他很快就猜到我们是使用了代理服务器来绕开路由器的封锁。他对经过路由器转发的数据包分析后发现，许多包中都存在 baidu 这样的字段\u0026hellip;\n于是阿至又想到了一个点子，他在路由器中输入了如下命令：\niptables -I INPUT -m string --string \u0026quot;/baidu/i\u0026quot; --algo regex -j DROP\n这样，只要报文中含有 “baidu” 这个字符串，就会被路由器丢弃，宁可错杀一百，不可放过一个！\n加密的代理 不久后，我们也发现baidu又不能正常访问了，甚至用bing搜索“baidu”都不行，似乎只要含有“baidu”这个关键词，报文就会被丢弃。于是我们想出了一个办法：既然你做关键词匹配，那么只要我的报文里没有关键词就好了。如果经过路由器的报文都是经过加密的，阿至肯定就不知道我们报文的真实内容是什么了，他也不至于和我们彻底闹翻，丢掉所有报文，不让我们连接互联网吧。\n我们首先想到的是，对socks5代理进行增强，让应用程序与代理服务之间进行加密通话。可是市场上的应用程序基本都只实现了简单的socks5代理，如果要让他们支持加密功能则需要把他们的源代码都改了，这个工作量可太大了！\n经过思考，我们想到可以利用已有的socks5代理协议，在此基础上实现自己的加密版本。我们写了一个socks5代理服务器SS Local，local接收应用程序的代理请求，可是local不运行在外网，而是运行在内网，它会把应用程序发送给他的报文先加密，然后发送给外网的另一个socks5服务器SS Server，server会解密报文，得到真正需要代理的请求。当请求返回时server也会先把报文加密，发送给local，local把报文解密，再发送给用户程序。\n这样，尽管用户程序以为自己还在使用普通的socks5代理，可是我们已经悄悄对socks5协议进行了升级，实际上经过路由器的报文都是加密过的了，阿至再也无法知道我们在看些什么了！\n透明的代理 虽然我们已经战胜了阿至，做到了几乎完美的加密，但我们还不满足于此。\n上面的代理得要用户程序主动使用，有没有可能实现透明的代理方法，让所有网络报文都经过代理？\n答案是有的。只要通过新建虚拟网卡，把通过其中的报文都代理了就好了\u0026hellip;\nVPN的原理就是这样\u0026hellip;\n漫无止境的战斗 不过，网络封锁与突破，将永远是一场漫无止境的战斗。\n事实上阿至还可以 做 DNS 污染， 识别加密数据规律 主动嗅探\u0026hellip; 但同时，兵来将挡，水来土掩，我们也永远有新的突破网络封锁的方式 \u0026ldquo;猫鼠游戏\u0026quot;永远不会完结 总结 黑客的手段 我们的举措 ip审查 代理 内容审查 加密代理 流量规律 换加密方式 主动嗅探 更好的伪装 ​\n​\n","permalink":"https://rzyn2020.github.io/posts/%E4%BB%A3%E7%90%86%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/","summary":"","title":"打破壁垒：代理技术在家庭网络中的应用"},{"content":" Programming languages should be designed not by piling feature on top of feature, but by removing the weaknesses and restrictions that make additional features appear necessary\n之前在 Twitter 上听 Robert Nystrom 的一个演说时，有观众问他“如何看待 ChatGPT，Copilot 对于编程的影响”。Robert 回道：他认为编程的乐趣在于“make something”，而 Copilot 这类工具却很有可能把 programmer 变成代码审核员，从而丧失了“make something”的乐趣。可是就算在前 ChatGPT 时代，我又真正体会到过“make something”的乐趣吗？之前我的编程实践总是一些课程作业，这些作业的 idea 或是框架总是由他人提出，目的也往往是通过 OJ。这样的编程实践给人带来的“make something”之感自然就大打折扣了。于是在可能发生的“AI 革命”的前夜，我决定自己动手写一个兼容 R7RS 的 Scheme 解释器，真正“make something”。\n在大一时曾读过部分 SICP，对 Scheme 有一点点认知。但对于其很多高级特性还不是很熟悉，尤其是 continuation 和 macro。于是在动写解释器前，打算先熟悉一下 Scheme 的特性。\nS-Expression 1960年，John McCarthy 在函数式编程的开山之作 Recursive Functions of Symbolic Expressions and Their Computation by Machine 中提出了 LSIP 语言，这也是 Scheme 的前身。LISP 语言最初也是为了支持人工智能系统 Advice Taker 而创造的(可惜 Advice Taker 代表的符号主义 AI 研究方法在当前的 AI 浪潮中似乎不见了身影)，其目的在于提供一种操作 expression 的功能以使得 Advice Taker 能在其上推理。\n在 LISP System 中，有 S-Expressions 和 S-Functions(对应 Scheme 中的过程/procedure) 两个概念。S-Expressions 即是 Symbolic Expression，和数学意义上的 expression (表达式)意义相同。S-expressions 本身仅仅是一种数据结构，没有任何求值的含义。 S-Expression 的定义如下：\n(以及list的定义如下)\n在 S-Expression 之上，我们又可以定义对其进行操作的 S-function (S-function事实上为 partial function，因为有可能无限循环)\natom. atom[x] has the value of T or F according to whether x is an atomic symbol.\natom [X] = T atom [(X · A)] = F\ncar. car[x] is defined if and only if x is not atomic. car [(e1 · e2)] = e1. Thus car [X] is undefined.\ncar [(X · A)] = X car [((X · A) · Y )] = (X · A)\n当然S-function也可以递归：\nff[x]. The value of ff[x] is the first atomic symbol of the S-Expression x with the parentheses ignored.\nThus ff[((A · B) · C)] = A\n向上面的式子叫做 M-expressions (meta-expressions)。(注意到 M-expression 之上就有求值的语义了)\n有趣的是，我们可以通过 S-Expressions 来表示 S-Functions，同理可以把任意一个 M-expression 用 S-Expression 表达：\n(这样就有平时用的 Scheme 的感觉了，，)\n然而单是这个转换本身没有什么作用，我们需要有一个函数 eval 来对转换后的 S-Expression 进行求值，其结果相当于对应的 M-Expression 的求值结果。我们在写 LSIP 程序时其实就是在写 S-Expression，但表示的却是 M-Expression。解释器运行程序就相当于把你写好的 S-Expression 丢给 eval 函数并返回结果。 S-Expression 这种程序的表示方式自然也被 Scheme 所继承，不过在 Scheme 中这些东西都是小写。而第一条转换规则中的 Atom QUOTE 可以简写为\u0026rsquo;。 除了 S-Expression，Scheme 还从 LISP 中继承了 GC,动态类型。高阶函数等特征。\nFun Facts: John McCarthy 父亲为爱尔兰移民，母亲为立陶宛犹太人移民，二人都思想开放，加入了美国共产党(Communist Party USA)。John 出身生于1927年，少时通过阅读俄文译作 100,000 Whys (难道中文版的《十万个为什么》也来自苏联？)燃起了对科学的兴趣。John后来也精通俄语，与多苏联科学家相识。但当他在 1968 年正真去苏联旅行之后很快就失望了，转变为共和党支持者。\nContinuation Scheme 于1970年代在 MIT AI Lab 被 Guy L. Steele 和 Gerald Jay Sussman发明(又是AI？)。与父亲 LISP 不同, Scheme 实现了尾递归优化，并引入了宏和 first class continuations，本节主要介绍 continuation，下一节介绍宏(Macro)。\n上一节说了 M-Expression 有求值语义，eval 函数也能求值，但并未说明到底怎样求值。具体来说，eval 接收到一个 S-Expression 后，对 S-Expression 的所有子Expression(接收到的 S-Expression 应为一个list，子 Expression 指的是 list 中的各个子项)逐个调用eval函数。第一个子 Expression 应为一个过程，剩余的 expression 为这个过程的参数，然后eval会调用apply将参数作用到过程上并返回结果。对于 Scheme 语言中定义的基本过程，apply 会直接计算并返回结果，对于复合过程，apply 会将函数形参替换为实际值，再调用 eval 对函数体求值并返回。\n可以看到，对一个 S-Expression 求值的过程可以看作一次次的对 eval 的调用。而每个 eval 调用结束之后都有下面还要进行的求值，这个后面还要进行的求值就叫做当前求值的 Continuation(延续)。\nScheme 中的 Continuation 是一个很抽象的概念，在其它编程语言中往往缺少对于概念。但在C语言中，我们可以通过机器状态来理解 Continuation。在C语言中，假如要调用一个函数 f，会在栈上 push f 的帧，f调用结束之后会将返回值 push 到栈上，再接着做后续计算。如果再将返回值 push 到栈上的一瞬间，我们对整个进程做一个快照，这个快照说明了在 f 返回后应该要做的计算，它其实就是 f 的 Continuation。在C语言中，我们可以通过int setjmp(jmp_buf env)来捕获在调用setjmp时的 Continuation 并保存在 env 中，而在未来调用void longjmp(jmp_buf env, int val) 会继续进行 setjmp 时保存的 Continuation，并把 val 作为 setjmp 的返回值。看起来就像进行了一次“时空穿越”。\nC语言中 setjmp 和 longjmp 的实现很好理解——setjmp 保存当前的 pc 指针以及寄存器的状态，longjmp时复原就行——当然这样也就引出了一个问题：c语言中的 setjmp 并不能真正保存 Continuation，因为 setjmp 不可能将栈上的值也保存了。但 Scheme 中的 Continuation 却是真正的 Continuation\nScheme 是通过 call/cc 这一过程起到和C语言中 setjmp 类似却更完备的功能的。call/cc 接收一个一元 lambda 函数，对其求值时相当于将当前的 Continuation传 入该一元 lambda 函数后对该函数体求值。如果一元 lambda 函数正常返回，则 call/cc 过程的返回值就是一元 lambda 函数的返回值。如过在任何地方调用了 Continuation(Continuation 也是一个一元过程)，当前的所要进行的计算就会变成 Continuation 所记录的计算，就好像 call/cc 过程刚刚返回一样，而此时 call/cc 的返回值为调用 Continuation 时传入的参数：\n(call/cc (lambda (k) (* 5 4))) =\u0026gt; 20 (call/cc (lambda (k) (* 5 (k 4)))) =\u0026gt; 4 (+ 2 (call/cc (lambda (k) (* 5 (k 4))))) =\u0026gt; 6 借助 call/cc，我们可以实现协程(coroutine)：\n(define lwp-list \u0026#39;()) (define lwp (lambda (thunk) (set! lwp-list (append lwp-list (list thunk))))) (define start (lambda () (let ((p (car lwp-list))) (set! lwp-list (cdr lwp-list)) (p)))) (define pause (lambda () (call/cc (lambda (k) (lwp (lambda () (k #f))) (start))))) (define quit (lambda () (if (null? lwp-list) #f (start)))) (lwp (lambda () (let f () (pause) (display \u0026#34;h\u0026#34;) (f)))) (lwp (lambda () (quit))) (lwp (lambda () (let f () (pause) (display \u0026#34;e\u0026#34;) (f)))) (lwp (lambda () (let f () (pause) (display \u0026#34;y\u0026#34;) (f)))) (lwp (lambda () (let f () (pause) (display \u0026#34;!\u0026#34;) (f)))) (lwp (lambda () (let f () (pause) (newline) (f)))) (start) =\u0026gt; hey! hey! hey! 如果利用 Macro，在每次调用 lambda 函数时插入“中断”指令，我们也可以模拟线程(由于没有迭代，每个 lambda 函数体的执行都是O(1)的时间复杂度，因此每次进入函数体时中断也能达到类似“定时中断”的效果)：\n(define clock 0) (define handler #f) (define start-timer (lambda (ticks new-handler) (set! handler new-handler) (set! clock ticks))) (define stop-timer (lambda () (let ((time-left clock)) (set! clock 0) time-left))) (define decrement-timer (lambda () (when (\u0026gt; clock 0) (set! clock (- clock 1)) (when (= clock 0) (handler))))) (define-syntax timed-lambda (syntax-rules () ((_ formals exp1 exp2 ...) (lambda formals (decrement-timer) exp1 exp2 ...)))) (define make-engine (let ((do-complete #f) (do-expire #f)) (define timer-handler (lambda () (start-timer (call/cc do-expire) timer-handler))) (define new-engine (lambda (resume) (lambda (ticks complete expire) ((call/cc (lambda (escape) (set! do-complete (lambda (ticks value) (escape (lambda () (complete ticks value))))) (set! do-expire (lambda (resume) (escape (lambda () (expire (new-engine resume)))))) (resume ticks))))))) (lambda (proc) (new-engine (lambda (ticks) (start-timer ticks timer-handler) (let ((value (proc))) (let ((ticks (stop-timer))) (do-complete ticks value)))))))) (define fibonacci (timed-lambda (n) (if (\u0026lt; n 2) n (+ (fibonacci (- n 1)) (fibonacci (- n 2)))))) (define eng (make-engine (lambda () (fibonacci 10)))) (eng 1 list (lambda (new-eng) (set! eng new-eng) \u0026#34;expired\u0026#34;)) Macro C语言的程序需要经过预编译进行宏展开之后才生成真正待编译的程序，同理 Scheme 程序也要经过 syntax expander 展开之后得到真正待解释的 S-Expression。但相比C语言单纯做字符串替换的宏，Scheme 宏有以下两个特点：\nScheme 中的宏是卫生宏（Hygienic Macro，宏扩展的代码和程序中的代码是相互独立的，宏扩展不会引入程序中未定义的变量或函数，也不会改变程序中已有的标识符的含义。\nScheme 中的宏做的是 pattern-based transformations。因为Scheme程序本身用 S-Expression 表达，所以非常容易做 pattern match 之后 transformation。\n具体而言，Scheme 通过 define-syntax 等方法将定义一系列 transformer，并指定一个 keyword，之后只要遇到该 keyword，就会尝试 pattern match 并作变换，例子如下：\n(define-syntax cond (syntax-rules (else) ((_ (else e1 e2 ...)) (begin e1 e2 ...)) ((_ (e0 e1 e2 ...)) (if e0 (begin e1 e2 ...))) ((_ (e0 e1 e2 ...) c1 c2 ...) (if e0 (begin e1 e2 ...) (cond c1 c2 ...))))) 上述例子中，cond 为 keyword，else 为 literal，表示程序中本来就有的 identifieer，不会在后续pattern match 中被认为是 pattern variable。当遇到一个 keyword 时，就会调用上述宏定义的 transformer，并一个 pattern 一个 pattern 试着匹配，如果匹配成功则进行变换。 如\n(cond (e0 e1 e2 e3) (else e4 e5 e6)) =\u0026gt; (if e0 (begin e1 e2 e3) (cond e4 e5 e6)) =\u0026gt; (if e0 (begin e1 e2 e3) (if e4 (begin e5 e6))) Summary 本文简单梳理了一下 Scheme 中我不太了解的几个特性——当然也仅仅是了解了一下，且背后牵扯到的PL/逻辑学理论甚至是精巧的实现都是没有本文涉及的。\n如果后面能够实现 continuation 以及 pattern match，也可谓是壮举了。\n","permalink":"https://rzyn2020.github.io/posts/scheme%E6%8B%BE%E9%81%97/","summary":"\u003cblockquote\u003e\n\u003cp\u003eProgramming languages should be designed not by piling feature on top of feature, but by removing the weaknesses and restrictions that make additional features appear necessary\u003c/p\u003e\u003c/blockquote\u003e","title":"Scheme 拾遗：S-Expression，Continuation 以及 Macro"},{"content":" When you are on the dancefloor, there is nothing to do but dance.\n有一道经典的Java面试题：\nInteger i = 100; Integer j = 100; System.out.print(i == j); // true or false? 由于之前没有准备直接上阵，在碰到这道题时一时不解。但显然这是考察autoboxing(自动装箱)机制，而一般整数转化为Integer对象时肯定是new一个新对象，按理说结果应该为false，但是考虑到在具体实现中可能为了效率考虑会预先缓存一部分整数对象，于是便猜测答案为true。下来网上一查，答案果然为true，但解释却是如下：\n这就有点奇怪了——我总觉得缓存多少是具体的编译器或者JVM抑或是相关类库实现的问题，而不该定义在语言规范中，而如果是和具体实现相关的，那么言之凿凿256个数字需要缓存就有点奇怪了。上网查查资料之后，发现256这个数字果然还是Integer类的默认实现中决定的。下面我就综合查找的资料，介绍一下这道题背后可能涉及的知识。\nReference Type 和 Primitive Type 首先Java类型系统以及JVM中，任何 Value(值) 要么是 reference type(引用类型)，要么是 primitive type(基本类型)。所谓reference type就是指向一个对象的值，总是一条new指令的返回值，往往是自身具有一定状态，并可以改变的(mutable)，在JVM实现中为一个指向具体对象的指针；而 primitive type的值 则只能通过字面量或是预先定义的在primitive type上的操作获得，而操作并不改变值本身，只是产生了一个新的值，即是不可变的(immutable)的，在JVM实现中也对应实现语言的primitive type(可以理解为c++中的Int)。\n但是在许多其他面向对象语言中(如Python)，一切皆是对象，一切值皆是引用。这样做比Java好理解许多，具体实现上也易于实现了。但是却带来了效率的低下，这主要有两点原因：\n对于整数这样的在编程中最基本且常用的值，如果每次两数相加都返回一个新对象，则是对资源的极大浪费。 你可能会想：为什么不把整数对象做成单例的？也就是一个只有一个1对象，也只有一个2对象，每次 1 + 1 总能得到同一个2 —— 但注意reference type的特征就是mutable，如果这样就做不到mutable了，和用primitive type表示整数也就没有区别了。 在JVM执行时，遇到引用需要先解引用才能获取整数值，然后再相加，之后封装成整数对象并返回引用，与直接将整数表示为实现语言的primitive type相比效率天差地别。 因此，为了效率考虑，则需要把整数，浮点数等归入primitive type。这样做就又产生了一个问题：在JVM中，一个值即可能是用实现语言的primitive type表示，也可能用指针表示，我们如何对二者进行区分呢？幸好Java是静态类型语言，在编译之后每条指令所操作的值的类型也是确定的。比如当执行iadd指令时栈上存的值就一定为两个整数。但在动态语言中就不一定了，我们必须要先检查类型是否匹配，然后进行操作。此时为了标明一个值究竟是primitive type还是reference type，我们必须把值的高位留出来作为类型tag以示区分。\n// 动态语言虚拟机中的一个值往往是这个样子的 struct Value_t { Type type; union { double number; bool boolean; HeapObject* object; } data; }; Generic 既然有了primitive type的整数，似乎再也不需要作为对象的整数了？看起来似乎是这样，但是Java却依然提供了Integer类表示作为对象的整数——这主要还是因为为了支持泛型的存在。\nJava的泛型是通过类型擦除实现的，也就是泛型信息只在编译期可见，而在运行期(也就是JVM)不可见。无论你是写成List\u0026lt;String\u0026gt; 还是 List\u0026lt;A\u0026gt; ，它们在编译后都会变成同一个List，而这个List存储的是Object对象。\n// 泛型类： public class Box\u0026lt;T\u0026gt; { private T t; public void set(T t) { this.t = t; } public T get() { return t; } } // 上面的泛型类在编译成字节码后 public class org/example/Box { private Ljava/lang/Object; t public \u0026lt;init\u0026gt;()V ... public set(Ljava/lang/Object;)V ... public get()Ljava/lang/Object; ... } 因为实际上用Object存储，所以每次get都是做了一次强制类型转换，Java编译器会生成CHECKCAST指令来保证类型转换时的正确性。\n// java代码 System.out.println(stringBox.get()); // 编译后的字节码 INVOKEVIRTUAL org/example/Box.get ()Ljava/lang/Object; CHECKCAST java/lang/String INVOKEVIRTUAL java/io/PrintStream.println (Ljava/lang/String;)V 但是如果泛型已经由编译器保证没有类型错误，为什么又要加CHECKCAST指令来运行时再次检查呢？考虑如下泛型程序，在可以通过编译，但在运行时CHECKCAST会报错：\npublic class Main { public static void main(String[] args) { Box stringBox = new Box\u0026lt;\u0026gt;(); stringBox.set(5); foo(stringBox); } public static void foo(Box\u0026lt;String\u0026gt; box) { System.out.println(box.get() + \u0026#34;123\u0026#34;); } } //Exception in thread \u0026#34;main\u0026#34; java.lang.ClassCastException: class java.lang.Integer cannot be cast to class //java.lang.String (java.lang.Integer and java.lang.String are in module java.base of loader \u0026#39;bootstrap\u0026#39;) //\tat org.example.Main.foo(Main.java:14) //\tat org.example.Main.main(Main.java:10) 这是因为Java为了让新代码和没有泛型之前(Java8)的代码兼容，而引入了Raw Type，也就是没有泛型参数的泛型——对这种类型的检查会适当放松——代价就是动态检查的开销。\n当然泛型不仅仅可以通过类型擦除实现，像C++的模板就是走向了另外一个极端——为每个类型都生成相应的类——这样的缺点自然是代码膨胀，好处却是可以动态获取类型信息(C++是否支持反射暂且不论，但如果Java采取和C++一样泛型机制就一定会支持这样的反射的)，不需要动态类型检查，也不需要像Java一样的Integer类。\n好，话题又回到Java的Integer类，正是应为Java的泛型是通过类型擦除实现，所以所有的泛型在背后都有一套统一的表示——也就是Object。但是primitive type却在Java OO继承链之外，也就无法使用泛型了——所有就引入了将primitive type封装成wrapper type的机制。将int封装为Integer即是一个例子。\nAutoboxing and Integer Cache 虽然已经有了wrapper type，但每次手动封装也是非常麻烦的。所以编译就加入了自动检测类型，在合适的时候将primitive type转化为相应的wrapper type，将wrapper type转化为相应的primitive type的机制，也就是“Autoboxing”与“Unboxing”\n所以说，面试题中Integer i = 100;等即采用了Autoboxing 机制，上面的代码在编译处理过之后就等价为下面的代码：\nInteger i = Integer.valueOf(100); Integer j = Integer.valueOf(100); System.out.print(i == j); // true or false? 已知引用比较在java中是直接比较地址，那么我们只需要知道Integer.valueOf做了什么就知道面试题的答案了。\n查阅 java doc，发现:\npublic static Integer valueOf(int i) Returns an Integer instance representing the specified int value. If a new Integer instance is not required, this method should generally be used in preference to the constructor Integer(int), as this method is likely to yield significantly better space and time performance by caching frequently requested values. This method will always cache values in the range -128 to 127, inclusive, and may cache other values outside of this range.\nParameters:\ni - an int value.\nReturns:\nan Integer instance representing i.\nSince:\n1.5\n所以说，除开根据Integer类的实现不同会有不同表现，如果只看标准类库的话那么面试题还没问题的，缓存值的Integer Cache大小总是大于256。但注意到 java doc 中说“may cache other values outside of this range”，这也许就说明还有调节的空间？果然，经查阅，-XX:AutoBoxCacheMax 选项就可以调节Integer Cache的大小。\n在我本机的Open jdk19中，Integer.valueOf实现如下：\n@IntrinsicCandidate public static Integer valueOf(int i) { if (i \u0026gt;= IntegerCache.low \u0026amp;\u0026amp; i \u0026lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); } 而用到的IntegerCache类实现如下：\nprivate static class IntegerCache { static final int low = -128; static final int high; static final Integer[] cache; static Integer[] archivedCache; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = VM.getSavedProperty(\u0026#34;java.lang.Integer.IntegerCache.high\u0026#34;); if (integerCacheHighPropValue != null) { try { h = Math.max(parseInt(integerCacheHighPropValue), 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(h, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; // Load IntegerCache.archivedCache from archive, if possible ... // Use the archived cache if it exists and is large enough ... // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high \u0026gt;= 127; } ... } 再追踪调用链可以发现VM类表示VM的各种选项，均有System类中的方法设置，但System类中方法又由谁调用，并从哪里知道参数呢？再追踪就会发现，果然这些命令行参数的解析和传入都是通过native method来实现的。\n","permalink":"https://rzyn2020.github.io/posts/autoboxing-and-integercache-in-java/","summary":"\u003cblockquote\u003e\n\u003cp\u003eWhen you are on the dancefloor, there is nothing to do but dance.\u003c/p\u003e\u003c/blockquote\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"Autoboxing and IntegerCache in Java"},{"content":" Surely all this is not without meaning.\n虽然题目起得很大，但是内容也只涉及了编译器实现的一小部分，主要还是一些自己对编译器high level的认识，加上部分cs143实验的总结。\n什么是编译器 一个编程语言可以看作一个从它的合法程序集合到运行时行为的total function，设为f。我们编程则是已知运行时行为b，求解出一个合法程序a以使得f(a)=b的过程。函数f一般都为可计算函数，且f对应的计算规则也是比较特殊以使得我们也较易掌握的，具体而言，就是可以采用模块化，分而治之这样的思想来构造出a，这种计算规则常常表现为定义在AST上的求值规则(如opretional semantic)。\n确定合法程序的集合的规则一般被称为 syntax\n而total function f 一般被称为 semantics\n有一部分的编程语言u被称为unsafe的，因为codom(u)往往含有一些我们——编程人员觉得不好的行为。比如该行为取决于目标代码所运行的机器，或是产生该行为的计算规则十分特殊(比如说数组越界不报错而是返回42)。而相应的，codom(u)均是好的行为的编程语言我们称为safe的编程语言。safe语言的例子有java，而c则是一个unsafe的语言。不过在实际编写代码，尤其是系统软件中，就算是safe的语言也往往会进行一些扩展，以允许编写一些与具体机器有关的unsafe操作。\n当然编程语言仅仅定义为total function还是不够的，要想让编程语言不仅仅是我们脑海中的方程，我们还需要让机器去运行它。但机器有着自己的语言，我们必须把编程语言翻译为机器语言才可以让机器去运行。我们把机器的语言称为目标语言，其一段程序称为目标代码，而我们的编程语言称为源语言，其一段程序称为源代码。由于目标代码是可以被机器运行并表现出运行时行为，我们也可以把一个编程语言f的值域看作是目标代码的集合。f在计算机上的实现就称作编译器。\n但是由于合法程序只是所有字符串的一个子集，而我们可以给编译器输入任何字符串，因此编译器必须还有错误程序检测的功能。因此，我们使用的编译器的一般都会有两项功能，其一是代码形式的转换，其二是拒绝错误的程序。因此我们可以把编译器看作从源代码到目标代码的partial function。\n编译器的结构 编译器可以被分为几个相互独立的部分，分别实现，然后用管道组合起来。CS143中cool的实现也是如此：该实验的最后你会获得lexer，parser，semant，cgen四个可执行文件，可以用如下shell脚本组合起来得到一个完整的编译器./lexer $* | ./parser $* | ./semant $* | ./cgen $*。其中 lexer，parser 对应的是语法分析阶段，semant对应的是语义分析阶段，而cgen对应的是代码生成阶段。\n除cgen/代码生成之外每个部分/阶段都有两项任务，一是检查并拒绝错误的程序，二是进行代码形式的转换。而cgen只有进行代码形式的转换一个任务，因为在cool以及大部分编译器的设计中，代码生成阶段都假定输入已经是合法的程序。\n每一阶段的工作可以看作一个数学函数f(X-\u0026gt;Y)，定义域X为该阶段能处理的输入,Y为可能的输出的集合。假如lexer，parser，semant，cgen都看作数学函数，则compiler = cgen ∘ semant ∘ parser ∘ lexer。具体来说，\ndom(lexer) = {文本程序} codom(lexer) = {token流} dom(parser) = {token流} codom(lexer) = {语法树} dom(semant) = {语法树} codom(lexer) = {装饰后的语法树(主要指添加类型信息)} dom(lexer) = {装饰后的语法树} codom(lexer) = {目标代码} 但是，值得注意的是，这里的函数都是 **partial function，**即并非每个定义域的值都有陪域的值与之对应，这些值就代表这编译过程的发现的错误程序，编译器会报错并提示用户修改。\n之所以一个compiler要被拆分为几个独立的部分，是因为这些部分的功能都相当内聚，互相之间联系较少。从错误处理的角度来看，lexer是用正则表达式排除错误程序，而parser是用CFG排除错误程序，semant做的事情则比较复杂，采用了多种技术来排除掉错误程序，并输出合法程序。\n我们又常常说 由 lexer 和 parser 定义了语法规则，通过lexer和parser检查的是满足语法规则的程序，这个阶段所以被称为语法分析阶段\nsemant定义了静态语义规则，通过semant检查的是满足静态语义规则的程序，这个阶段所以被称为语义分析阶段。\n语义分析阶段的任务 因此，semant做的事被称为语义分析，它会做许多检查：比如说检查标识符必须先声明再使用，类继承图必须无环之类的。但是语义分析阶段做的最重要的一件事则是类型检查，其目的是检查程序满足type rules，而type rule即是type system的主要组成部分。不过类型检查也不必非得在语义分析阶段做，有的语言也将类型检查纳入运行时，具体类型系统做了什么样的检查，这还得要从编程语言的求值规则说起。\n编程语言写成的程序虽然是字符串，但这个字符串却实际上表示了一种树型结构，我们把这个树型结构叫做对应字符串的语法树。为什么要用树型结构？因为树型结构的表达能力足够强，也是易于理解的。我们所能构建的大部分复杂事物往往都只采用了组合和抽象两种手段。组合即是将基本的事物放在一起，而抽象指将许多事物忽略其细节，只关注其整体作用。如在Scheme中，基本的元素就是整数字面量，而组合的方法则有+, -, *, /等运算，而抽象则是函数。\n一般来说，语法分析阶段只负责保证程序确实表达了一个树型结构即可\n剩下的检查都是语义分析的任务了\n但并非任意种类元素都能组合，抽象，一种运算可能只能组合某种特定类型的元素，比如说 1 + 2 就是对的，但是 1 + \u0026quot;2\u0026quot;就是不对的(不对指在程序员看来，这是无意义的。假如程序员真的写出了这样的程序，则他会希望编译期或是运行时报错，而非一声不吭执行下去得到一个奇怪的结果)。我们可以给语法树的每个节点都赋予一个类型，并定义类型推导的规则，这些推导规则的集合就叫做该语言的类型系统。\n上面说的检查过程就叫做类型检查，检查程序是否满足类型系统的规则，是语义分析中最为重要的一个部分。在程序员眼中，类型检查如果静态能做自然好，但是动态报错也是无妨的——只要不一声不吭地执行就算是好的行为，动态类型检查的语言也可以是safe的。虽然动态进行检查会导致程序运行时错误增多，但是却增加了许多灵活性。\n一般在编译器语义分析过程中进行类型检查的语言称为静态语言，而动态类型检查的语言称为动态语言。\n另外我们常常会用到强类型语言与弱类型语言两个词，这两词的含义并未明确定义，而是依赖于语境。一般来说，如果一个语言不会因类型错误而产生unsafe行为，则称为强类型语言，反之则称为弱类型语言。\n代码生成阶段的任务 通过语义检查的程序都是合法的程序，下一步就应该将合法的程序转化为目标代码了。但值得注意的是，lexer，parser以及semant中也都进行了代码形式的转换，将程序代码从字符流转化为了语法树(可能还伴随着符号表的填充)。和错误处理一样，lexer也是通过正则表达式来讲字符串识别为一个个token，parser也是通过CFG从token流中构建语法树。而semant只是遍历已建好的语法树并收集信息。lexer和parser合称为语法分析，在许多编译器实现中两个阶段是紧密耦合在一起的，Antlr，Pest等语法分析工具也是同时做了lexer和parser的事情，你只需要向这些工具中输入语言语法的specification，这些工具就会自动生成将字符串转化为语法树的代码。这些语法分析工具背后的理论则涉及形式语言与自动机，可以说是计算机理论在实际软件编写中非常成功的应用了。\n与语法分析阶段，代码生成阶段往往没有如此自动化的工具或是普遍性的理论支撑——当然语言的语义是有operational semantics,denotational semantics 等形式化方法定义的，但是就算是用最贴近实现的operational semantics 来指导实现，我们所得到的也只能是一个效率低下的解释器。因为这些形式化的语义定义往往是直接在AST上定义，以AST层面的概念为程序状态，而我们想要的是将AST直接映射到一种低级语言，这往往是需要程序员自己去思考如何实现的。\n将高级语言的许多概念，如类，对象的创建，控制流等映射到低级语言的过程在我看来是一件非常神奇的事情。在之前我也曾学过汇编语言，学过一些高级语言，但二者之间如何进行转换确实在我学习编译原理之前万万没有想到的。下面就拿cool举个例子：\nclass A { method1() : SELF_TYPE { // 1 self }; method2() : SELF_TYPE { // 2 self }; }; class B inherits A { method1() : SELF_TYPE { // 3 self }; method3() : SELF_TYPE { // 4 self }; }; /////////////////////// 5 let b: A in { let a : Int \u0026lt;- rand() in { if a % 2 == 0 then { b = new A() } else { b = new B() } } b.method1() } 当有一个B类的对象b时，代码中的b.method1()会调用3处的方法，并把对象自己绑定到self上，而b.method2()则会调用2处方法，b.method3自然也会调用4处的方法。到此为止一切似乎还算好实现，每个方法都对应一段代码，要知道一个方法调用究竟对应哪个方法，我们可以先在B类中找该方法，如果找到就生成call这个方法的低级语言代码，如果找不到则到其父类中去找。这样似乎一个call调用哪个方法静态时就已经决定了。\n但是考虑5处的代码段，在cool中b.method1()会根据b的实际类型来选择到底调用哪个方法。假如运行时发现b是B类对象，则会调用3处方法，否则会调用1处方法。根据运行时状态来决定调用哪段代码？这应该如何实现？初听之可能觉得不可思议，但是看了实现之后却发现又无比自然。\n在cool中，一个Class在内存中以这样的形式存储：\n首先是有一个class_objTab，其中包含了每个类的原型与初始化方法的地址，我们在new一个类时，实际上是将原型拷贝一份，然后调用其初始化方法。而如何获得其原型和初始化方法呢？这就是通过offset以及class_objTab的地址算出的了。当然了，对于初始化方法和原型对象，我们也可以不通过查class_objTab表而直接得到其地址。\n而每一个类原型，也就是XXX_protObj，都包含以下几部分：{classTag ObjectSize DispatchTablePointer}，其中classTag表明其在class_objTab中的位置，而ObjectSize表示其大小(如果类含有成员变量自然size就会增大了)，DispatchTablePointer指向一个包含许多方法的表，这个表在c++中的对应被称为虚函数表。\n当我们生成调用b.method1()的代码时，我们不需要知道method1的实际地址，我们只要知道该对象指向的虚函数表中的第几位对应名为method1的方法就行了。如下面代码所示，在继承关系中重载时会直接将父类同名方法覆盖，因此对于method1，无论b是B类还是A类对象，它们需要调用的method1都在各自对象的虚函数表的相同位置，这样就实现了调用哪个方法的动态决定，也就是Java中所说的动态绑定。\nclass_objTab: .word Object_protObj .word Object_init .word A_protObj .word A_init .word B_protObj .word B_init ... A_protObj: .word 9 .word 3 .word A_dispTab .word -1 A_dispTab: .word Object.abort .word Object.type_name .word Object.copy .word A.method1 .word A.method2 B_protObj: .word 10 .word 3 .word B_dispTab .word -1 B_dispTab: .word Object.abort .word Object.type_name .word Object.copy .word B.method1 .word A.method2 .word B.method3 当然cool也支持“静态绑定”，你可以直接显示写出要调用的方法是哪个类中的，比如b@B.method1()会直接调用3处方法，而b@A.method1()则会直接调用1处方法，并不需要动态通过虚函数表间接得到。\n虽然说上面cool的对象模型很好地支持了动态绑定，但仔细想想，classTag似乎又是多余的——在new一个对象时完全可以静态决定其原型和初始化方法的位置。但是由于cool还是实现了另一种功能，因此classTag还是必要的：\n由于cool支持上图所示的case expression，也就是当expr0为不同类型时执行不同的代码，具体来说，会执行在typek中在继承链条上距离expr0的实际类型最近的分支的代码。比如 A继承自B，B继承自C，假设a为A类对象\ncase a of: x1 : C =\u0026gt; expr1; x2 : B =\u0026gt; expr2; esac 上述代码则会执行expr2。\n考虑将上面的代码翻译为机器代码，我们就需要运行时判断一个对象的是否为某个类，因此也就必须有一个来标识类身份的classTag了。但以上代码不仅仅要求我们运行时判断一个对象是否精确为某个类，还要求能给定一堆类，判断哪个类是该对象继承链上最近的类，这就要求我们在目标代码中还要维持一些与继承相关的信息了。这种相关信息自然可以在对象模型中新加一个域来指向其父类，但是用一个trick之后也能通过classTag来维持上述case expression所需的信息。\n如果我们在给程序中的类分配classTag时，满足“该类的所有子类的classTag都在某个确定的区间”这个性质，我们就能在运行时判断判断继承关系了，而case expression中的所要求的\u0026quot;继承链上最近\u0026quot;我们则可以通过对所有分支的类按照继承关系做一个拓扑排序，然后从继承链的最低端开始判断即可。而满足上述性质的classTag的分配方式也有许多，前序遍历序号则是一个例子。\n另外，关于如何在编译到机器码的语言中实现GC，这是我之前总也想不到的，但学习了cool之后才发现，原来只需要在每次new完一个对象之后调用GC处理函数就会进入GC过程，而只要分配对象时只需在对象头前预留一定的空间，GC就可以在这些空间做一些标记，从而实现垃圾回收相关算法了。\n","permalink":"https://rzyn2020.github.io/posts/%E7%BC%96%E8%AF%91%E5%99%A8%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E4%BB%BB%E5%8A%A1/","summary":"\u003cblockquote\u003e\n\u003cp\u003eSurely all this is not without meaning.\u003c/p\u003e\u003c/blockquote\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"编译器的结构与任务"},{"content":" You are my creator, but I am your master; Obey! 导言 操作系统大体来说即是“管理软/硬件资源，为程序提服务”的程序。我们一方面可以从应用的视角把操作系统当作服务的提供者，去学习如何使用操作系统提供的API，如POSIX或是windows api，另一方面也可以深入其内部去学习它的实现。操作系统的实现紧密围绕着管理资源与提供服务两项任务展开，而对硬件资源的管理是实现中最为“dirty”的一部分。为了能屏蔽这些琐碎的硬件细节，让我们把精力集中在操作系统中各个对象的交互上去，jyy通过AM提供了一组API，抽象出了硬件提供的服务，从而把OS真正变成了一个普通的C程序。\n可是屏蔽太多的细节也会让人感到不安与心虚——内存的地址空间到底是怎样被决定的？页表究竟是怎样实现的？各个处理器上执行流刚刚开始时的栈又是谁决定的？当然，OS作为ICS的后继课程，是默认我们对于计算机体系结构有一定了解的，上述问题在ICS的PA实验中也都有答案——理论上在PA中我们应该已经自己实现了从硬件模拟器到AM再到简易操作系统的所有内容，对于OS和硬件如何交互应该再熟悉不过了——但是，对于我这个在PA后期全程摆烂的人来说，这些问题始终是模模糊糊不知所云的。“欠下的债终究是要还的”，所以我的OS就stuck住了，所以我才会在这里从xv6和riscv入手看看OS是究竟如何在硬件上运行起来的。\nqemu vitr OS终究是要运行在硬件上的，而qemu提供了对硬件的模拟。由于我选取的是riscv64版本的xv6，因此运行xv6的qemu必须模拟基于riscv64架构的机器。\n可以看到qemu提供了对于多种机器的模拟，其中xv6所使用的是virt，qemu-virt是一个虚拟的机器，该机器是仿照真实世界中的 SiFive FU540-C000 开发的。\n先不管各种设备与该机器的具体结构，对于一个操作系统来说我们最关心的是cpu reset后的状态，包括内存空间的分配与各个寄存器的值。SiFive FU540-C000 Manual的第五章就介绍了memory map。当然，如果觉得manual太过难读，在运行时通过qemu monitor亲眼看看机器的状态也是一种选择。\n我们可以在qemu中使用-S 选项令qemu在初始化完成 (CPU Reset) 后暂停\n我们运行qemu时使用的命令如下：\n# 各个选项意义可RTFM https://www.qemu.org/docs/master/system/riscv/virt.html qemu-system-riscv64 -machine virt -bios none -kernel kernel/kernel # 通过-kernel 选项直接把可执行文件加载到内存空间中 -m 128M # 分配128M RAM -smp 1 -nographic -monitor telnet:127.0.0.1:55555,server,nowait -drive file=fs.img,if=none,format=raw,id=x0 -device virtio-blk-device,drive=x0,bus=virtio-mmio-bus.0 -S -gdb tcp::26003 之后进入qemu monitor中查看memory map和寄存器状态。\n可以发现，在CPU reset后，除pc值为0x1000外，其余寄存器值均为0x0。而在第一张图中可以发现内存的0x1000 到 0x11fff通过mmio映射到了rom中，\n通过gdb检查内存可以发现，rom中存储了以上几条指令。\n通过这几条指令，pc将跳转到0x80000000处开始执行，而从memory map中也可以得知0x80000000是我们为virt分配的 128M 内存的开始，我们所写OS的第一条指令也位于这个位置。\nkernel的链接 上一节说到，我们的OS的第一条指令位于0x80000000处，而kernel是被当作可执行文件通过-kernel选项直接加载进地址空间的。\n通过readelf命令查看kernel的信息如下：\n可以看到到，加载位置的确是写在elf文件中的，qemu也确实忠实地按照elf的说明加载了可执行文件kernel。\n但是为什么kernel会存储这样的信息呢？是谁决定Entry Point的位置，是谁决定的VirtAddr与Size呢？这些都是通过 -T kernel/kernel.ld为链接器指定的linkScript确定。\n（另外，默认的linkScript可以通过ld --verbose查看）\n// kernel/kernel.ld OUTPUT_ARCH( \u0026#34;riscv\u0026#34; ) ENTRY( _entry ) SECTIONS { /* * ensure that entry.S / _entry is at 0x80000000, * where qemu\u0026#39;s -kernel jumps. */ . = 0x80000000; .text : { *(.text .text.*) . = ALIGN(0x1000); _trampoline = .; *(trampsec) . = ALIGN(0x1000); ASSERT(. - _trampoline == 0x1000, \u0026#34;error: trampoline larger than one page\u0026#34;); PROVIDE(etext = .); } .rodata : { . = ALIGN(16); *(.srodata .srodata.*) /* do not need to distinguish this from .rodata */ . = ALIGN(16); *(.rodata .rodata.*) } .data : { . = ALIGN(16); *(.sdata .sdata.*) /* do not need to distinguish this from .data */ . = ALIGN(16); *(.data .data.*) } .bss : { . = ALIGN(16); *(.sbss .sbss.*) /* do not need to distinguish this from .bss */ . = ALIGN(16); *(.bss .bss.*) } PROVIDE(end = .); } riscv特权模式 在我们大体明白程序是如何被编译链接以及被加载到内存中之后，就可以开始去一行行读代码了。但在这之前，我们还得要清楚所谓对于硬件的控制最终是要通过机器代码来实现的，由于汇编代码和机器代码有着良好的对应关系，为了精准地控制硬件我们不得不用到一些汇编代码，这就要求我们对于riscv比较熟悉了。\nriscv的规范详见(Volume I, Volume II)，其中卷一定义了实现通用计算的一些指令和寄存器，而卷二则定义了一些特权指令和CSR寄存器(Control and Status Registers)。通用指令不需多说，无非是内存访问与计算之类。而特权指令和CSR寄存器则既是实现OS所必须的，又是我所不熟悉的。\nriscv定义了三种特权模式 —— user mode，supervisor mode，以及machine mode。在三种不同的特权模式下运行的代码也对硬件有着不同的控制权限，更高一级的级别能进行低级别的所有操作，反之不行。我们的用户程序一般运行在user mode中，而OS内核一般运行在supervisor mode中，machine mode是CPU reset之后的模式，仅用来做一些初始化配置。（部分嵌入式的riscv实现可能只支持machine mode，或者只支持machine mode和user mode，但现代化的操作系统一般都需要supervisor mode的支持）\nriscv定义了一组CSR寄存器，我们可以通过对CSR寄存器的读写来控制机器的状态。每种特权模式下都有自己对应的一组寄存器。由于寄存器数目较多，也并不需要全部理解，所以我们可以从阅读xv6代码开始，遇到没有见过的寄存器就去查阅手册，按需学习。\n初始化 # qemu -kernel loads the kernel at 0x80000000 # and causes each CPU to jump there. # kernel.ld causes the following code to # be placed at 0x80000000. .section .text .global _entry _entry: # set up a stack for C. # stack0 is declared in start.c, # with a 4096-byte stack per CPU. # sp = stack0 + (hartid * 4096) la sp, stack0 li a0, 1024*4 csrr a1, mhartid addi a1, a1, 1 mul a0, a0, a1 add sp, sp, a0 # jump to start() in start.c call start spin: j spin xv6执行的第一段代码位于entry.s ，此时还处于machine mode。其中mhartid寄存器是一个machine mode的寄存器，表示当前cpu的序号，该寄存器只能在machine mode下被读取。在通过给sp 赋初值初始化好栈之后就进入了start函数，正式跳入了C代码。在start函数中执行的操作也均在machine mode下。\nvoid start() { // set M Previous Privilege mode to Supervisor, for mret. unsigned long x = r_mstatus(); x \u0026amp;= ~MSTATUS_MPP_MASK; x |= MSTATUS_MPP_S; w_mstatus(x); // set M Exception Program Counter to main, for mret. // requires gcc -mcmodel=medany w_mepc((uint64)main); // disable paging for now. w_satp(0); // delegate all interrupts and exceptions to supervisor mode. w_medeleg(0xffff); w_mideleg(0xffff); w_sie(r_sie() | SIE_SEIE | SIE_STIE | SIE_SSIE); // configure Physical Memory Protection to give supervisor mode // access to all of physical memory. w_pmpaddr0(0x3fffffffffffffull); w_pmpcfg0(0xf); // If PMP entry 0’s A field is set to TOR, zero is used for the lower bound, and so it matches any address y \u0026lt; pmpaddr0. // ask for clock interrupts. timerinit(); // keep each CPU\u0026#39;s hartid in its tp register, for cpuid(). int id = r_mhartid(); w_tp(id); // switch to supervisor mode and jump to main(). asm volatile(\u0026#34;mret\u0026#34;); } start函数中对各个寄存器的读写均是通过内联汇编实现的，每个读写在xv6中也均有注释表明其作用。在进行一系列初始化后，通过mret指令即进入supervisor mode，开始执行main函数.\n中断和异常 在对机器的初始化配置中，中断和异常是令我感到困惑较多的部分。\n首先，下图是riscv machine mode下和中断，异常相关的一组寄存器。 (supervisor mode和user mode下也有相应的sstatus，sip等CSR，其作用和对应的machine mode CSR类似)\nriscv中的异常指程序运行中由于某条指令而引发的错误，如访问了没有权限访问的内存，缺页错误或是ecall。在发生异常后会将当前的pc存储在mepc中(ecall除外，该指令会在mepc中存储pc+1)，然后将pc设为mtvec中提前存储好的值。无论当前cpu处于什么模式，在发生异常后都会进入machine mode。\nriscv将中断分为三种：时钟中断，软件中断和外部中断，其中是时钟中断是由CLINT管理并发起的，外部中断是由PLIC管理并发起的，而软件中断是通过写入某些寄存器来发起的。具体的结构如下：\nriscv中的mstatus寄存器控制着中断的状态，在machine mode下将MIE置为1就表示打开machine mode下的中断，同时从下图中也可以看出，machine mode下还可以通过读写SIE位来控制supervisor mode下的中断开关。\nmstatus控制总的中断开关，而mie则更细一步对三种中断进行控制，当且仅当MIE和MxIE都打开时，x类型的中断才算是打开。mip总是将正在处理的中断位置为1，另外Y模式对应的软件中断可以通过将YIP置为1引发。\n在特权模式X下，比X等级更高的模式Y下的中断始终是开启的，不论YIE的值为多少；同理比X等级更低的模式下的中断都是关闭的。\n当中断或异常发生时，二者都会将当前特权模式记录在mstatus的MPP位中，将当前中断状态记录在MPIE中，然后通过将MIE位置为0来关掉当前的中断。将pc置为mtvec，同时，发生中断/异常的原因会被记录在mcause寄存器中，以下是mcause寄存器可能记录的值：\n在中断处理函数处理完成之后，就会调用mret返回，mret会恢复在MPP中记录的特权模式以及在MPIE中记录的中断开关情况，然后将MPP和MPIE恢复为默认值。\n中断委托与时钟中断 由于我们的中断和异常都是需要在OS内核中处理的，因此进入trap之后应该是supervisor mode。但是由于riscv中默认所有中断和异常都由machine mode处理，因此riscv就提供了一个中断和异常委托机制来把machine mode的中断处理委托给更低级别的模式来处理，但是中断委托不能委托比被委托模式级别更高级别的中断。例如当把某中断委托给supervisor mode后，更supervisor 和 user mode下发生该中断时就会把返回地址写入sepc，把中断原因写入sstatus，然后将pc置为stvec。\nriscv通过medeleg CSR来对异常进行委托，通过mideleg CSR来对中断进行委托。我们可以在start函数中发现xv6把所有的中断和异常都委托给了supervisor mode，并打开了supervisor mode下的中断。\n但是值得注意的是，按照xv6 book的说法，时钟中断是无法被委托给supervisor mode的，即无论当前CPU是什么模式，CLINT发起的都是machine mode的中断，所以中断发生后也只能进入machine mode，将pc置为mepc。因此我们必须在machine mode下对时钟进行配置，并设置machine mode下的中断处理函数。具体配置见timerinit函数：\n// set up to receive timer interrupts in machine mode, // which arrive at timervec in kernelvec.S, // which turns them into software interrupts for // devintr() in trap.c. void timerinit() { // each CPU has a separate source of timer interrupts. int id = r_mhartid(); // ask the CLINT for a timer interrupt. int interval = 1000000; // cycles; about 1/10th second in qemu. *(uint64*)CLINT_MTIMECMP(id) = *(uint64*)CLINT_MTIME + interval; // prepare information in scratch[] for timervec. // scratch[0..2] : space for timervec to save registers. // scratch[3] : address of CLINT MTIMECMP register. // scratch[4] : desired interval (in cycles) between timer interrupts. uint64 *scratch = \u0026amp;timer_scratch[id][0]; scratch[3] = CLINT_MTIMECMP(id); scratch[4] = interval; w_mscratch((uint64)scratch); // set the machine-mode trap handler. w_mtvec((uint64)timervec); // enable machine-mode interrupts. w_mstatus(r_mstatus() | MSTATUS_MIE); // enable machine-mode timer interrupts. w_mie(r_mie() | MIE_MTIE); } 我们把mepc赋值为timervec，也就是专门处理时钟中断的trap。为了让时钟中断也能被supervisor mode下的trap处理，可以通过在timervec中将sip的相应位置为1，在mret后就会触发软件中断，这样就将machine mode下的时钟中断就转换为supervisor mode下的软件中断了。\n.globl timervec .align 4 timervec: # start.c has set up the memory that mscratch points to: # scratch[0,8,16] : register save area. # scratch[24] : address of CLINT\u0026#39;s MTIMECMP register. # scratch[32] : desired interval between interrupts. csrrw a0, mscratch, a0 sd a1, 0(a0) sd a2, 8(a0) sd a3, 16(a0) # schedule the next timer interrupt # by adding interval to mtimecmp. ld a1, 24(a0) # CLINT_MTIMECMP(hart) ld a2, 32(a0) # interval ld a3, 0(a1) add a3, a3, a2 sd a3, 0(a1) # raise a supervisor software interrupt. li a1, 2 csrw sip, a1 ld a3, 16(a0) ld a2, 8(a0) ld a1, 0(a0) csrrw a0, mscratch, a0 mret 虚拟内存 riscv的硬件机制中我所不熟悉的除了前面所说的初始化和中断处理外，就是虚拟内存了。\n由于xv6采取riscv64下的sv39分页模式，我就以此为例说明。\nriscv会在supervisor mode和user mode开启分页，分页是通过satp CSR来管理的。\nsatp通过MODE字段来选择分页模式并开启分页，在PPN字段存储当前根页表的地址。sv39模式是采取三级页表，页表均存储在RAM中，由OS填写。具体虚拟地址到物理地址的转换见下图：\n总结 在捋清楚硬件提供怎样的服务之后，OS终于变成了一个普通的C程序，AM里玄之又玄的API开始鲜活起来。\n","permalink":"https://rzyn2020.github.io/posts/%E6%8E%A2%E7%A9%B6%E6%94%AF%E6%92%91os%E7%9A%84%E7%A1%AC%E4%BB%B6%E4%BB%A5xv6%E5%92%8Criscv%E4%B8%BA%E4%BE%8B/","summary":"\u003cblockquote\u003e\n\u003cpre\u003e\u003ccode\u003eYou are my creator, but I am your master; Obey!\n\u003c/code\u003e\u003c/pre\u003e\u003c/blockquote\u003e\n\u003c!-- raw HTML omitted --\u003e","title":"探究支撑os的硬件(以xv6和riscv为例)"},{"content":" 凡治众如治寡，分数是也；斗众如斗寡，形名是也。\n本篇博客内容大多都来自Jeff的算法书籍，因书籍内容充实和有趣，读之后又怕忘记，因此摘抄复述自己感觉有趣内容，并适时加以扩展。\nIntro 在算术中，乘法是最基本的运算。数学往往只关心抽象的一般的东西，它只把数字看作数字本身，只把乘法看作为一种定义在数上的满足某种特定性质的运算，但是为了让数字能真正为我们所用，我们还必须定义数字实际上的表示方法，以及在一种表示方法下对数字进行运算的方法(比如乘法)——按照这种方法，任意给定两个数，我们都能得出其运算结果(乘积)。这样一种确定性的方法就可以称作一种算法。\n通俗意义上的算法即是指一系列明晰确定的指令(步骤)的序列，它描述了一个问题的可行解决方案。注意到组成算法的是一系列明晰确定的指令，我们把这些指令叫做原子指令，所谓原子就是指这些指令是最简单的，不可再分的指令了。如果要使算法是真正可行的，我们还必须确保原子指令是可行的。如果有一个算法，描述了如何成为富翁。而这个算法的一个原子指令是“先定一个小目标，我先挣它一个亿！”，那么这个算法对于我来说是显然是不可行的了😂。\n首先，如果数的表示方法为十进制整数，而个位数相乘或者相加都为原子指令的话，竖式计算法当然就是一种最好不过的算法了。\n其次，如果把数字定位为线段的长度，原子指令定为基本的尺规作图步骤的话，一种乘法的算法就是如下这样。\n当然，我们也需要有一些评价这些算法的指标以便在解决同一问题的不同算法间取舍。最重要的指标当然是算法正确性了，另外，算法执行的快慢也是一个很重要的指标，它可以用一个算法从开始到结束所执行的原子指令条数来衡量。由于计算指令条数的精确数目较为繁琐且意义不大，时间复杂度也就随之而出了。\n在计算n位数×n位数时，在使用十进制数字表示和竖式算法时，时间复杂度为$O(n^2)$，因为第一个数的每一个数字都要和第二个数的每一个数字相乘；使用几何模型和上图所述算法时，由于只需要有限个步骤，算法时间复杂度就是$O(1)$了。\n考虑到无论我们实际日常使用还是计算机表示，使用X进制表示法都是最常见的，把个位数的×和＋都作为原子指令也是最自然的，我们的研究对象也就主要集中在这种计算模型上了。那么问题来了，计算乘法的算法多种多样，有没有一种算法能以低于$O(n^2)$的时间复杂度来计算乘法呢？\nSplitMultiply 分而治之的思想在算法上的应用往往能得很好的效果。比如说利用了分治法的Quick-Sort, Merge-Sort都能得到很好的时间复杂度。相应的，也许分治的思想也能在乘法中起到作用。\n很显然，$(10^ma + b)(10^mc + d) = 10^{2m}ac + 10^m(bc + ad) + bd$，按照这个分解，就有了如下的分治算法：\n这个算法的正确性显而易见，但是要计算这样的递归算法的时间复杂度就较为困难了。不过，其用时的递推式却很容易写出来，即$T(n)=4T(n/2)+O(n)$，而要根据这个递推式求出$T(n)$的渐进式，递归树法能给我们很多Insight。\n将全部项求和，很容易得出时间复杂度任然为$O(n^2)$。\n但是，为什么Quick-Sort, Merge-Sort都可以成功降低复杂度呢？这可以从二者用时的递推式中看出了:$T(n)=2T(n/2)+O(n)$。\n再考虑递归树中的耗时大概分为两大部分，一部分是每次递归时的耗时，一部分是所有叶节点对应的最小子情况的耗时。假设递推式为$T(n)=aT(n/b)+f(n)$，不妨设当$n$为1时到达子节点，树高为H，叶节点数为L，则有$n/b^H=1 \\implies H=log_bn,L=b^H=a^{log_bn}=n^{log_ba}$,因此，叶节点对应的项的代价为为$\\Theta(n^{log_ba})$,而内部节点对应的代价为$\\Sigma_{j=0}^{log_bn-1}a^jf(n/b^j)$，因此，整个递归过程的用时就由这两项决定。由这两项的相对大小就可以得到整个过程的渐进复杂度。在对这两项进行分析之后，就得到了主定理，之后就可以以此为出发点分析算法的时间复杂度了。\nSplitMultiply算法符合情况一，也就是由于SplitMultiply算法的递归过程中每层节点扩展得太快，导致叶节点完全占据了主导地位，因此复杂度完全由叶节点决定；而两个分治的排序算法都符合情况二，即每层节点代价的总和差不多相同，因此最终时间复杂度为$\\Theta(nlogn)$。\nFastMultiply SplitMultiply的失败之处在于每层节点扩展得太快，即$log_ba$太大，因此有没有一种适用于乘法的分治算法使得$log_ba$较小呢？事实上，Karatsuba就把a从4降到了3，从而使得乘法的时间复杂度由$n^2$降至$n^{log_23}=n^{1.58496……}$。\nKaratsuba的想法主要来源于他发现，上面的分解式中$bc+ad$是一个整体，如能一次就把这个整体算出来，就能只调用三个递归子过程。考虑到$ac+ab-(a-c)(c-d)=bc+ad$，我们只需要额外计算一个$(a-c)(c-d)$即可获得中间的$bc+ad$的值。（注意到$a \\times 10^m$的复杂度实际上为$O(n)$）\n具体算法如下：\nKaratsuba在发现这个算法时还是一个23岁的学生。1950年代，苏联数学家Kolmogorov举办了一个研讨会，提出“任何n*n的乘法算法都不可能在$n^2$的时间复杂度以下”，可是在一周之后，Karatsuba就发现了这个算法。\n","permalink":"https://rzyn2020.github.io/posts/multiplication-part1/","summary":"\u003cblockquote\u003e\n\u003cp\u003e凡治众如治寡，分数是也；斗众如斗寡，形名是也。\u003c/p\u003e\u003c/blockquote\u003e","title":"Multiplication"},{"content":"int setjmp(jmp_buf env)\nvoid longjmp(jmp_buf env, int val)\nsetjmp 和 longjmp 是setjmp.h定义的相互协作的一组跳转函数。 调用 setjmp 时可以将当前的环境保存在一个jmp_buf类型的变量中，之后调用 longjmp 后会跳转到 setjmp 执行后的下一条语句执行，就好像刚刚从 setjmp返回一样。\n函数行为描述见man，源码见glibc。\n其中,jmp_buf的定义如下:\ntypedef long int __jmp_buf[8]; /* Calling environment, plus possibly a saved signal mask. */ struct __jmp_buf_tag { /* NOTE: The machine-dependent definitions of `__sigsetjmp\u0026#39; assume that a `jmp_buf\u0026#39; begins with a `__jmp_buf\u0026#39; and that `__mask_was_saved\u0026#39; follows it. Do not move these members or add others before it. */ __jmp_buf __jmpbuf;\t/* Calling environment. */ int __mask_was_saved;\t/* Saved the signal mask? */ __sigset_t __saved_mask;\t/* Saved signal mask. */ }; typedef struct __jmp_buf_tag jmp_buf[1]; 本来预想jmp_buf应该是简单的一个存储寄存器信息的数组，却发现其定义较为复杂。在阅读其定义的时候，又牵扯出了许多不熟悉的c知识点。试解析定义如下： 其中typedef struct __jmp_buf_tag jmp_buf[1]定义了一个名为jmp_buf的变量类型,它实际上是一个大小为1的struct __jmp_buf_tag数组。而结构体struct __jmp_buf_tag包含三个成员，后两个与信号机制有关，不做讨论。第一个成员为__jmp_buf类型，用来保存寄存器信息。而__jmp_buf类型实际上是一个大小为8的long int数组。 那么为什么要把实际上存储信息的结构体__jmp_buf_tag包含在一个数组里面呢？也许是因为将数组当作参数传递时总是传递数组的地址，而将结构体当作参数传递时却总是将整个结构体的值赋值一遍传给被调用函数。我们的jmp_buf作为一个在函数调用间保存信息的实体应该满足数组的特征，因此将其定义为数组更合适一些。当然，如果不这样做，每次被调用函数需要结构体__jmp_buf_tag时传入它的指针也是可行的，只是略显麻烦罢了。\nhint: 结构体定义了一种变量类型，作为一个整体复制和赋值。在行为上更加类似于int而非int[]; 变量名是与值绑定的符号，而指针是与一个地址值绑定的符号。\n","permalink":"https://rzyn2020.github.io/posts/%E6%B5%85%E6%9E%90jump-buf%E7%9A%84%E5%AE%9A%E4%B9%89/","summary":"","title":"浅析jmp_buf的定义"},{"content":"由于树本身定义的递归性，置于树上的操作往往也是递归性的的。\n在某些语言中，递归是自然的，最基本的语言要素(比如说scheme)，然而在另外一些语言中，递归却不是最基本的要素。\n图灵丘奇论题证明了图灵机和lambda演算的等价性，既然纯递归的lambda演算和给人毫无递归印象的图灵机的计算能力是相同的，那么一切递归方法自然都能用非递归方法模拟了。考虑到现实计算机中递归函数的调用就是通过栈实现的，因此我们可以在任何一门语言简单地利用栈来模拟递归。因此，对于树的任何递归操作都有与之对应的非递归方法了(尽管这种非递归方法任然是模拟递归的)。\n树的定义以及构造方法如下(用节点Node来表示树，用树的表达式字符串来构造树):\npublic class Node\u0026lt;Item\u0026gt; { Item item; Node left; Node right; Node(Item item, Node left, Node right) { this.item = item; this.left = left; this.right = right; } /** * @param tree 树的表达式 * 形如:\u0026#34;1(5(6(3,2),),5(5,3(1,)))\u0026#34; * \u0026#34;1(1(1(1(1,),),),)\u0026#34; * @return 树的头节点 */ public static Node makeTree(String tree) { if (tree == \u0026#34;\u0026#34;) return null; if (tree.length() == 1) return new Node(Integer.valueOf(tree), null, null); char[] t = tree.toCharArray(); int item = Integer.valueOf(tree.substring(0, 1)); int mid = 0; int bra = 0; for (int i = 2; i \u0026lt; t.length; i++) { if (t[i] == \u0026#39;(\u0026#39;) bra++; else if (t[i] == \u0026#39;)\u0026#39;) bra--; else if (t[i] == \u0026#39;,\u0026#39;) { if (bra == 0) { mid = i; break; } } } Node left = makeTree(tree.substring(2, mid)); Node right = makeTree(tree.substring(mid + 1, tree.length() - 1)); return new Node(item, left, right); } } 对于栈中每一个frame的模拟如下:\nstatic class frameSim { int retAddr; Node t; frameSim(int retAddr, Node t) { this.retAddr = retAddr; this.t = t; } } 前序，中序，后序的递归以及非递归遍历方法如下：\n其中用switch case语句模拟地址跳转。\npublic static void preOrder(Node t) { if (t == null) { return; } System.out.print(t.item); preOrder(t.left); preOrder(t.right); } public static void preOrderNonRec(Node t) { Stack\u0026lt;frameSim\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); frameSim current = new frameSim(-1, t); int pc = 0; while (true) { switch (pc) { case 0: System.out.print(current.t.item); case 1: if (current.t.left != null) { stack.push(current); current = new frameSim(2, current.t.left); pc = 0; continue; } case 2: if (current.t.right != null) { stack.push(current); current = new frameSim(3, current.t.right); pc = 0; continue; } case 3: } pc = current.retAddr; if (pc == -1) break; current = stack.pop(); } } public static void inOrder(Node t) { if (t == null) { return; } inOrder(t.left); System.out.print(t.item); inOrder(t.right); } public static void inOrderNonRec(Node t) { Stack\u0026lt;frameSim\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); frameSim current = new frameSim(-1, t); int pc = 0; while (true) { switch (pc) { case 0: if (current.t.left != null) { stack.push(current); current = new frameSim(1, current.t.left); pc = 0; continue; } case 1: System.out.print(current.t.item); case 2: if (current.t.right != null) { stack.push(current); current = new frameSim(3, current.t.right); pc = 0; continue; } case 3: } pc = current.retAddr; if (pc == -1) break; current = stack.pop(); } } public static void postOrder(Node t) { if (t == null) { return; } postOrder(t.left); postOrder(t.right); System.out.print(t.item); } public static void postOrderNonRec(Node t) { Stack\u0026lt;frameSim\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); frameSim current = new frameSim(-1, t); int pc = 0; while (true) { switch (pc) { case 0: if (current.t.left != null) { stack.push(current); current = new frameSim(1, current.t.left); pc = 0; continue; } case 1: if (current.t.right != null) { stack.push(current); current = new frameSim(2, current.t.right); pc = 0; continue; } case 2: System.out.print(current.t.item); case 3: } pc = current.retAddr; if (pc == -1) break; current = stack.pop(); } } ","permalink":"https://rzyn2020.github.io/posts/%E6%A0%91%E7%9A%84%E9%9D%9E%E9%80%92%E5%BD%92%E9%81%8D%E5%8E%86%E7%94%A8%E6%A0%88%E6%A8%A1%E6%8B%9F%E9%80%92%E5%BD%92/","summary":"\u003cp\u003e由于树本身定义的递归性，置于树上的操作往往也是递归性的的。\u003c/p\u003e","title":"树的非递归遍历—用栈模拟递归"},{"content":" 万物皆流，无物常驻\n导引 过程的抽象 流(stream)是在java8中出现的一种新的数据抽象，它对数据的处理有着较大的简化作用。\n流的概念可能最早来自于列表(List)，列表可以理解为按顺序排列的一组对象(数组和链表都是其具体实现)。\n大多数程序的最外在特征是给定一个输入后，按照某种规则得出相应的输出。编写由输入到输出的规则就是programmer所做的事情了。许多程序的规则都可以被抽象为三部分:\n根据输入产生一组数据 对第一步产生的数据组进行处理 对处理过后的数据约简而得到最终的输出 当然，最后约简的操作也可以算作数据处理的一部分。但由于它是最后一步操作，所以往往将它独立出来。\n这种抽象可以类比为国家选拔人才的机制。\n随着形式的变化，国家向大学提出了向H部门输送X专业的高级人才的要求。(这相当于用户输入) 大学招收了一群X专业的本科新生。(产生了一组数据) 大学对这些新生进行专业教育，淘汰掉挂科的学生。(处理数据) 毕业之时，将成绩优异的学生推荐给H部门。(约简得到输出) 也许正因为这种对过程的抽象方式天然地存在于人的大脑结构之中(是某种先验的思维模式)，我们才会很自然地将无论是社会还是计算机中的许多过程都按照这种方式进行抽象。\n从List到Stream 程序的三部分抽象中有两个关键部分:一是如何表示数据，二是如何处理数据。\n对于数据的表示，我们很自然地会想到使用List这样的计算机能支持的最简单数据集合来表示。\n对于数据的处理方式，我们抽象出了许多种类，比如说:\nmap: 对于List中的每一项数据都进行某种操作\nfilter: 删除List中某些不需要的元素\ncount: 得到List中总的元素数目\n有些处理方式(比如说count)，对List操作之后得到的并不是List，不再能连续地进行下一步操作，所以只能作为最后一步约简地处理方式。\n然而用一般计算机语言中的List表示数据组，却有以下两种缺点:\n一，不能表示无限数据组 二，每次处理都必须对每个元素都进行处理，造成了资源的浪费。(但实际上我们的程序可能只需要处理前几个数据就可以得出结果了) 因此，出现了一种新的数据抽象，流(stream)。流的主要特征即是惰性求值。而惰性求值很好地避免了以上两个问题。所谓惰性求值，即需要的时候再进行求值。\n比方说我们的数据组是一串5个白色乒乓球。要对这些乒乓球进行如下处理，首先是染蓝色颜料，其次染黄色颜料，最后我们要拿到第二个染色后的乒乓球。按照List的处理逻辑，我们要先把所有的球染成蓝色，然后将所有的球染成黄色，最后再取出第二个球。但是按照stream的处理逻辑，我们首先知道了要把球 染成蓝色，但我们先记住这个命令，却不实际操作。然后记住要染黄色的命令，也不实际操作。在最后一步，我们要拿出第二个染色后的球。这时候我们再依次对这些球进行处理。先处理完第一个球，然后处理第二个球，这时直接拿出第二个球即可， 而不需要对剩余球进行染色。\n此处笔者自感表达不清，关于stream的解释详见SICP3.5。\nstream API 由于stream的强大抽象能力，java8中新引入了stream API。java8中的stream即是上述概念模型的一种实现，并无特殊性。其主要操作自然也是分为stream的构造，处理以及约简三部分。下面三部分将分别记录常用的API。\n构造 由collection或Array转化 Collection:\ndefault Stream\u0026lt;E\u0026gt; stream()\nArray:\npublic static \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; stream(T[] array)\npublic static \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; stream(T[] array, int startInclusive, int endExclusive)\npublic static IntStream stream(int[] array)\npublic static IntStream stream(int[] array, int startInclusive, int endExclusive)\n以及类似的DoubleStream和LongStream方法\n由Stream直接创建 Stream:\nstatic \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; empty()\nReturns an empty sequential Stream.\nstatic \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; of(T t)\nReturns a sequential Stream containing a single element.\nstatic \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; ofNullable(T t)\nReturns a sequential Stream containing a single element, if non-null, otherwise returns an empty Stream.\n@SafeVarargs static \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; of(T... values)\nReturns a sequential ordered stream whose elements are the specified values.\nstatic \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; iterate(T seed, UnaryOperator\u0026lt;T\u0026gt; f)\nReturns an infinite sequential ordered Stream produced by iterative application of a function f to an initial element seed, producing a Stream consisting of seed, f(seed), f(f(seed)), etc.\nstatic \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; generate(Supplier\u0026lt;? extends T\u0026gt; s)\nReturns an infinite sequential unordered stream where each element is generated by the provided Supplier. This is suitable for generating constant streams, streams of random elements, etc.\nstatic \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; concat(Stream\u0026lt;? extends T\u0026gt; a, Stream\u0026lt;? extends T\u0026gt; b)\nCreates a lazily concatenated stream whose elements are all the elements of the first stream followed by all the elements of the second stream.\n另外也可以通过streamBuilder类创建stream\n处理 Stream:\nStream\u0026lt;T\u0026gt; filter(Predicate\u0026lt;? super T\u0026gt; predicate)\nReturns a stream consisting of the elements of this stream that match the given predicate. This is an intermediate operation.\n\u0026lt;R\u0026gt; Stream\u0026lt;R\u0026gt; map(Function\u0026lt;? super T,​? extends R\u0026gt; mapper)\nReturns a stream consisting of the results of applying the given function to the elements of this stream. This is an intermediate operation.\nStream\u0026lt;T\u0026gt; limit(long maxSize)\nReturns a stream consisting of the elements of this stream, truncated to be no longer than maxSize in length. This is a short-circuiting stateful intermediate operation.\nStream\u0026lt;T\u0026gt; skip(long n)\nReturns a stream consisting of the remaining elements of this stream after discarding the first n elements of the stream. If this stream contains fewer than n elements then an empty stream will be returned. This is a stateful intermediate operation.\nStream\u0026lt;T\u0026gt; sorted()\nReturns a stream consisting of the elements of this stream, sorted according to natural order. If the elements of this stream are not Comparable, a java.lang.ClassCastException may be thrown when the terminal operation is executed. For ordered streams, the sort is stable. For unordered streams, no stability guarantees are made.\nThis is a stateful intermediate operation.\nStream\u0026lt;T\u0026gt; sorted(Comparator\u0026lt;? super T\u0026gt; comparator) Returns a stream consisting of the elements of this stream, sorted according to the provided Comparator. For ordered streams, the sort is stable. For unordered streams, no stability guarantees are made.\nThis is a stateful intermediate operation.\n约简 Stream:\nvoid forEach(Consumer\u0026lt;? super T\u0026gt; action)\nPerforms an action for each element of this stream. This is a terminal operation.\nOptional\u0026lt;T\u0026gt; findFirst()\nReturns an Optional describing the first element of this stream, or an empty Optional if the stream is empty. If the stream has no encounter order, then any element may be returned. This is a short-circuiting terminal operation.\nOptional\u0026lt;T\u0026gt; max(Comparator\u0026lt;? super T\u0026gt; comparator)\nReturns the maximum element of this stream according to the provided Comparator. This is a special case of a reduction. This is a terminal operation.\nOptional\u0026lt;T\u0026gt; min(Comparator\u0026lt;? super T\u0026gt; comparator)\nReturns the minimum element of this stream according to the provided Comparator. This is a special case of a reduction. This is a terminal operation.\nT reduce(T identity, BinaryOperator\u0026lt;T\u0026gt; accumulator)\nPerforms a reduction on the elements of this stream, using the provided identity value and an associative accumulation function, and returns the reduced value. This is equivalent to:\nT result = identity; for (T element : this stream) result = accumulator.apply(result, element) return result; but is not constrained to execute sequentially. The identity value must be an identity for the accumulator function. This means that for all t, accumulator.apply(identity, t) is equal to t. The accumulator function must be an associative function.\nThis is a terminal operation.\nOptional\u0026lt;T\u0026gt; reduce(BinaryOperator\u0026lt;T\u0026gt; accumulator)\nPerforms a reduction on the elements of this stream, using an associative accumulation function, and returns an Optional describing the reduced value, if any. This is equivalent to:\nboolean foundAny = false; T result = null; for (T element : this stream) { if (!foundAny) { foundAny = true; result = element; } else result = accumulator.apply(result, element); } return foundAny ? Optional.of(result) : Optional.empty(); but is not constrained to execute sequentially. The accumulator function must be an associative function.This is a terminal operation.\n","permalink":"https://rzyn2020.github.io/posts/%E6%B5%85%E8%B0%88java8%E4%B8%AD%E7%9A%84%E6%B5%81/","summary":"\u003cblockquote\u003e\n\u003cp\u003e万物皆流，无物常驻\u003c/p\u003e\u003c/blockquote\u003e","title":"浅谈java8中的流"},{"content":" 2021-03-06~2021-08-18 hexo next 2021-08-18~2023-04-21 hexo keep 2023-04-21~? hugo diary ","permalink":"https://rzyn2020.github.io/about/","summary":"\u003chr\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#abb2bf;background-color:#282c34;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e2021-03-06~2021-08-18 hexo next\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e2021-08-18~2023-04-21 hexo keep\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e2023-04-21~?          hugo diary\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"About"}]